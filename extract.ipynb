{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee57f4b-4e4a-42ae-9683-343774c348f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyxlsb\n",
    "pip install sqlalchemy psycopg2-binary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6486e77-fdd0-49e0-90c2-094615d930e2",
   "metadata": {},
   "source": [
    "# Connexion BDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa857a7-7626-475a-8915-0f79ef1f611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q \"sqlalchemy>=2\" psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae207269-9650-4173-81eb-b44a74f42e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] Connecté à PostgreSQL Render\n",
      "PostgreSQL 17.6 (Debian 17.6-1.pgdg12+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14+deb12u1) 12.2.0, 64-bit\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import OperationalError\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "PG_HOST = \"dpg-d3jq6apr0fns738f81i0-a.frankfurt-postgres.render.com\"\n",
    "PG_PORT = 5432\n",
    "PG_DB   = \"aerotec_datawarehouse\"\n",
    "PG_USER = \"aerotec_datawarehouse_user\"\n",
    "PG_PASS = \"LHTYZJ3aUDI8IeylbA1SZs9M9TsKQ4To\"\n",
    "\n",
    "conn_str = (\n",
    "    f\"postgresql+psycopg2://{PG_USER}:{quote_plus(PG_PASS)}@{PG_HOST}:{PG_PORT}/{PG_DB}\"\n",
    ")\n",
    "\n",
    "# Astuces de stabilité pour Render :\n",
    "# - sslmode=require (obligatoire)\n",
    "# - connect_timeout : évite de bloquer si le réseau/host ne répond pas\n",
    "# - keepalives_* : évite les coupures silencieuses d’idle\n",
    "engine = create_engine(\n",
    "    conn_str,\n",
    "    connect_args={\n",
    "        \"sslmode\": \"require\",\n",
    "        \"connect_timeout\": 5,\n",
    "        \"keepalives\": 1,\n",
    "        \"keepalives_idle\": 30,\n",
    "        \"keepalives_interval\": 10,\n",
    "        \"keepalives_count\": 3,\n",
    "    },\n",
    "    pool_pre_ping=True,     # ping avant réutilisation du pool\n",
    "    pool_recycle=1800,      # recycle connexions > 30 min\n",
    "    pool_size=5,\n",
    "    max_overflow=5,\n",
    ")\n",
    "\n",
    "# Test rapide de connectivité (à garder au début du main)\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        ver = conn.execute(text(\"select version();\")).scalar()\n",
    "        print(\"[ok] Connecté à PostgreSQL Render\")\n",
    "        print(ver)\n",
    "except OperationalError as e:\n",
    "    print(\"[error] Connexion PostgreSQL échouée:\", e)\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2341020a-4972-418e-b2a9-9c904a1541a7",
   "metadata": {},
   "source": [
    " # fichier qualité des trigrammes.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0127f132-cfba-4b30-b958-7ad1c70d19a1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07e0087b-c5bc-40e3-9c01-cd4dfaee5ee7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] Connecté à PostgreSQL\n",
      "PostgreSQL 17.6 (Debian 17.6-1.pgdg12+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14+deb12u1) 12.2.0, 64-bit\n",
      "\n",
      "--- Feuille: PDG -> public.fichier_qualite_des_trigrammes__pdg ---\n",
      "rows=20 | cols=4\n",
      "Colonnes: edition, date, motif, redacteur\n",
      "\n",
      "Schema détecté:\n",
      "  - edition: INT -> Integer\n",
      "  - date: DATE -> Date\n",
      "  - motif: STRING -> Text\n",
      "  - redacteur: STRING -> Text\n",
      "\n",
      "Sample (top 8):\n",
      "    edition       date                                              motif    redacteur\n",
      "9         1 2024-06-10                                           Création  S. BELMONTE\n",
      "10        2 2024-09-16                           Ajout nouveaux arrivants    Y. RAGEOT\n",
      "11        3 2024-10-21                                    Ajout couturier    Y. RAGEOT\n",
      "12        4 2024-10-28  Mise à jour des dates d'entrée \n",
      "Ajout des habi...    Y. RAGEOT\n",
      "13        5 2024-12-16  Ajout nouvelle arrivante - 1 personne - Feriel...  F.BOULHABEL\n",
      "14        6 2024-12-18                              Départ de Yann RAGEOT  S. BELMONTE\n",
      "15        7 2024-12-19  Ajout de nouveaux arrivants - 4 personnes - Fr...  F.BOULHABEL\n",
      "16        8 2024-12-20  Ajout de nouvel arrivant - 1 personne - Loris ...  F.BOULHABEL\n",
      "[ok] Inserted into public.fichier_qualite_des_trigrammes__pdg\n",
      "\n",
      "--- Feuille: Liste -> public.fichier_qualite_des_trigrammes__liste ---\n",
      "rows=201 | cols=6\n",
      "Colonnes: nom_prenom, trig, personnel_int_ext, site, date_d_attribution, date_de_retrait\n",
      "\n",
      "Schema détecté:\n",
      "  - nom_prenom: STRING -> Text\n",
      "  - trig: STRING -> Text\n",
      "  - personnel_int_ext: STRING -> Text\n",
      "  - site: STRING -> Text\n",
      "  - date_d_attribution: DATE -> Date\n",
      "  - date_de_retrait: DATE -> Date\n",
      "\n",
      "Sample (top 8):\n",
      "                  nom_prenom trig personnel_int_ext site date_d_attribution date_de_retrait\n",
      "9               ABAT Nicolas  ABT           Interne  AEC         2025-02-17             NaT\n",
      "10   ABDELLAOUI Schéhérazade  ADI           Interne  AEB         2025-05-05             NaT\n",
      "11          ADJEROUD Bastian  BAD           Interne  AEX         2024-05-21             NaT\n",
      "12              AGREBI Lilia  ARI           Interne  AEC         2025-02-24             NaT\n",
      "13          ALBERTON YANNICK  YAL           Interne  AEC         2018-11-05      2021-09-10\n",
      "14  ALIAS Séverine née HERAL  ALS           Interne  AEG         2024-05-21             NaT\n",
      "15      ALLARD Jean-François  ALD           Externe  AEC                NaT             NaT\n",
      "16               ALLARD Yann  YAD           Interne  AEC         2024-06-03             NaT\n",
      "[ok] Inserted into public.fichier_qualite_des_trigrammes__liste\n",
      "\n",
      "Done. Feuilles analysées & importées: 2\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, unicodedata, warnings\n",
    "\n",
    "# --- DB: SQLAlchemy\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy import types as satypes\n",
    "from sqlalchemy.exc import OperationalError\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "# ================== CONFIG ================== #\n",
    "FILE_PATH = r\"C:\\globasoft\\aerotech\\fic\\fichier qualité des trigrammes.xlsx\"\n",
    "SHOW_SAMPLE = True\n",
    "TARGET_SCHEMA = \"public\"          # schéma cible\n",
    "IF_EXISTS_MODE = \"replace\"        # \"replace\" ou \"append\"\n",
    "\n",
    "# Forcer certains noms de colonnes en DATE/DATETIME (optionnel)\n",
    "FORCE_DATE_COLS = {\"date_d_attribution\", \"date_de_retrait\"}  # snake_case attendu\n",
    "\n",
    "# ================== ACCÈS DB ================== #\n",
    "REQUIRED_KEYS = (\"PG_HOST\",\"PG_PORT\",\"PG_DB\",\"PG_USER\",\"PG_PASS\")\n",
    "\n",
    "def _collect_pg_config():\n",
    "    \"\"\"Récupère les creds depuis le 1er bloc (globals) OU depuis l'env.\"\"\"\n",
    "    cfg = {}\n",
    "    g = globals()\n",
    "    # 1) variables déjà définies dans le 1er bloc ?\n",
    "    for k in REQUIRED_KEYS:\n",
    "        if k in g and g[k]:\n",
    "            cfg[k] = g[k]\n",
    "    # 2) sinon variables d'environnement ?\n",
    "    for k in REQUIRED_KEYS:\n",
    "        if k not in cfg or not cfg[k]:\n",
    "            v = os.getenv(k)\n",
    "            if v:\n",
    "                cfg[k] = v\n",
    "\n",
    "    # défauts pratiques si seul le host Render est utilisé\n",
    "    if \"PG_HOST\" not in cfg or not cfg[\"PG_HOST\"]:\n",
    "        cfg[\"PG_HOST\"] = \"dpg-d3jq6apr0fns738f81i0-a.frankfurt-postgres.render.com\"\n",
    "    if \"PG_PORT\" not in cfg or not cfg[\"PG_PORT\"]:\n",
    "        cfg[\"PG_PORT\"] = 5432\n",
    "    else:\n",
    "        cfg[\"PG_PORT\"] = int(cfg[\"PG_PORT\"])\n",
    "\n",
    "    missing = [k for k in REQUIRED_KEYS if k not in cfg or cfg[k] in (\"\", None)]\n",
    "    if missing:\n",
    "        raise RuntimeError(\n",
    "            \"Paramètres DB manquants: \"\n",
    "            + \", \".join(missing)\n",
    "            + \". Définis-les dans le 1er bloc (PG_*) ou via variables d'environnement.\"\n",
    "        )\n",
    "    return cfg\n",
    "\n",
    "def get_engine():\n",
    "    \"\"\"Réutilise l'engine existant si présent. Sinon, en crée un avec SSL Render.\"\"\"\n",
    "    g = globals()\n",
    "    if \"engine\" in g and g[\"engine\"] is not None:\n",
    "        return g[\"engine\"]\n",
    "\n",
    "    cfg = _collect_pg_config()\n",
    "    conn_str = (\n",
    "        f\"postgresql+psycopg2://{cfg['PG_USER']}:{quote_plus(cfg['PG_PASS'])}\"\n",
    "        f\"@{cfg['PG_HOST']}:{cfg['PG_PORT']}/{cfg['PG_DB']}\"\n",
    "    )\n",
    "    eng = create_engine(\n",
    "        conn_str,\n",
    "        connect_args={\n",
    "            \"sslmode\": \"require\",\n",
    "            \"connect_timeout\": 5,\n",
    "            \"keepalives\": 1,\n",
    "            \"keepalives_idle\": 30,\n",
    "            \"keepalives_interval\": 10,\n",
    "            \"keepalives_count\": 3,\n",
    "        },\n",
    "        pool_pre_ping=True,\n",
    "        pool_recycle=1800,\n",
    "        pool_size=5,\n",
    "        max_overflow=5,\n",
    "    )\n",
    "    return eng\n",
    "\n",
    "# ================== UTILS ================== #\n",
    "def strip_accents_lower(s):\n",
    "    if s is None or (isinstance(s, float) and pd.isna(s)): return \"\"\n",
    "    s = unicodedata.normalize(\"NFKD\", str(s))\n",
    "    s = \"\".join(c for c in s if not unicodedata.combining(c))\n",
    "    return s.lower().strip()\n",
    "\n",
    "def snake_id(s):\n",
    "    s = strip_accents_lower(s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s.strip())           # normalise espaces\n",
    "    s = re.sub(r\"[\\s\\.\\-]+\", \"_\", s)             # espaces/points/tirets -> _\n",
    "    s = re.sub(r\"[^a-z0-9_]\", \"_\", s)            # autres -> _\n",
    "    s = re.sub(r\"_+\", \"_\", s).strip(\"_\") or \"col\"\n",
    "    return s\n",
    "\n",
    "def pg_ident(name: str, maxlen=63) -> str:\n",
    "    \"\"\"PostgreSQL ident max 63 chars.\"\"\"\n",
    "    return name[:maxlen]\n",
    "\n",
    "def parse_number_like(s: pd.Series) -> pd.Series:\n",
    "    # gère espace normal, insécable et fine insécable\n",
    "    x = s.astype(\"string\")\\\n",
    "         .str.replace(\"\\u00A0\", \" \", regex=False)\\\n",
    "         .str.replace(\"\\u202F\", \" \", regex=False)\\\n",
    "         .str.replace(\" \", \"\", regex=False)\n",
    "    x = x.str.replace(r\"(?<=\\d)\\.(?=\\d{3}(?:\\D|$))\", \"\", regex=True)\\\n",
    "         .str.replace(\",\", \".\", regex=False)\n",
    "    return pd.to_numeric(x, errors=\"coerce\")\n",
    "\n",
    "# --- header smarter ---\n",
    "HEADER_KEYWORDS = (\n",
    "    \"date\", \"motif\", \"rédact\", \"redact\", \"trig\", \"nom\", \"prénom\", \"prenom\",\n",
    "    \"personnel\", \"site\", \"retrait\", \"édition\", \"edition\"\n",
    ")\n",
    "\n",
    "def choose_header_row(df: pd.DataFrame, scan=25) -> int:\n",
    "    limit = min(len(df), scan)\n",
    "    header_candidate_idx = None\n",
    "    header_candidate_hits = -1\n",
    "    for i in range(limit):\n",
    "        row = df.iloc[i].astype(str)\n",
    "        hits = 0\n",
    "        for v in row:\n",
    "            t = strip_accents_lower(v)\n",
    "            if t and any(k in t for k in HEADER_KEYWORDS):\n",
    "                hits += 1\n",
    "        if hits >= 2 and hits > header_candidate_hits:\n",
    "            header_candidate_hits = hits\n",
    "            header_candidate_idx = i\n",
    "    if header_candidate_idx is not None:\n",
    "        return header_candidate_idx\n",
    "    best, idx = -1, 0\n",
    "    for i in range(limit):\n",
    "        row = df.iloc[i].astype(str)\n",
    "        non_empty = row.map(lambda x: x.strip()!=\"\").sum()\n",
    "        texty = row.map(lambda x: bool(re.search(r\"[A-Za-zÀ-ÿ]\", x))).sum()\n",
    "        score = non_empty*2 + texty\n",
    "        if score>best: best, idx = score, i\n",
    "    return idx\n",
    "\n",
    "def normalize_columns(header_vals):\n",
    "    cols, seen = [], {}\n",
    "    for v in header_vals:\n",
    "        s = snake_id(v) if (v is not None and str(v).strip()!=\"\") else \"col\"\n",
    "        seen[s] = seen.get(s,0)+1\n",
    "        cols.append(s if seen[s]==1 else f\"{s}_{seen[s]}\")\n",
    "    return cols\n",
    "\n",
    "def drop_empty_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.dropna(axis=1, how=\"all\")\n",
    "    blank_cols = [c for c in df.columns\n",
    "                  if df[c].isna().all() or df[c].astype(str).str.strip().eq(\"\").all()]\n",
    "    return df.drop(columns=blank_cols) if blank_cols else df\n",
    "\n",
    "# --- inférence minimale robuste ---\n",
    "MAP_TRUE  = {\"true\",\"vrai\",\"oui\",\"yes\",\"1\",\"y\",\"o\"}\n",
    "MAP_FALSE = {\"false\",\"faux\",\"non\",\"no\",\"0\",\"n\"}\n",
    "\n",
    "DATE_TOKEN_RE = re.compile(\n",
    "    r\"(?:\\d{4}[-/\\.]\\d{1,2}[-/\\.]\\d{1,2})|(?:\\d{1,2}[-/\\.]\\d{1,2}[-/\\.]\\d{2,4})|\"\n",
    "    r\"(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec|janv|févr|fevr|avr|mai|juin|juil|sept|oct|nov|d[ée]c)\",\n",
    "    re.I\n",
    ")\n",
    "ISO_DATE_RE = re.compile(r\"^\\d{4}-\\d{2}-\\d{2}(?:[ T]\\d{2}:\\d{2}:\\d{2})?$\")\n",
    "COLNAME_DATE_HINTS = (\"date\", \"dt\", \"heure\", \"time\")\n",
    "\n",
    "def infer_col(s: pd.Series):\n",
    "    s = s.copy()\n",
    "    ss = s.astype(\"string\").str.strip()\n",
    "    ss = ss.where(~ss.fillna(\"\").eq(\"0\"), pd.NA)  # éviter 0 -> 1970-01-01\n",
    "\n",
    "    # 🔒 Forçage par nom de colonne (date_de_retrait, date_d_attribution) sans warning\n",
    "    if snake_id(s.name) in FORCE_DATE_COLS:\n",
    "        val = ss.fillna(\"\")\n",
    "        iso_mask = val.str.match(ISO_DATE_RE)\n",
    "        if iso_mask.mean() >= 0.5:\n",
    "            # Majoritairement ISO -> pas de warning\n",
    "            dt = pd.to_datetime(ss, errors=\"coerce\", dayfirst=False)\n",
    "        else:\n",
    "            # Essaie les deux et garde le meilleur parse\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings(\"ignore\", message=\"Could not infer format.*\", category=UserWarning)\n",
    "                dt1 = pd.to_datetime(ss, errors=\"coerce\", dayfirst=True,  cache=True)\n",
    "                dt2 = pd.to_datetime(ss, errors=\"coerce\", dayfirst=False, cache=True)\n",
    "            dt = dt2 if dt2.notna().sum() > dt1.notna().sum() else dt1\n",
    "\n",
    "        valid_dt = dt.dropna()\n",
    "        has_time = (len(valid_dt) and (valid_dt.dt.time.astype(str) != \"00:00:00\").mean() > 0.2)\n",
    "        return (dt, \"DATETIME\" if has_time else \"DATE\")\n",
    "\n",
    "    # 0) ISO\n",
    "    iso_mask = ss.fillna(\"\").str.match(ISO_DATE_RE)\n",
    "    if iso_mask.mean() >= 0.5:\n",
    "        dt_iso = pd.to_datetime(ss.where(iso_mask), errors=\"coerce\", dayfirst=False)\n",
    "        ok = dt_iso.notna().mean() if len(ss) else 0.0\n",
    "        if ok >= 0.5:\n",
    "            valid_dt = dt_iso.dropna()\n",
    "            has_time = (len(valid_dt) and (valid_dt.dt.time.astype(str) != \"00:00:00\").mean() > 0.2)\n",
    "            return (dt_iso, \"DATETIME\" if has_time else \"DATE\")\n",
    "\n",
    "    # 1) Excel serial\n",
    "    as_num = pd.to_numeric(ss, errors=\"coerce\")\n",
    "    frac_num = as_num.notna().mean() if len(ss) else 0.0\n",
    "    if frac_num >= 0.9:\n",
    "        mask = as_num.between(60, 2950000)\n",
    "        parsed = pd.to_datetime(as_num.where(mask), unit=\"D\", origin=\"1899-12-30\", errors=\"coerce\")\n",
    "        ok = parsed.notna().mean() if len(ss) else 0.0\n",
    "        if ok >= 0.7:\n",
    "            valid_dt = parsed.dropna()\n",
    "            has_time = (len(valid_dt) and (valid_dt.dt.time.astype(str) != \"00:00:00\").mean() > 0.2)\n",
    "            return (parsed, \"DATETIME\" if has_time else \"DATE\")\n",
    "\n",
    "    # 2) tokens / nom de colonne (tolérant aux colonnes clairsemées)\n",
    "    colname_hint = any(h in strip_accents_lower(s.name or \"\") for h in COLNAME_DATE_HINTS)\n",
    "    date_token_ratio = ss.fillna(\"\").str.contains(DATE_TOKEN_RE, na=False).mean()\n",
    "    looks_datey = colname_hint or (date_token_ratio >= 0.30)\n",
    "    if looks_datey:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", message=\"Could not infer format.*\", category=UserWarning)\n",
    "            dt1 = pd.to_datetime(ss, errors=\"coerce\", dayfirst=True,  cache=True)\n",
    "            dt2 = pd.to_datetime(ss, errors=\"coerce\", dayfirst=False, cache=True)\n",
    "        dt = dt2 if dt2.notna().sum() > dt1.notna().sum() else dt1\n",
    "\n",
    "        n_all = len(ss)\n",
    "        n_parsed = int(dt.notna().sum())\n",
    "        nonempty_mask = ss.fillna(\"\").str.strip().ne(\"\")\n",
    "        n_nonempty = int(nonempty_mask.sum())\n",
    "\n",
    "        ok_abs = (n_parsed / n_all) if n_all else 0.0\n",
    "        ok_nonempty = (n_parsed / n_nonempty) if n_nonempty else 0.0\n",
    "\n",
    "        if colname_hint:\n",
    "            accept = (n_parsed >= 3 and ok_nonempty >= 0.80) or (n_parsed >= 2 and ok_abs >= 0.20)\n",
    "        else:\n",
    "            accept = ok_abs >= 0.70\n",
    "\n",
    "        if accept:\n",
    "            valid_dt = dt.dropna()\n",
    "            has_time = (len(valid_dt) and (valid_dt.dt.time.astype(str) != \"00:00:00\").mean() > 0.2)\n",
    "            return (dt, \"DATETIME\" if has_time else \"DATE\")\n",
    "\n",
    "    # 3) bool strict\n",
    "    mb = ss.str.lower().map(lambda x: True if x in MAP_TRUE else (False if x in MAP_FALSE else pd.NA))\n",
    "    if (mb.notna().mean() if len(ss) else 0) >= 0.98:\n",
    "        return mb.astype(\"boolean\"), \"BOOL\"\n",
    "\n",
    "    # 4) nombre\n",
    "    nums = parse_number_like(ss)\n",
    "    if (nums.notna().mean() if len(ss.dropna()) else 0) >= 0.85:\n",
    "        nz = nums.dropna()\n",
    "        if len(nz) and np.isclose(nz, np.round(nz)).all():\n",
    "            return nums.round().astype(\"Int64\"), \"INT\"\n",
    "        return nums.astype(\"Float64\"), \"FLOAT\"\n",
    "\n",
    "    # 5) texte\n",
    "    return ss.astype(\"string\"), \"STRING\"\n",
    "\n",
    "def pg_type(tag: str):\n",
    "    return {\n",
    "        \"DATE\": satypes.Date(),\n",
    "        \"DATETIME\": satypes.DateTime(),  # timestamp without time zone\n",
    "        \"INT\": satypes.Integer(),\n",
    "        \"FLOAT\": satypes.Float(precision=53),\n",
    "        \"BOOL\": satypes.Boolean(),\n",
    "        \"STRING\": satypes.Text()\n",
    "    }.get(tag, satypes.Text())\n",
    "\n",
    "# ================== DB WRITE ================== #\n",
    "def write_df_to_postgres(engine, df: pd.DataFrame, table_name: str, schema_tags: dict):\n",
    "    # cast pandas → types sûrs\n",
    "    for c, tag in schema_tags.items():\n",
    "        if tag == \"DATE\":\n",
    "            df[c] = pd.to_datetime(df[c], errors=\"coerce\").dt.date\n",
    "        elif tag == \"DATETIME\":\n",
    "            df[c] = pd.to_datetime(df[c], errors=\"coerce\")\n",
    "\n",
    "    dtype_map = {c: pg_type(tag) for c, tag in schema_tags.items()}\n",
    "\n",
    "    df.to_sql(\n",
    "        name=table_name,\n",
    "        con=engine,\n",
    "        schema=TARGET_SCHEMA,\n",
    "        if_exists=IF_EXISTS_MODE,   # \"replace\" ou \"append\"\n",
    "        index=False,\n",
    "        dtype=dtype_map,\n",
    "        method=\"multi\",\n",
    "        chunksize=1000\n",
    "    )\n",
    "\n",
    "# ================== MAIN ================== #\n",
    "def main():\n",
    "    xlsx = Path(FILE_PATH)\n",
    "    if not xlsx.exists():\n",
    "        print(f\"[error] Fichier introuvable: {xlsx}\")\n",
    "        return\n",
    "\n",
    "    # Connexion DB (réutilise le 1er bloc ou env)\n",
    "    try:\n",
    "        engine = get_engine()\n",
    "        with engine.connect() as conn:\n",
    "            ver = conn.execute(text(\"select version();\")).scalar()\n",
    "            print(\"[ok] Connecté à PostgreSQL\")\n",
    "            print(ver)\n",
    "    except (OperationalError, RuntimeError) as e:\n",
    "        print(\"[error] Connexion PostgreSQL échouée:\", e)\n",
    "        return\n",
    "\n",
    "    # Lecture multi-feuilles\n",
    "    sheets = pd.read_excel(xlsx, sheet_name=None, engine=\"openpyxl\", header=None)\n",
    "\n",
    "    file_base = snake_id(xlsx.stem)\n",
    "    done = 0\n",
    "\n",
    "    for name, raw in sheets.items():\n",
    "        raw = raw.dropna(how=\"all\", axis=0).dropna(how=\"all\", axis=1)\n",
    "        if raw.empty:\n",
    "            continue\n",
    "\n",
    "        h = choose_header_row(raw, scan=25)\n",
    "        cols = normalize_columns(raw.iloc[h].tolist())\n",
    "        df = raw.iloc[h+1:].copy()\n",
    "        df.columns = cols\n",
    "\n",
    "        df = df.dropna(how=\"all\")\n",
    "        df = drop_empty_columns(df)\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        schema = {}\n",
    "        for c in df.columns:\n",
    "            casted, tag = infer_col(df[c])\n",
    "            df[c] = casted\n",
    "            schema[c] = tag\n",
    "\n",
    "        # Nom de table: public.<file> si 1 feuille, sinon public.<file>__<sheet>\n",
    "        sheet_base = snake_id(name)\n",
    "        table_name = file_base if len(sheets) == 1 else f\"{file_base}__{sheet_base}\"\n",
    "        table_name = pg_ident(table_name)\n",
    "\n",
    "        print(f\"\\n--- Feuille: {name} -> {TARGET_SCHEMA}.{table_name} ---\")\n",
    "        print(f\"rows={len(df)} | cols={df.shape[1]}\")\n",
    "        print(\"Colonnes:\", \", \".join(df.columns.astype(str)))\n",
    "        print(\"\\nSchema détecté:\")\n",
    "        for c in df.columns:\n",
    "            pgt = type(pg_type(schema[c])).__name__.replace(\"TypeEngine\", \"\")\n",
    "            print(f\"  - {c}: {schema[c]} -> {pgt}\")\n",
    "\n",
    "        if SHOW_SAMPLE:\n",
    "            with pd.option_context(\"display.max_columns\", 80, \"display.width\", 200):\n",
    "                print(\"\\nSample (top 8):\")\n",
    "                print(df.head(8))\n",
    "\n",
    "        # Écriture DB\n",
    "        try:\n",
    "            write_df_to_postgres(engine, df.copy(), table_name, schema)\n",
    "            print(f\"[ok] Inserted into {TARGET_SCHEMA}.{table_name}\")\n",
    "            done += 1\n",
    "        except Exception as e:\n",
    "            print(f\"[error] Échec insertion {TARGET_SCHEMA}.{table_name}: {e}\")\n",
    "\n",
    "    print(f\"\\nDone. Feuilles analysées & importées: {done}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512156ef-83e5-48d0-9366-eb6acf766b53",
   "metadata": {},
   "source": [
    "# Conditionsdepaiement.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00e463cb-e4b5-4166-8712-a60c764a7ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:31:00] Fichier: C:\\globasoft\\aerotech\\fic\\Conditionsdepaiement.xlsx\n",
      "[15:31:00] Feuille[0]: shape=(19, 3)\n",
      "[15:31:00] Après drop vides: (19, 3) -> (19, 3)\n",
      "[15:31:00] Colonnes du fichier conservées: code_condition, libelle, delai_source\n",
      "\n",
      "--- Conditions de paiement (collecte) ---\n",
      "rows=19 | cols=3\n",
      "Colonnes: code_condition, libelle, delai_source\n",
      "\n",
      "Schéma final (identique au fichier, sans colonnes ajoutées):\n",
      "  - code_condition: dtype pandas = float64\n",
      "  - libelle: dtype pandas = string\n",
      "  - delai_source: dtype pandas = Int64\n",
      "\n",
      "Sample (top 15):\n",
      "    code_condition                        libelle  delai_source\n",
      "0              1.0             Chèque à réception             0\n",
      "1              6.0   Virement bancaire à 30 jours            30\n",
      "2              7.0        Règlement à la commande             0\n",
      "3              9.0              Chèque à 30 jours            30\n",
      "4             15.0   Virement bancaire à 60 jours            60\n",
      "5             16.0   Virement bancaire à 45 jours            45\n",
      "6             18.0           Virement à réception             0\n",
      "7             25.0         Règlement 30 jours FDM            30\n",
      "8             23.0         Virement le 10 du Mois          <NA>\n",
      "9             13.0  Virement 45 jours fin de mois          <NA>\n",
      "10            24.0   Virement bancaire à 15 jours            15\n",
      "11             8.0           chéque sous 10 jours            10\n",
      "12            22.0              Chéque à 45 jours            45\n",
      "13            11.0          Chèque à la livraison             0\n",
      "14            19.0      Paiement par anticipation             0\n",
      "[15:31:00] [ok] Connecté PostgreSQL\n",
      "[15:31:00] PostgreSQL 17.6 (Debian 17.6-1.pgdg12+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14+deb12u1) 12.2.0, 64-bit\n",
      "[15:31:01] [ok] Inserted into public.conditionsdepaiement\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import re, unicodedata\n",
    "from datetime import datetime\n",
    "\n",
    "# --- DB: SQLAlchemy\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy import types as satypes\n",
    "from sqlalchemy.exc import OperationalError\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "# ========= CONFIG =========\n",
    "FILE_PATH = r\"C:\\globasoft\\aerotech\\fic\\Conditionsdepaiement.xlsx\"\n",
    "SHOW_SAMPLE = True\n",
    "\n",
    "# DB cible\n",
    "TARGET_SCHEMA   = \"public\"\n",
    "IF_EXISTS_MODE  = \"replace\"      # \"replace\" ou \"append\"\n",
    "TABLE_NAME      = None           # None => snake(file_stem) ; sinon \"conditions_paiement\"\n",
    "\n",
    "# ========= LOG =========\n",
    "def now(): return datetime.now().strftime(\"%H:%M:%S\")\n",
    "def log(msg): print(f\"[{now()}] {msg}\", flush=True)\n",
    "\n",
    "# ========= ACCÈS DB =========\n",
    "REQUIRED_KEYS = (\"PG_HOST\",\"PG_PORT\",\"PG_DB\",\"PG_USER\",\"PG_PASS\")\n",
    "\n",
    "def _collect_pg_config():\n",
    "    \"\"\"Récupère creds depuis globals/env, avec defaults Render.\"\"\"\n",
    "    cfg, g = {}, globals()\n",
    "    for k in REQUIRED_KEYS:\n",
    "        if k in g and g[k]:\n",
    "            cfg[k] = g[k]\n",
    "    for k in REQUIRED_KEYS:\n",
    "        if k not in cfg or not cfg[k]:\n",
    "            v = os.getenv(k)\n",
    "            if v:\n",
    "                cfg[k] = v\n",
    "\n",
    "    if not cfg.get(\"PG_HOST\"):\n",
    "        cfg[\"PG_HOST\"] = \"dpg-d3jq6apr0fns738f81i0-a.frankfurt-postgres.render.com\"\n",
    "    cfg[\"PG_PORT\"] = int(cfg.get(\"PG_PORT\", 5432))\n",
    "\n",
    "    missing = [k for k in REQUIRED_KEYS if not cfg.get(k)]\n",
    "    if missing:\n",
    "        raise RuntimeError(\"Paramètres DB manquants: \" + \", \".join(missing))\n",
    "    return cfg\n",
    "\n",
    "def get_engine():\n",
    "    \"\"\"Réutilise engine global si présent, sinon crée avec SSL Render.\"\"\"\n",
    "    g = globals()\n",
    "    if \"engine\" in g and g[\"engine\"] is not None:\n",
    "        return g[\"engine\"]\n",
    "    cfg = _collect_pg_config()\n",
    "    conn_str = (\n",
    "        f\"postgresql+psycopg2://{cfg['PG_USER']}:{quote_plus(cfg['PG_PASS'])}\"\n",
    "        f\"@{cfg['PG_HOST']}:{cfg['PG_PORT']}/{cfg['PG_DB']}\"\n",
    "    )\n",
    "    eng = create_engine(\n",
    "        conn_str,\n",
    "        connect_args={\n",
    "            \"sslmode\": \"require\",\n",
    "            \"connect_timeout\": 5,\n",
    "            \"keepalives\": 1,\n",
    "            \"keepalives_idle\": 30,\n",
    "            \"keepalives_interval\": 10,\n",
    "            \"keepalives_count\": 3,\n",
    "        },\n",
    "        pool_pre_ping=True,\n",
    "        pool_recycle=1800,\n",
    "        pool_size=5,\n",
    "        max_overflow=5,\n",
    "    )\n",
    "    return eng\n",
    "\n",
    "# ========= UTILS =========\n",
    "def strip_accents_lower(s: str) -> str:\n",
    "    if s is None: return \"\"\n",
    "    s = unicodedata.normalize(\"NFKD\", str(s))\n",
    "    s = \"\".join(c for c in s if not unicodedata.combining(c))\n",
    "    return s.lower().strip()\n",
    "\n",
    "def snake_id(s: str) -> str:\n",
    "    s = strip_accents_lower(s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s.strip())\n",
    "    s = re.sub(r\"[\\s\\.\\-]+\", \"_\", s)\n",
    "    s = re.sub(r\"[^a-z0-9_]\", \"_\", s)\n",
    "    return re.sub(r\"_+\", \"_\", s).strip(\"_\") or \"col\"\n",
    "\n",
    "def parse_number_like(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Normalise nombres FR/US et convertit en nombre (ou NaN).\"\"\"\n",
    "    x = series.astype(\"string\") \\\n",
    "        .str.replace(\"\\u00A0\", \" \", regex=False) \\\n",
    "        .str.replace(\"\\u202F\", \" \", regex=False) \\\n",
    "        .str.replace(\" \", \"\", regex=False)\n",
    "    x = x.str.replace(r\"(?<=\\d)\\.(?=\\d{3}(?:\\D|$))\", \"\", regex=True)  # 1.234.567 -> 1234567\n",
    "    x = x.str.replace(\",\", \".\", regex=False)                           # virgule -> point\n",
    "    return pd.to_numeric(x, errors=\"coerce\")\n",
    "\n",
    "def pick_numeric_dtype(s: pd.Series):\n",
    "    \"\"\"\n",
    "    Détermine un type SQLAlchemy pour une colonne existante SANS créer de nouvelles colonnes.\n",
    "    - si toute la colonne est Int64 -> Integer\n",
    "    - sinon si float -> Float\n",
    "    - sinon -> Text\n",
    "    \"\"\"\n",
    "    if pd.api.types.is_integer_dtype(s):\n",
    "        return satypes.Integer()\n",
    "    if pd.api.types.is_float_dtype(s):\n",
    "        return satypes.Float(precision=53)\n",
    "    return satypes.Text()\n",
    "\n",
    "# ========= ECRITURE DB =========\n",
    "def dtype_map_for_postgres(df: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Mapping typé pour to_sql (PostgreSQL) uniquement sur colonnes existantes.\n",
    "    \"\"\"\n",
    "    dtypes = {}\n",
    "    for c in df.columns:\n",
    "        dtypes[c] = pick_numeric_dtype(df[c]) if (pd.api.types.is_numeric_dtype(df[c])) else satypes.Text()\n",
    "    return dtypes\n",
    "\n",
    "def write_to_db(engine, df: pd.DataFrame, table_name: str):\n",
    "    dtypes = dtype_map_for_postgres(df)\n",
    "    df.to_sql(\n",
    "        name=table_name,\n",
    "        con=engine,\n",
    "        schema=TARGET_SCHEMA,\n",
    "        if_exists=IF_EXISTS_MODE,\n",
    "        index=False,\n",
    "        dtype=dtypes,\n",
    "        method=\"multi\",\n",
    "        chunksize=1000\n",
    "    )\n",
    "\n",
    "# ========= MAIN =========\n",
    "def main():\n",
    "    xlsx = Path(FILE_PATH)\n",
    "    log(f\"Fichier: {xlsx}\")\n",
    "    if not xlsx.exists():\n",
    "        log(\"[error] Fichier introuvable\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # header=None => pas d’en-têtes dans le fichier d’origine\n",
    "        df0 = pd.read_excel(xlsx, sheet_name=0, header=None, engine=\"openpyxl\")\n",
    "    except Exception as e:\n",
    "        log(f\"[error] Lecture échouée: {e}\")\n",
    "        return\n",
    "\n",
    "    log(f\"Feuille[0]: shape={df0.shape}\")\n",
    "\n",
    "    # Purge lignes/colonnes totalement vides\n",
    "    df = df0.dropna(how=\"all\", axis=0).dropna(how=\"all\", axis=1)\n",
    "    log(f\"Après drop vides: {df0.shape} -> {df.shape}\")\n",
    "    if df.empty:\n",
    "        log(\"Feuille vide après nettoyage.\")\n",
    "        return\n",
    "\n",
    "    # Respect strict du schéma du fichier : 2 ou 3 colonnes MAX, PAS d’ajout\n",
    "    if df.shape[1] >= 3:\n",
    "        df = df.iloc[:, :3].copy()\n",
    "        # Noms techniques stables (puisqu’il n’y a pas d’en-têtes) — mais pas de nouvelle colonne\n",
    "        df.columns = [\"code_condition\", \"libelle\", \"delai_source\"]\n",
    "        log(\"Colonnes du fichier conservées: code_condition, libelle, delai_source\")\n",
    "    elif df.shape[1] == 2:\n",
    "        df = df.iloc[:, :2].copy()\n",
    "        df.columns = [\"code_condition\", \"libelle\"]\n",
    "        log(\"Colonnes du fichier conservées: code_condition, libelle\")\n",
    "    else:\n",
    "        log(\"[warn] Moins de 2 colonnes non vides trouvées. Abandon.\")\n",
    "        return\n",
    "\n",
    "    # Nettoyage léger SANS créer de colonne : trims + tentative de parse numérique sur ce qui existe seulement\n",
    "    if \"libelle\" in df.columns:\n",
    "        df[\"libelle\"] = df[\"libelle\"].astype(\"string\").str.strip()\n",
    "\n",
    "    # Si le code est clairement numérique, on le convertit (sinon on le laisse tel quel)\n",
    "    if \"code_condition\" in df.columns:\n",
    "        s = df[\"code_condition\"].astype(\"string\").str.strip()\n",
    "        non_na = s.dropna()\n",
    "        all_digits = non_na.str.fullmatch(r\"\\d+\").all() if len(non_na) else True\n",
    "        if all_digits:\n",
    "            df[\"code_condition\"] = parse_number_like(df[\"code_condition\"]).astype(\"Int64\")\n",
    "\n",
    "    # Si delai_source existe, on essaye juste un parse numérique (sans créer d’autre colonne)\n",
    "    if \"delai_source\" in df.columns:\n",
    "        parsed = parse_number_like(df[\"delai_source\"])\n",
    "        # Si tout est int (hors NaN), on caste en Int64 ; sinon on laisse tel quel\n",
    "        if parsed.dropna().apply(float.is_integer).all():\n",
    "            df[\"delai_source\"] = parsed.astype(\"Int64\")\n",
    "        else:\n",
    "            # si mixte, garde la série d’origine (respect total du fichier)\n",
    "            pass\n",
    "\n",
    "    # Affichage\n",
    "    print(\"\\n--- Conditions de paiement (collecte) ---\")\n",
    "    print(f\"rows={len(df)} | cols={df.shape[1]}\")\n",
    "    print(\"Colonnes:\", \", \".join(df.columns.astype(str)))\n",
    "\n",
    "    print(\"\\nSchéma final (identique au fichier, sans colonnes ajoutées):\")\n",
    "    for c in df.columns:\n",
    "        print(f\"  - {c}: dtype pandas = {df[c].dtype}\")\n",
    "\n",
    "    if SHOW_SAMPLE:\n",
    "        with pd.option_context(\"display.max_columns\", 120, \"display.width\", 220):\n",
    "            print(\"\\nSample (top 15):\")\n",
    "            print(df.head(15))\n",
    "\n",
    "    # === Connexion & écriture DB ===\n",
    "    file_base = snake_id(xlsx.stem)  # ex: \"conditionsdepaiement\"\n",
    "    table_name = TABLE_NAME or file_base\n",
    "\n",
    "    try:\n",
    "        engine = get_engine()\n",
    "        with engine.connect() as conn:\n",
    "            ver = conn.execute(text(\"select version();\")).scalar()\n",
    "            log(\"[ok] Connecté PostgreSQL\")\n",
    "            log(ver)\n",
    "    except (OperationalError, RuntimeError) as e:\n",
    "        log(f\"[error] Connexion PostgreSQL échouée: {e}\")\n",
    "        return df\n",
    "\n",
    "    try:\n",
    "        write_to_db(engine, df, table_name)\n",
    "        log(f\"[ok] Inserted into {TARGET_SCHEMA}.{table_name}\")\n",
    "    except Exception as e:\n",
    "        log(f\"[error] Échec insertion {TARGET_SCHEMA}.{table_name}: {e}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_conditions = main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904113a8-3a66-4165-81c9-b213fcff63db",
   "metadata": {},
   "source": [
    "# FNP AEC projets - source.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eb37216-3eab-4cc2-8ed7-61212191ea33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:24:20] Fichier: C:\\globasoft\\aerotech\\fic\\FNP AEC projets - source.xlsx\n",
      "[15:24:21] \n",
      "[feuille] FNP achats: shape initiale=(1417, 23)\n",
      "[15:24:21] [feuille] FNP achats: après drop vides -> (1417, 23)\n",
      "[15:24:21] [feuille] FNP achats: header choisi à la ligne 0\n",
      "[15:24:21] [feuille] FNP achats: colonnes normalisées -> periode, fournisseur_interne_externe, fournisseurs, code_projets, libelle_commande, type, n_cmd_aec, cdp, n_cmd_frs_date_cmd, montant_commande_ht, factures_recues, fact_recues, factures_non_recues, avancement_sur_factu_non_recues, montant_fnp, commentaires, compte_tiers, compte_charges, soumis_non_soumis, tva, reste, client_interne, section_analytique\n",
      "[15:24:21] [feuille] FNP achats: shape après nettoyage colonnes -> (1416, 23)\n",
      "[15:24:21] [excel_serial_to_datetime] valeurs hors fenêtre [60, 106750] remplacées par NaN: 149\n",
      "\n",
      "--- Feuille: FNP achats -> fnp_aec_projets_source.fnp_achats ---\n",
      "rows=1416 | cols=23\n",
      "Colonnes: periode, fournisseur_interne_externe, fournisseurs, code_projets, libelle_commande, type, n_cmd_aec, cdp, n_cmd_frs_date_cmd, montant_commande_ht, factures_recues, fact_recues, factures_non_recues, avancement_sur_factu_non_recues, montant_fnp, commentaires, compte_tiers, compte_charges, soumis_non_soumis, tva, reste, client_interne, section_analytique\n",
      "\n",
      "Schema détecté:\n",
      "  - periode: DATE  ->  date\n",
      "  - fournisseur_interne_externe: STRING  ->  text\n",
      "  - fournisseurs: STRING  ->  text\n",
      "  - code_projets: STRING  ->  text\n",
      "  - libelle_commande: STRING  ->  text\n",
      "  - type: STRING  ->  text\n",
      "  - n_cmd_aec: DATE  ->  date\n",
      "  - cdp: STRING  ->  text\n",
      "  - n_cmd_frs_date_cmd: DATE  ->  date\n",
      "  - montant_commande_ht: DATETIME  ->  timestamp without time zone\n",
      "  - factures_recues: STRING  ->  text\n",
      "  - fact_recues: STRING  ->  text\n",
      "  - factures_non_recues: STRING  ->  text\n",
      "  - avancement_sur_factu_non_recues: FLOAT  ->  double precision\n",
      "  - montant_fnp: STRING  ->  text\n",
      "  - commentaires: STRING  ->  text\n",
      "  - compte_tiers: STRING  ->  text\n",
      "  - compte_charges: STRING  ->  text\n",
      "  - soumis_non_soumis: STRING  ->  text\n",
      "  - tva: STRING  ->  text\n",
      "  - reste: STRING  ->  text\n",
      "  - client_interne: DATE  ->  date\n",
      "  - section_analytique: STRING  ->  text\n",
      "\n",
      "Sample (top 10):\n",
      "       periode fournisseur_interne_externe                            fournisseurs code_projets              libelle_commande             type   n_cmd_aec      cdp n_cmd_frs_date_cmd  montant_commande_ht  \\\n",
      "1   2024-01-30                     Externe                           L3 WESCAM USA      C191893                   camera MX15       S/T France  1900-08-01      BAZ                NaN                  NaN   \n",
      "2   2024-01-30                     Externe                AEROPORT CASTRES MAZAMET      C192026      REDEVANCES AERONAUTIQUES       S/T France  1905-05-10      PRO         2023-08-30  1900-07-10 02:52:48   \n",
      "3   2024-01-30                     Externe                      MOUSER ELECTRONICS      C192195       Connecteurs d’éclairage  Matériel France  1903-12-03      JFA         2022-09-06                  NaN   \n",
      "4   2024-01-30                     Externe  PROFESSIONAL & BROADCAST SERVICE - PBS      C192195                       KIL1/E1  Matériel France  1904-04-16      TBI         2022-11-17                  NaN   \n",
      "5   2024-01-30                     Externe                                   CIPEM      C192195  CLAVIER IK-TR-911-RED USB-US       S/T France  1905-07-20      JFA         2023-10-30  1901-08-15 00:00:00   \n",
      "6   2024-01-30                     Externe                                   NEHIA      C202695       PREDECOUPES HD MASK 115       S/T France  1904-11-30      MSU         2023-04-27  1900-08-19 00:00:00   \n",
      "7   2024-01-30                     Externe                                 TENCATE      C202695     FABRICATION PANNEAU PORTE       S/T France  1904-12-06      MSU         2023-05-04  1907-04-13 00:00:00   \n",
      "8   2024-01-30                     Externe                                LOGO SKY      C202695              MATERIAL 3M 6900  Matériel France  1905-11-01  SRE/MSU         2023-12-20                  NaN   \n",
      "9   2024-01-30                     Externe                                   ZELIN      C212808                multiples lots       S/T France  1902-12-16      TBI         2022-02-21  1933-12-27 00:00:00   \n",
      "10  2024-01-30                     Externe                           BDEX AVIATION      C212809                         DOCHD   Matériel Monde  1903-05-13      TBI         2022-05-17  1901-02-28 00:00:00   \n",
      "\n",
      "       factures_recues         fact_recues factures_non_recues  avancement_sur_factu_non_recues        montant_fnp                       commentaires compte_tiers compte_charges soumis_non_soumis                 tva  \\\n",
      "1   2035920.4000000001  0.9654671614945716   72820.82000000007                              1.0  72820.82000000007                               <NA>   4081010000     6040000000            Soumis  14564.164000000013   \n",
      "2                 <NA>                <NA>              192.12                              1.0             192.12                               <NA>   4081010000     6040000000            Soumis   38.42400000000001   \n",
      "3                29.86                   1                <NA>                              1.0               <NA>  s48.23 : mail pour maj statut JFA   4081010000     6010000000            Soumis                <NA>   \n",
      "4                 <NA>                   1                <NA>                              1.0               <NA>  s48.23 : mail pour maj statut JFA   4081010000     6010000000            Soumis                <NA>   \n",
      "5                 <NA>                <NA>                 593                              1.0                593                               <NA>   4081010000     6040000000            Soumis  118.60000000000001   \n",
      "6                 <NA>                <NA>                 232                              1.0                232                               <NA>   4081010000     6040000000            Soumis  46.400000000000006   \n",
      "7                 <NA>                <NA>                2660                              1.0               2660                               <NA>   4081010000     6040000000            Soumis                 532   \n",
      "8                 <NA>                <NA>                  44                              1.0                 44                               <NA>   4081010000     6010000000            Soumis                 8.8   \n",
      "9                 9915  0.7986306886830447                2500                              1.0               2500                     mail TBI 31/05   4081010000     6040000000            Soumis                 500   \n",
      "10                <NA>                <NA>                 425                              1.0                425                               <NA>   4081010000     6010000000        Non soumis                <NA>   \n",
      "\n",
      "   reste client_interne       section_analytique  \n",
      "1   <NA>     1902-09-25  AEC-999-DCS-C191893-21J  \n",
      "2   <NA>     1902-09-25  AEC-999-DCS-C192026-21J  \n",
      "3   <NA>     1902-09-25  AEC-999-DCS-C192195-21J  \n",
      "4   <NA>     1902-09-25  AEC-999-DCS-C192195-21J  \n",
      "5   <NA>     1902-09-25  AEC-999-DCS-C192195-21J  \n",
      "6   <NA>     1902-09-25  AEC-999-DCS-C202695-21J  \n",
      "7   <NA>     1902-09-25  AEC-999-DCS-C202695-21J  \n",
      "8   <NA>     1902-09-25  AEC-999-DCS-C202695-21J  \n",
      "9   <NA>     1902-09-25  AEC-999-DCS-C212808-21J  \n",
      "10  <NA>     1902-09-25  AEC-999-DCS-C212809-21J  \n",
      "[15:24:22] \n",
      "[feuille] Feuil3: shape initiale=(128, 24)\n",
      "[15:24:22] [feuille] Feuil3: après drop vides -> (128, 24)\n",
      "[15:24:22] [feuille] Feuil3: header choisi à la ligne 0\n",
      "[15:24:22] [feuille] Feuil3: colonnes normalisées -> code_projet, fournisseur, ffcleunik, nofact, cofou, typebc, naf, lbcleunik, prix, prixmon, comon, qtefa, cofa, desa1, cobc, daterec, tva, compt, analytiq, datesaisie, unite, coefunite, codeemp, i1cleunik\n",
      "[15:24:22] [feuille] Feuil3: shape après nettoyage colonnes -> (127, 23)\n",
      "[15:24:22] [excel_serial_to_datetime] valeurs hors fenêtre [60, 106750] remplacées par NaN: 35\n",
      "[15:24:22] [excel_serial_to_datetime] valeurs hors fenêtre [60, 106750] remplacées par NaN: 35\n",
      "\n",
      "--- Feuille: Feuil3 -> fnp_aec_projets_source.feuil3 ---\n",
      "rows=127 | cols=23\n",
      "Colonnes: code_projet, fournisseur, ffcleunik, nofact, cofou, typebc, naf, lbcleunik, prix, prixmon, comon, qtefa, cofa, desa1, cobc, daterec, tva, compt, datesaisie, unite, coefunite, codeemp, i1cleunik\n",
      "\n",
      "Schema détecté:\n",
      "  - code_projet: STRING  ->  text\n",
      "  - fournisseur: STRING  ->  text\n",
      "  - ffcleunik: DATE  ->  date\n",
      "  - nofact: STRING  ->  text\n",
      "  - cofou: STRING  ->  text\n",
      "  - typebc: INT  ->  integer\n",
      "  - naf: INT  ->  integer\n",
      "  - lbcleunik: STRING  ->  text\n",
      "  - prix: DATETIME  ->  timestamp without time zone\n",
      "  - prixmon: DATETIME  ->  timestamp without time zone\n",
      "  - comon: INT  ->  integer\n",
      "  - qtefa: INT  ->  integer\n",
      "  - cofa: STRING  ->  text\n",
      "  - desa1: STRING  ->  text\n",
      "  - cobc: STRING  ->  text\n",
      "  - daterec: DATE  ->  date\n",
      "  - tva: INT  ->  integer\n",
      "  - compt: INT  ->  integer\n",
      "  - datesaisie: DATE  ->  date\n",
      "  - unite: STRING  ->  text\n",
      "  - coefunite: BOOL  ->  boolean\n",
      "  - codeemp: STRING  ->  text\n",
      "  - i1cleunik: STRING  ->  text\n",
      "\n",
      "Sample (top 10):\n",
      "   code_projet      fournisseur   ffcleunik     nofact  cofou  typebc    naf lbcleunik                 prix              prixmon  comon  qtefa     cofa                      desa1  cobc     daterec  tva       compt  \\\n",
      "1      C213178  AEROTEC BLAGNAC  1905-10-08    2262023  00017       3   1945      1518                  NaN                  NaN      9      1  EQUIPMT                C213178-089  1580  2023-01-02    2  6011000000   \n",
      "2      C202695  SURUGUE MICKAEL  1905-10-09  NDF23-006    MSU       3   1216      <NA>  1900-04-13 20:24:00  1900-04-13 20:24:00      9      1  MISSION  A/R GRAULHET 15/12/22 PC6  <NA>  2023-01-04    2  6256000000   \n",
      "3      C202695  SURUGUE MICKAEL  1905-10-10  NDF23-007    MSU       3   1216      <NA>  1900-04-13 20:24:00  1900-04-13 20:24:00      9      1  MISSION  A/R GRAULHET 05/01/23 PC6  <NA>  2023-01-06    2  6256000000   \n",
      "4      C212810           AVALEX  1905-10-11      46504  00194       3    697        44  1920-04-17 23:16:48  1921-10-06 00:00:00      6      1  EQUIPMT    \"17.3\"\" HD WIDESCREEN,\"   229  2022-12-22    2  6011000000   \n",
      "5      C213178  AEROTEC BLAGNAC  1905-10-12     226759  00017       3   1150       322                  NaN                  NaN      9     -1  SSTRAIT  38-2 FLIGHT TEST CAMPAIGN  1067  2023-01-03    2  6040000000   \n",
      "6      C213178  AEROTEC BLAGNAC  1905-10-13     226760  00017       3   1150      1496  1944-06-15 00:00:00  1944-06-15 00:00:00      9      1  SSTRAIT  38-2 FLIGHT TEST CAMPAIGN  1067  2023-01-03    2  6040000000   \n",
      "7      C223301  AEROTEC BLAGNAC  1905-10-14     226765  00017       3  20042      1672  1902-05-29 00:00:00  1902-05-29 00:00:00      9      1  EQUIPMT      PEINTURE OIL DEFECTOR  1634  2023-01-04    2  6011000000   \n",
      "8      C223521            NEHIA  1905-10-15   22002895  00315       3   1791      1374  1944-06-26 00:00:00  1944-06-26 00:00:00      9      1  EQUIPMT         STENCILS HDMASK115  1534  2022-12-20    2  6011000000   \n",
      "9      C223521            NEHIA  1905-10-16   22002895  00315       3   1791      1375  1944-06-26 00:00:00  1944-06-26 00:00:00      9      1  EQUIPMT         STENCILS HDMASK115  1534  2022-12-20    2  6011000000   \n",
      "10     C223521            NEHIA  1905-10-17   22002895  00315       3   1791      1379  1901-08-02 00:00:00  1901-08-02 00:00:00      9      1  EQUIPMT         STENCILS HDMASK115  1534  2022-12-20    2  6011000000   \n",
      "\n",
      "    datesaisie unite  coefunite codeemp i1cleunik  \n",
      "1   2023-01-02     u       True     IVI      <NA>  \n",
      "2   2023-01-12     u       True     AOD      <NA>  \n",
      "3   2023-01-12     u       True     AOD      <NA>  \n",
      "4   2023-01-12     u       True     AOD      <NA>  \n",
      "5   2023-01-12     u       True     AOD      <NA>  \n",
      "6   2023-01-12     u       True     AOD      <NA>  \n",
      "7   2023-01-12     u       True     AOD      <NA>  \n",
      "8   2023-01-12     u       True     AOD      <NA>  \n",
      "9   2023-01-12     u       True     AOD      <NA>  \n",
      "10  2023-01-12     u       True     AOD      <NA>  \n",
      "\n",
      "Done. Feuilles analysées: 2\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, unicodedata, warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# ============== CONFIG ==============\n",
    "FILE_PATH = r\"C:\\globasoft\\aerotech\\fic\\FNP AEC projets - source.xlsx\"\n",
    "SHOW_SAMPLE = True\n",
    "\n",
    "# ============== LOG ==============\n",
    "def now(): return datetime.now().strftime(\"%H:%M:%S\")\n",
    "def log(msg): print(f\"[{now()}] {msg}\", flush=True)\n",
    "\n",
    "# ============== UTILS ==============\n",
    "def strip_accents_lower(s):\n",
    "    if s is None or (isinstance(s, float) and pd.isna(s)): return \"\"\n",
    "    s = unicodedata.normalize(\"NFKD\", str(s))\n",
    "    s = \"\".join(c for c in s if not unicodedata.combining(c))\n",
    "    return s.lower().strip()\n",
    "\n",
    "def snake_id(s):\n",
    "    s = strip_accents_lower(s)\n",
    "    s = re.sub(r\"[\\s\\.\\-]+\", \"_\", s)\n",
    "    s = re.sub(r\"[^a-z0-9_]\", \"_\", s)\n",
    "    return re.sub(r\"_+\", \"_\", s).strip(\"_\") or \"col\"\n",
    "\n",
    "def parse_number_like(series: pd.Series) -> pd.Series:\n",
    "    x = series.astype(\"string\").str.replace(\"\\u00A0\",\" \", regex=False).str.replace(\" \",\"\", regex=False)\n",
    "    x = x.str.replace(r\"(?<=\\d)\\.(?=\\d{3}(?:\\D|$))\",\"\", regex=True)  # retire séparateurs de milliers\n",
    "    x = x.str.replace(\",\",\".\", regex=False)                          # virgule -> point\n",
    "    return pd.to_numeric(x, errors=\"coerce\")\n",
    "\n",
    "# ============== HEADER PICK + NORMALIZE ==============\n",
    "HEADER_HINTS = (\n",
    "    \"projet\",\"projets\",\"code\",\"id\",\"date\",\"mois\",\"année\",\"client\",\"fournisseur\",\"libelle\",\"libellé\",\n",
    "    \"montant\",\"quantite\",\"qté\",\"qte\",\"prix\",\"ttc\",\"ht\",\"statut\",\"status\",\"site\",\"type\",\"categorie\",\n",
    "    \"echeance\",\"échéance\",\"délai\",\"delai\",\"commentaire\",\"ref\",\"réf\"\n",
    ")\n",
    "\n",
    "def choose_header_row(df: pd.DataFrame, scan=25) -> int:\n",
    "    \"\"\"1) ligne contenant plusieurs mots-clés; 2) densité + présence de texte.\"\"\"\n",
    "    limit = min(len(df), scan)\n",
    "    cand_idx, cand_hits = None, -1\n",
    "    for i in range(limit):\n",
    "        row = df.iloc[i].astype(str)\n",
    "        hits = 0\n",
    "        for v in row:\n",
    "            t = strip_accents_lower(v)\n",
    "            if t and any(k in t for k in HEADER_HINTS):\n",
    "                hits += 1\n",
    "        if hits >= 2 and hits > cand_hits:\n",
    "            cand_idx, cand_hits = i, hits\n",
    "    if cand_idx is not None:\n",
    "        return cand_idx\n",
    "\n",
    "    best, idx = -1, 0\n",
    "    for i in range(limit):\n",
    "        row = df.iloc[i].astype(str)\n",
    "        non_empty = row.map(lambda x: x.strip()!=\"\").sum()\n",
    "        texty = row.map(lambda x: bool(re.search(r\"[A-Za-zÀ-ÿ]\", x))).sum()\n",
    "        score = non_empty*2 + texty\n",
    "        if score > best: best, idx = score, i\n",
    "    return idx\n",
    "\n",
    "def normalize_columns(header_vals):\n",
    "    cols, seen = [], {}\n",
    "    for v in header_vals:\n",
    "        s = snake_id(v) if (v is not None and str(v).strip()!=\"\") else \"col\"\n",
    "        seen[s] = seen.get(s,0)+1\n",
    "        cols.append(s if seen[s]==1 else f\"{s}_{seen[s]}\")\n",
    "    return cols\n",
    "\n",
    "def drop_empty_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.dropna(axis=1, how=\"all\")\n",
    "    blank_cols = [c for c in df.columns if df[c].dropna().astype(str).str.strip().eq(\"\").all()]\n",
    "    if blank_cols:\n",
    "        df = df.drop(columns=blank_cols)\n",
    "    return df\n",
    "\n",
    "# ============== INFÉRENCE TYPES (simple et robuste) ==============\n",
    "MAP_TRUE  = {\"true\",\"vrai\",\"oui\",\"yes\",\"1\",\"y\",\"o\"}\n",
    "MAP_FALSE = {\"false\",\"faux\",\"non\",\"no\",\"0\",\"n\"}\n",
    "\n",
    "DATE_TOKEN_RE = re.compile(\n",
    "    r\"(?:\\d{4}[-/\\.]\\d{1,2}[-/\\.]\\d{1,2})|(?:\\d{1,2}[-/\\.]\\d{1,2}[-/\\.]\\d{2,4})|\"\n",
    "    r\"(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec|janv|févr|fevr|avr|mai|juin|juil|sept|oct|nov|d[ée]c)\",\n",
    "    re.I\n",
    ")\n",
    "ISO_DATE_RE = re.compile(r\"^\\d{4}-\\d{2}-\\d{2}(?:[ T]\\d{2}:\\d{2}:\\d{2})?$\")\n",
    "COLNAME_DATE_HINTS = (\"date\",\"dt\",\"heure\",\"time\",\"echeance\",\"échéance\")\n",
    "\n",
    "def excel_serial_to_datetime(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Conversion sûre des numéros de date Excel -> datetime.\n",
    "    Fenêtre 'safe' contrainte à [60 .. 106750] jours:\n",
    "    - 60  ~ 1900-03-01\n",
    "    - 106750 ~ limite Timedelta pandas (~2173)\n",
    "    Tout ce qui est hors-fenêtre -> NaN AVANT conversion.\n",
    "    \"\"\"\n",
    "    vals = pd.to_numeric(series, errors=\"coerce\").astype(\"float64\")\n",
    "    vals[~np.isfinite(vals)] = np.nan\n",
    "\n",
    "    lower, upper = 60.0, 106750.0\n",
    "    mask = (vals >= lower) & (vals <= upper)\n",
    "    n_out = int((~mask & ~pd.isna(vals)).sum())\n",
    "    if n_out:\n",
    "        log(f\"[excel_serial_to_datetime] valeurs hors fenêtre [{int(lower)}, {int(upper)}] remplacées par NaN: {n_out}\")\n",
    "    vals = vals.where(mask, np.nan)\n",
    "\n",
    "    base = pd.Timestamp(\"1899-12-30\")\n",
    "    # conversion sûre (les NaN restent NaT)\n",
    "    td = pd.to_timedelta(vals, unit=\"D\", errors=\"coerce\")\n",
    "    dt = base + td\n",
    "    return pd.to_datetime(dt, errors=\"coerce\")\n",
    "\n",
    "def infer_col(col: pd.Series):\n",
    "    s = col.copy()\n",
    "    ss = s.astype(\"string\").str.strip()\n",
    "    ss = ss.where(~ss.fillna(\"\").eq(\"0\"), pd.NA)  # éviter 0 -> 1970-01-01\n",
    "\n",
    "    # 0) ISO direct\n",
    "    iso_mask = ss.fillna(\"\").str.match(ISO_DATE_RE)\n",
    "    if iso_mask.mean() >= 0.5:\n",
    "        dt_iso = pd.to_datetime(ss.where(iso_mask), errors=\"coerce\", dayfirst=False)\n",
    "        ok = dt_iso.notna().mean() if len(ss) else 0.0\n",
    "        if ok >= 0.5:\n",
    "            has_time = (dt_iso.dt.time.astype(str) != \"00:00:00\").mean() > 0.2\n",
    "            return (\n",
    "                dt_iso.dt.strftime(\"%Y-%m-%d %H:%M:%S\") if has_time else dt_iso.dt.strftime(\"%Y-%m-%d\"),\n",
    "                \"DATETIME\" if has_time else \"DATE\"\n",
    "            )\n",
    "\n",
    "    # 1) Excel serial plausibles (et majoritairement dans la fenêtre sûre)\n",
    "    as_num = pd.to_numeric(ss, errors=\"coerce\")\n",
    "    if len(ss):\n",
    "        safe_mask = (as_num >= 60) & (as_num <= 106750)\n",
    "        safe_ratio = safe_mask.mean()\n",
    "    else:\n",
    "        safe_ratio = 0.0\n",
    "\n",
    "    if (as_num.notna().mean() if len(ss) else 0.0) >= 0.9 and safe_ratio >= 0.7:\n",
    "        parsed = excel_serial_to_datetime(as_num)\n",
    "        ok = parsed.notna().mean() if len(ss) else 0.0\n",
    "        if ok >= 0.7:\n",
    "            has_time = (parsed.dt.time.astype(str) != \"00:00:00\").mean() > 0.2\n",
    "            return (\n",
    "                parsed.dt.strftime(\"%Y-%m-%d %H:%M:%S\") if has_time else parsed.dt.strftime(\"%Y-%m-%d\"),\n",
    "                \"DATETIME\" if has_time else \"DATE\"\n",
    "            )\n",
    "\n",
    "    # 2) tokens de date / nom “datey”\n",
    "    colname_hint = any(h in strip_accents_lower(s.name or \"\") for h in COLNAME_DATE_HINTS)\n",
    "    date_token_ratio = ss.fillna(\"\").str.contains(DATE_TOKEN_RE, na=False).mean()\n",
    "    looks_datey = colname_hint or (date_token_ratio >= 0.30)\n",
    "    if looks_datey:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", message=\"Could not infer format.*\", category=UserWarning)\n",
    "            dt1 = pd.to_datetime(ss, errors=\"coerce\", dayfirst=True,  cache=True)\n",
    "            dt2 = pd.to_datetime(ss, errors=\"coerce\", dayfirst=False, cache=True)\n",
    "        dt = dt2 if dt2.notna().sum() > dt1.notna().sum() else dt1\n",
    "        ok = dt.notna().mean() if len(ss) else 0.0\n",
    "        ok_thresh = 0.50 if colname_hint else 0.70\n",
    "        if ok >= ok_thresh:\n",
    "            has_time = (dt.dt.time.astype(str) != \"00:00:00\").mean() > 0.2\n",
    "            return (\n",
    "                pd.to_datetime(dt).dt.strftime(\"%Y-%m-%d %H:%M:%S\") if has_time else pd.to_datetime(dt).dt.strftime(\"%Y-%m-%d\"),\n",
    "                \"DATETIME\" if has_time else \"DATE\"\n",
    "            )\n",
    "\n",
    "    # 3) bool strict\n",
    "    mb = ss.str.lower().map(lambda x: True if x in MAP_TRUE else (False if x in MAP_FALSE else pd.NA))\n",
    "    if (mb.notna().mean() if len(ss) else 0) >= 0.98:\n",
    "        return mb.astype(\"boolean\"), \"BOOL\"\n",
    "\n",
    "    # 4) nombre\n",
    "    nums = parse_number_like(ss)\n",
    "    if (nums.notna().mean() if len(ss.dropna()) else 0) >= 0.85:\n",
    "        nz = nums.dropna()\n",
    "        if len(nz) and (np.mod(nz, 1) == 0).all():\n",
    "            return nums.astype(\"Int64\"), \"INT\"\n",
    "        return nums.astype(\"Float64\"), \"FLOAT\"\n",
    "\n",
    "    # 5) texte\n",
    "    return ss.astype(\"string\"), \"STRING\"\n",
    "\n",
    "def pg_type(tag: str) -> str:\n",
    "    return {\n",
    "        \"DATE\":\"date\",\"DATETIME\":\"timestamp without time zone\",\n",
    "        \"INT\":\"integer\",\"FLOAT\":\"double precision\",\"BOOL\":\"boolean\"\n",
    "    }.get(tag, \"text\")\n",
    "\n",
    "# ============== MAIN ==============\n",
    "def main():\n",
    "    xlsx = Path(FILE_PATH)\n",
    "    log(f\"Fichier: {xlsx}\")\n",
    "    if not xlsx.exists():\n",
    "        log(\"[error] Fichier introuvable\"); return\n",
    "\n",
    "    try:\n",
    "        sheets = pd.read_excel(xlsx, sheet_name=None, engine=\"openpyxl\", header=None)\n",
    "    except Exception as e:\n",
    "        log(f\"[error] Lecture échouée: {e}\"); return\n",
    "\n",
    "    done = 0\n",
    "    for name, raw in sheets.items():\n",
    "        log(f\"\\n[feuille] {name}: shape initiale={raw.shape}\")\n",
    "\n",
    "        # nettoyage vide\n",
    "        raw = raw.dropna(how=\"all\", axis=0).dropna(how=\"all\", axis=1)\n",
    "        log(f\"[feuille] {name}: après drop vides -> {raw.shape}\")\n",
    "        if raw.empty: \n",
    "            log(f\"[feuille] {name}: vide, on passe.\")\n",
    "            continue\n",
    "\n",
    "        # header + normalisation\n",
    "        h = choose_header_row(raw, scan=25)\n",
    "        log(f\"[feuille] {name}: header choisi à la ligne {h}\")\n",
    "        cols = normalize_columns(raw.iloc[h].tolist())\n",
    "        log(f\"[feuille] {name}: colonnes normalisées -> {', '.join(cols)}\")\n",
    "        df = raw.iloc[h+1:].copy()\n",
    "        df.columns = cols\n",
    "        df = df.dropna(how=\"all\")\n",
    "        df = drop_empty_columns(df)\n",
    "        log(f\"[feuille] {name}: shape après nettoyage colonnes -> {df.shape}\")\n",
    "        if df.empty:\n",
    "            log(f\"[feuille] {name}: vide après normalisation, on passe.\")\n",
    "            continue\n",
    "\n",
    "        # inférence types\n",
    "        schema = {}\n",
    "        for c in df.columns:\n",
    "            casted, tag = infer_col(df[c])\n",
    "            df[c] = casted\n",
    "            schema[c] = tag\n",
    "\n",
    "        base = f\"{snake_id(xlsx.stem)}.{snake_id(name)}\"\n",
    "        print(f\"\\n--- Feuille: {name} -> {base} ---\")\n",
    "        print(f\"rows={len(df)} | cols={df.shape[1]}\")\n",
    "        print(\"Colonnes:\", \", \".join(df.columns.astype(str)))\n",
    "        print(\"\\nSchema détecté:\")\n",
    "        for c in df.columns:\n",
    "            print(f\"  - {c}: {schema[c]}  ->  {pg_type(schema[c])}\")\n",
    "\n",
    "        if SHOW_SAMPLE:\n",
    "            with pd.option_context(\"display.max_columns\", 120, \"display.width\", 220):\n",
    "                print(\"\\nSample (top 10):\")\n",
    "                print(df.head(10))\n",
    "\n",
    "        done += 1\n",
    "\n",
    "    print(f\"\\nDone. Feuilles analysées: {done}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b778bf4-a237-4cae-be16-be2ab9c4947d",
   "metadata": {},
   "source": [
    "# Projets AEC AE 2025 - source.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3747a9f-d754-44af-ab95-2abb51be1267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:45:14] Fichier: C:\\globasoft\\aerotech\\fic\\FNP AEC projets - source.xlsx\n",
      "[15:45:15] [ok] Connecté PostgreSQL\n",
      "[15:45:15] PostgreSQL 17.6 (Debian 17.6-1.pgdg12+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14+deb12u1) 12.2.0, 64-bit\n",
      "[15:45:15] \n",
      "[feuille] FNP achats: shape initiale=(1417, 23)\n",
      "[15:45:15] [feuille] FNP achats: après drop vides -> (1417, 23)\n",
      "[15:45:15] [feuille] FNP achats: header choisi à la ligne 0\n",
      "[15:45:15] [feuille] FNP achats: colonnes normalisées -> periode, fournisseur_interne_externe, fournisseurs, code_projets, libelle_commande, type, n_cmd_aec, cdp, n_cmd_frs_date_cmd, montant_commande_ht, factures_recues, fact_recues, factures_non_recues, avancement_sur_factu_non_recues, montant_fnp, commentaires, compte_tiers, compte_charges, soumis_non_soumis, tva, reste, client_interne, section_analytique\n",
      "[15:45:15] [feuille] FNP achats: shape après nettoyage colonnes -> (1416, 23)\n",
      "\n",
      "--- Feuille: FNP achats -> public.fnp_aec_projets_source__fnp_achats ---\n",
      "rows=1416 | cols=23\n",
      "Colonnes: periode, fournisseur_interne_externe, fournisseurs, code_projets, libelle_commande, type, n_cmd_aec, cdp, n_cmd_frs_date_cmd, montant_commande_ht, factures_recues, fact_recues, factures_non_recues, avancement_sur_factu_non_recues, montant_fnp, commentaires, compte_tiers, compte_charges, soumis_non_soumis, tva, reste, client_interne, section_analytique\n",
      "\n",
      "Schema détecté:\n",
      "  - periode: DATE -> Date\n",
      "  - fournisseur_interne_externe: STRING -> Text\n",
      "  - fournisseurs: STRING -> Text\n",
      "  - code_projets: STRING -> Text\n",
      "  - libelle_commande: STRING -> Text\n",
      "  - type: STRING -> Text\n",
      "  - n_cmd_aec: DATE -> Date\n",
      "  - cdp: STRING -> Text\n",
      "  - n_cmd_frs_date_cmd: DATE -> Date\n",
      "  - montant_commande_ht: DATETIME -> DateTime\n",
      "  - factures_recues: STRING -> Text\n",
      "  - fact_recues: STRING -> Text\n",
      "  - factures_non_recues: STRING -> Text\n",
      "  - avancement_sur_factu_non_recues: FLOAT -> Float\n",
      "  - montant_fnp: STRING -> Text\n",
      "  - commentaires: STRING -> Text\n",
      "  - compte_tiers: STRING -> Text\n",
      "  - compte_charges: STRING -> Text\n",
      "  - soumis_non_soumis: STRING -> Text\n",
      "  - tva: STRING -> Text\n",
      "  - reste: STRING -> Text\n",
      "  - client_interne: DATE -> Date\n",
      "  - section_analytique: STRING -> Text\n",
      "\n",
      "Sample (top 10):\n",
      "      periode fournisseur_interne_externe                            fournisseurs code_projets              libelle_commande             type  n_cmd_aec      cdp n_cmd_frs_date_cmd montant_commande_ht  \\\n",
      "1  2024-01-30                     Externe                           L3 WESCAM USA      C191893                   camera MX15       S/T France 1900-08-01      BAZ                NaT                 NaT   \n",
      "2  2024-01-30                     Externe                AEROPORT CASTRES MAZAMET      C192026      REDEVANCES AERONAUTIQUES       S/T France 1905-05-10      PRO         2023-08-30 1900-07-10 02:52:48   \n",
      "3  2024-01-30                     Externe                      MOUSER ELECTRONICS      C192195       Connecteurs d’éclairage  Matériel France 1903-12-03      JFA         2022-09-06                 NaT   \n",
      "4  2024-01-30                     Externe  PROFESSIONAL & BROADCAST SERVICE - PBS      C192195                       KIL1/E1  Matériel France 1904-04-16      TBI         2022-11-17                 NaT   \n",
      "5  2024-01-30                     Externe                                   CIPEM      C192195  CLAVIER IK-TR-911-RED USB-US       S/T France 1905-07-20      JFA         2023-10-30 1901-08-15 00:00:00   \n",
      "6  2024-01-30                     Externe                                   NEHIA      C202695       PREDECOUPES HD MASK 115       S/T France 1904-11-30      MSU         2023-04-27 1900-08-19 00:00:00   \n",
      "7  2024-01-30                     Externe                                 TENCATE      C202695     FABRICATION PANNEAU PORTE       S/T France 1904-12-06      MSU         2023-05-04 1907-04-13 00:00:00   \n",
      "8  2024-01-30                     Externe                                LOGO SKY      C202695              MATERIAL 3M 6900  Matériel France 1905-11-01  SRE/MSU         2023-12-20                 NaT   \n",
      "9  2024-01-30                     Externe                                   ZELIN      C212808                multiples lots       S/T France 1902-12-16      TBI         2022-02-21 1933-12-27 00:00:00   \n",
      "10 2024-01-30                     Externe                           BDEX AVIATION      C212809                         DOCHD   Matériel Monde 1903-05-13      TBI         2022-05-17 1901-02-28 00:00:00   \n",
      "\n",
      "       factures_recues         fact_recues factures_non_recues  avancement_sur_factu_non_recues        montant_fnp                       commentaires compte_tiers compte_charges soumis_non_soumis                 tva  \\\n",
      "1   2035920.4000000001  0.9654671614945716   72820.82000000007                              1.0  72820.82000000007                               <NA>   4081010000     6040000000            Soumis  14564.164000000013   \n",
      "2                 <NA>                <NA>              192.12                              1.0             192.12                               <NA>   4081010000     6040000000            Soumis   38.42400000000001   \n",
      "3                29.86                   1                <NA>                              1.0               <NA>  s48.23 : mail pour maj statut JFA   4081010000     6010000000            Soumis                <NA>   \n",
      "4                 <NA>                   1                <NA>                              1.0               <NA>  s48.23 : mail pour maj statut JFA   4081010000     6010000000            Soumis                <NA>   \n",
      "5                 <NA>                <NA>                 593                              1.0                593                               <NA>   4081010000     6040000000            Soumis  118.60000000000001   \n",
      "6                 <NA>                <NA>                 232                              1.0                232                               <NA>   4081010000     6040000000            Soumis  46.400000000000006   \n",
      "7                 <NA>                <NA>                2660                              1.0               2660                               <NA>   4081010000     6040000000            Soumis                 532   \n",
      "8                 <NA>                <NA>                  44                              1.0                 44                               <NA>   4081010000     6010000000            Soumis                 8.8   \n",
      "9                 9915  0.7986306886830447                2500                              1.0               2500                     mail TBI 31/05   4081010000     6040000000            Soumis                 500   \n",
      "10                <NA>                <NA>                 425                              1.0                425                               <NA>   4081010000     6010000000        Non soumis                <NA>   \n",
      "\n",
      "   reste client_interne       section_analytique  \n",
      "1   <NA>     1902-09-25  AEC-999-DCS-C191893-21J  \n",
      "2   <NA>     1902-09-25  AEC-999-DCS-C192026-21J  \n",
      "3   <NA>     1902-09-25  AEC-999-DCS-C192195-21J  \n",
      "4   <NA>     1902-09-25  AEC-999-DCS-C192195-21J  \n",
      "5   <NA>     1902-09-25  AEC-999-DCS-C192195-21J  \n",
      "6   <NA>     1902-09-25  AEC-999-DCS-C202695-21J  \n",
      "7   <NA>     1902-09-25  AEC-999-DCS-C202695-21J  \n",
      "8   <NA>     1902-09-25  AEC-999-DCS-C202695-21J  \n",
      "9   <NA>     1902-09-25  AEC-999-DCS-C212808-21J  \n",
      "10  <NA>     1902-09-25  AEC-999-DCS-C212809-21J  \n",
      "[15:45:18] [ok] Inserted into public.fnp_aec_projets_source__fnp_achats\n",
      "[15:45:18] \n",
      "[feuille] Feuil3: shape initiale=(128, 24)\n",
      "[15:45:18] [feuille] Feuil3: après drop vides -> (128, 24)\n",
      "[15:45:18] [feuille] Feuil3: header choisi à la ligne 0\n",
      "[15:45:18] [feuille] Feuil3: colonnes normalisées -> code_projet, fournisseur, ffcleunik, nofact, cofou, typebc, naf, lbcleunik, prix, prixmon, comon, qtefa, cofa, desa1, cobc, daterec, tva, compt, analytiq, datesaisie, unite, coefunite, codeemp, i1cleunik\n",
      "[15:45:18] [feuille] Feuil3: shape après nettoyage colonnes -> (127, 23)\n",
      "\n",
      "--- Feuille: Feuil3 -> public.fnp_aec_projets_source__feuil3 ---\n",
      "rows=127 | cols=23\n",
      "Colonnes: code_projet, fournisseur, ffcleunik, nofact, cofou, typebc, naf, lbcleunik, prix, prixmon, comon, qtefa, cofa, desa1, cobc, daterec, tva, compt, datesaisie, unite, coefunite, codeemp, i1cleunik\n",
      "\n",
      "Schema détecté:\n",
      "  - code_projet: STRING -> Text\n",
      "  - fournisseur: STRING -> Text\n",
      "  - ffcleunik: DATE -> Date\n",
      "  - nofact: STRING -> Text\n",
      "  - cofou: STRING -> Text\n",
      "  - typebc: INT -> Integer\n",
      "  - naf: INT -> Integer\n",
      "  - lbcleunik: STRING -> Text\n",
      "  - prix: DATETIME -> DateTime\n",
      "  - prixmon: DATETIME -> DateTime\n",
      "  - comon: INT -> Integer\n",
      "  - qtefa: INT -> Integer\n",
      "  - cofa: STRING -> Text\n",
      "  - desa1: STRING -> Text\n",
      "  - cobc: STRING -> Text\n",
      "  - daterec: DATE -> Date\n",
      "  - tva: INT -> Integer\n",
      "  - compt: INT -> Integer\n",
      "  - datesaisie: DATE -> Date\n",
      "  - unite: STRING -> Text\n",
      "  - coefunite: BOOL -> Boolean\n",
      "  - codeemp: STRING -> Text\n",
      "  - i1cleunik: STRING -> Text\n",
      "\n",
      "Sample (top 10):\n",
      "   code_projet      fournisseur  ffcleunik     nofact  cofou  typebc    naf lbcleunik                          prix             prixmon  comon  qtefa     cofa                      desa1  cobc    daterec  tva  \\\n",
      "1      C213178  AEROTEC BLAGNAC 1905-10-08    2262023  00017       3   1945      1518                           NaT                 NaT      9      1  EQUIPMT                C213178-089  1580 2023-01-02    2   \n",
      "2      C202695  SURUGUE MICKAEL 1905-10-09  NDF23-006    MSU       3   1216      <NA> 1900-04-13 20:24:00.000000000 1900-04-13 20:24:00      9      1  MISSION  A/R GRAULHET 15/12/22 PC6  <NA> 2023-01-04    2   \n",
      "3      C202695  SURUGUE MICKAEL 1905-10-10  NDF23-007    MSU       3   1216      <NA> 1900-04-13 20:24:00.000000000 1900-04-13 20:24:00      9      1  MISSION  A/R GRAULHET 05/01/23 PC6  <NA> 2023-01-06    2   \n",
      "4      C212810           AVALEX 1905-10-11      46504  00194       3    697        44 1920-04-17 23:16:48.000000025 1921-10-06 00:00:00      6      1  EQUIPMT    \"17.3\"\" HD WIDESCREEN,\"   229 2022-12-22    2   \n",
      "5      C213178  AEROTEC BLAGNAC 1905-10-12     226759  00017       3   1150       322                           NaT                 NaT      9     -1  SSTRAIT  38-2 FLIGHT TEST CAMPAIGN  1067 2023-01-03    2   \n",
      "6      C213178  AEROTEC BLAGNAC 1905-10-13     226760  00017       3   1150      1496 1944-06-15 00:00:00.000000000 1944-06-15 00:00:00      9      1  SSTRAIT  38-2 FLIGHT TEST CAMPAIGN  1067 2023-01-03    2   \n",
      "7      C223301  AEROTEC BLAGNAC 1905-10-14     226765  00017       3  20042      1672 1902-05-29 00:00:00.000000000 1902-05-29 00:00:00      9      1  EQUIPMT      PEINTURE OIL DEFECTOR  1634 2023-01-04    2   \n",
      "8      C223521            NEHIA 1905-10-15   22002895  00315       3   1791      1374 1944-06-26 00:00:00.000000000 1944-06-26 00:00:00      9      1  EQUIPMT         STENCILS HDMASK115  1534 2022-12-20    2   \n",
      "9      C223521            NEHIA 1905-10-16   22002895  00315       3   1791      1375 1944-06-26 00:00:00.000000000 1944-06-26 00:00:00      9      1  EQUIPMT         STENCILS HDMASK115  1534 2022-12-20    2   \n",
      "10     C223521            NEHIA 1905-10-17   22002895  00315       3   1791      1379 1901-08-02 00:00:00.000000000 1901-08-02 00:00:00      9      1  EQUIPMT         STENCILS HDMASK115  1534 2022-12-20    2   \n",
      "\n",
      "         compt datesaisie unite  coefunite codeemp i1cleunik  \n",
      "1   6011000000 2023-01-02     u       True     IVI      <NA>  \n",
      "2   6256000000 2023-01-12     u       True     AOD      <NA>  \n",
      "3   6256000000 2023-01-12     u       True     AOD      <NA>  \n",
      "4   6011000000 2023-01-12     u       True     AOD      <NA>  \n",
      "5   6040000000 2023-01-12     u       True     AOD      <NA>  \n",
      "6   6040000000 2023-01-12     u       True     AOD      <NA>  \n",
      "7   6011000000 2023-01-12     u       True     AOD      <NA>  \n",
      "8   6011000000 2023-01-12     u       True     AOD      <NA>  \n",
      "9   6011000000 2023-01-12     u       True     AOD      <NA>  \n",
      "10  6011000000 2023-01-12     u       True     AOD      <NA>  \n",
      "[15:45:18] [error] Échec insertion public.fnp_aec_projets_source__feuil3: (psycopg2.errors.NumericValueOutOfRange) integer out of range\n",
      "\n",
      "[SQL: INSERT INTO public.fnp_aec_projets_source__feuil3 (code_projet, fournisseur, ffcleunik, nofact, cofou, typebc, naf, lbcleunik, prix, prixmon, comon, qtefa, cofa, desa1, cobc, daterec, tva, compt, datesaisie, unite, coefunite, codeemp, i1cleunik) VALUES (%(code_projet_m0)s, %(fournisseur_m0)s, %(ffcleunik_m0)s, %(nofact_m0)s, %(cofou_m0)s, %(typebc_m0)s, %(naf_m0)s, %(lbcleunik_m0)s, %(prix_m0)s, %(prixmon_m0)s, %(comon_m0)s, %(qtefa_m0)s, %(cofa_m0)s, %(desa1_m0)s, %(cobc_m0)s, %(daterec_m0)s, %(tva_m0)s, %(compt_m0)s, %(datesaisie_m0)s, %(unite_m0)s, %(coefunite_m0)s, %(codeemp_m0)s, %(i1cleunik_m0)s), (%(code_projet_m1)s, %(fournisseur_m1)s, %(ffcleunik_m1)s, %(nofact_m1)s, %(cofou_m1)s, %(typebc_m1)s, %(naf_m1)s, %(lbcleunik_m1)s, %(prix_m1)s, %(prixmon_m1)s, %(comon_m1)s, %(qtefa_m1)s, %(cofa_m1)s, %(desa1_m1)s, %(cobc_m1)s, %(daterec_m1)s, %(tva_m1)s, %(compt_m1)s, %(datesaisie_m1)s, %(unite_m1)s, %(coefunite_m1)s, %(codeemp_m1)s, %(i1cleunik_m1)s), (%(code_projet_m2)s, %(fournisseur_m2)s, %(ffcleunik_m2)s, %(nofact_m2)s, %(cofou_m2)s, %(typebc_m2)s, %(naf_m2)s, %(lbcleunik_m2)s, %(prix_m2)s, %(prixmon_m2)s, %(comon_m2)s, %(qtefa_m2)s, %(cofa_m2)s, %(desa1_m2)s, %(cobc_m2)s, %(daterec_m2)s, %(tva_m2)s, %(compt_m2)s, %(datesaisie_m2)s, %(unite_m2)s, %(coefunite_m2)s, %(codeemp_m2)s, %(i1cleunik_m2)s), (%(code_projet_m3)s, %(fournisseur_m3)s, %(ffcleunik_m3)s, %(nofact_m3)s, %(cofou_m3)s, %(typebc_m3)s, %(naf_m3)s, %(lbcleunik_m3)s, %(prix_m3)s, %(prixmon_m3)s, %(comon_m3)s, %(qtefa_m3)s, %(cofa_m3)s, %(desa1_m3)s, %(cobc_m3)s, %(daterec_m3)s, %(tva_m3)s, %(compt_m3)s, %(datesaisie_m3)s, %(unite_m3)s, %(coefunite_m3)s, %(codeemp_m3)s, %(i1cleunik_m3)s), (%(code_projet_m4)s, %(fournisseur_m4)s, %(ffcleunik_m4)s, %(nofact_m4)s, %(cofou_m4)s, %(typebc_m4)s, %(naf_m4)s, %(lbcleunik_m4)s, %(prix_m4)s, %(prixmon_m4)s, %(comon_m4)s, %(qtefa_m4)s, %(cofa_m4)s, %(desa1_m4)s, %(cobc_m4)s, %(daterec_m4)s, %(tva_m4)s, %(compt_m4)s, %(datesaisie_m4)s, %(unite_m4)s, %(coefunite_m4)s, %(codeemp_m4)s, %(i1cleunik_m4)s), (%(code_projet_m5)s, %(fournisseur_m5)s, %(ffcleunik_m5)s, %(nofact_m5)s, %(cofou_m5)s, %(typebc_m5)s, %(naf_m5)s, %(lbcleunik_m5)s, %(prix_m5)s, %(prixmon_m5)s, %(comon_m5)s, %(qtefa_m5)s, %(cofa_m5)s, %(desa1_m5)s, %(cobc_m5)s, %(daterec_m5)s, %(tva_m5)s, %(compt_m5)s, %(datesaisie_m5)s, %(unite_m5)s, %(coefunite_m5)s, %(codeemp_m5)s, %(i1cleunik_m5)s), (%(code_projet_m6)s, %(fournisseur_m6)s, %(ffcleunik_m6)s, %(nofact_m6)s, %(cofou_m6)s, %(typebc_m6)s, %(naf_m6)s, %(lbcleunik_m6)s, %(prix_m6)s, %(prixmon_m6)s, %(comon_m6)s, %(qtefa_m6)s, %(cofa_m6)s, %(desa1_m6)s, %(cobc_m6)s, %(daterec_m6)s, %(tva_m6)s, %(compt_m6)s, %(datesaisie_m6)s, %(unite_m6)s, %(coefunite_m6)s, %(codeemp_m6)s, %(i1cleunik_m6)s), (%(code_projet_m7)s, %(fournisseur_m7)s, %(ffcleunik_m7)s, %(nofact_m7)s, %(cofou_m7)s, %(typebc_m7)s, %(naf_m7)s, %(lbcleunik_m7)s, %(prix_m7)s, %(prixmon_m7)s, %(comon_m7)s, %(qtefa_m7)s, %(cofa_m7)s, %(desa1_m7)s, %(cobc_m7)s, %(daterec_m7)s, %(tva_m7)s, %(compt_m7)s, %(datesaisie_m7)s, %(unite_m7)s, %(coefunite_m7)s, %(codeemp_m7)s, %(i1cleunik_m7)s), (%(code_projet_m8)s, %(fournisseur_m8)s, %(ffcleunik_m8)s, %(nofact_m8)s, %(cofou_m8)s, %(typebc_m8)s, %(naf_m8)s, %(lbcleunik_m8)s, %(prix_m8)s, %(prixmon_m8)s, %(comon_m8)s, %(qtefa_m8)s, %(cofa_m8)s, %(desa1_m8)s, %(cobc_m8)s, %(daterec_m8)s, %(tva_m8)s, %(compt_m8)s, %(datesaisie_m8)s, %(unite_m8)s, %(coefunite_m8)s, %(codeemp_m8)s, %(i1cleunik_m8)s), (%(code_projet_m9)s, %(fournisseur_m9)s, %(ffcleunik_m9)s, %(nofact_m9)s, %(cofou_m9)s, %(typebc_m9)s, %(naf_m9)s, %(lbcleunik_m9)s, %(prix_m9)s, %(prixmon_m9)s, %(comon_m9)s, %(qtefa_m9)s, %(cofa_m9)s, %(desa1_m9)s, %(cobc_m9)s, %(daterec_m9)s, %(tva_m9)s, %(compt_m9)s, %(datesaisie_m9)s, %(unite_m9)s, %(coefunite_m9)s, %(codeemp_m9)s, %(i1cleunik_m9)s), (%(code_projet_m10)s, %(fournisseur_m10)s, %(ffcleunik_m10)s, %(nofact_m10)s, %(cofou_m10)s, %(typebc_m10)s, %(naf_m10)s, %(lbcleunik_m10)s, %(prix_m10)s, %(prixmon_m10)s, %(comon_m10)s, %(qtefa_m10)s, %(cofa_m10)s, %(desa1_m10)s, %(cobc_m10)s, %(daterec_m10)s, %(tva_m10)s, %(compt_m10)s, %(datesaisie_m10)s, %(unite_m10)s, %(coefunite_m10)s, %(codeemp_m10)s, %(i1cleunik_m10)s), (%(code_projet_m11)s, %(fournisseur_m11)s, %(ffcleunik_m11)s, %(nofact_m11)s, %(cofou_m11)s, %(typebc_m11)s, %(naf_m11)s, %(lbcleunik_m11)s, %(prix_m11)s, %(prixmon_m11)s, %(comon_m11)s, %(qtefa_m11)s, %(cofa_m11)s, %(desa1_m11)s, %(cobc_m11)s, %(daterec_m11)s, %(tva_m11)s, %(compt_m11)s, %(datesaisie_m11)s, %(unite_m11)s, %(coefunite_m11)s, %(codeemp_m11)s, %(i1cleunik_m11)s), (%(code_projet_m12)s, %(fournisseur_m12)s, %(ffcleunik_m12)s, %(nofact_m12)s, %(cofou_m12)s, %(typebc_m12)s, %(naf_m12)s, %(lbcleunik_m12)s, %(prix_m12)s, %(prixmon_m12)s, %(comon_m12)s, %(qtefa_m12)s, %(cofa_m12)s, %(desa1_m12)s, %(cobc_m12)s, %(daterec_m12)s, %(tva_m12)s, %(compt_m12)s, %(datesaisie_m12)s, %(unite_m12)s, %(coefunite_m12)s, %(codeemp_m12)s, %(i1cleunik_m12)s), (%(code_projet_m13)s, %(fournisseur_m13)s, %(ffcleunik_m13)s, %(nofact_m13)s, %(cofou_m13)s, %(typebc_m13)s, %(naf_m13)s, %(lbcleunik_m13)s, %(prix_m13)s, %(prixmon_m13)s, %(comon_m13)s, %(qtefa_m13)s, %(cofa_m13)s, %(desa1_m13)s, %(cobc_m13)s, %(daterec_m13)s, %(tva_m13)s, %(compt_m13)s, %(datesaisie_m13)s, %(unite_m13)s, %(coefunite_m13)s, %(codeemp_m13)s, %(i1cleunik_m13)s), (%(code_projet_m14)s, %(fournisseur_m14)s, %(ffcleunik_m14)s, %(nofact_m14)s, %(cofou_m14)s, %(typebc_m14)s, %(naf_m14)s, %(lbcleunik_m14)s, %(prix_m14)s, %(prixmon_m14)s, %(comon_m14)s, %(qtefa_m14)s, %(cofa_m14)s, %(desa1_m14)s, %(cobc_m14)s, %(daterec_m14)s, %(tva_m14)s, %(compt_m14)s, %(datesaisie_m14)s, %(unite_m14)s, %(coefunite_m14)s, %(codeemp_m14)s, %(i1cleunik_m14)s), (%(code_projet_m15)s, %(fournisseur_m15)s, %(ffcleunik_m15)s, %(nofact_m15)s, %(cofou_m15)s, %(typebc_m15)s, %(naf_m15)s, %(lbcleunik_m15)s, %(prix_m15)s, %(prixmon_m15)s, %(comon_m15)s, %(qtefa_m15)s, %(cofa_m15)s, %(desa1_m15)s, %(cobc_m15)s, %(daterec_m15)s, %(tva_m15)s, %(compt_m15)s, %(datesaisie_m15)s, %(unite_m15)s, %(coefunite_m15)s, %(codeemp_m15)s, %(i1cleunik_m15)s), (%(code_projet_m16)s, %(fournisseur_m16)s, %(ffcleunik_m16)s, %(nofact_m16)s, %(cofou_m16)s, %(typebc_m16)s, %(naf_m16)s, %(lbcleunik_m16)s, %(prix_m16)s, %(prixmon_m16)s, %(comon_m16)s, %(qtefa_m16)s, %(cofa_m16)s, %(desa1_m16)s, %(cobc_m16)s, %(daterec_m16)s, %(tva_m16)s, %(compt_m16)s, %(datesaisie_m16)s, %(unite_m16)s, %(coefunite_m16)s, %(codeemp_m16)s, %(i1cleunik_m16)s), (%(code_projet_m17)s, %(fournisseur_m17)s, %(ffcleunik_m17)s, %(nofact_m17)s, %(cofou_m17)s, %(typebc_m17)s, %(naf_m17)s, %(lbcleunik_m17)s, %(prix_m17)s, %(prixmon_m17)s, %(comon_m17)s, %(qtefa_m17)s, %(cofa_m17)s, %(desa1_m17)s, %(cobc_m17)s, %(daterec_m17)s, %(tva_m17)s, %(compt_m17)s, %(datesaisie_m17)s, %(unite_m17)s, %(coefunite_m17)s, %(codeemp_m17)s, %(i1cleunik_m17)s), (%(code_projet_m18)s, %(fournisseur_m18)s, %(ffcleunik_m18)s, %(nofact_m18)s, %(cofou_m18)s, %(typebc_m18)s, %(naf_m18)s, %(lbcleunik_m18)s, %(prix_m18)s, %(prixmon_m18)s, %(comon_m18)s, %(qtefa_m18)s, %(cofa_m18)s, %(desa1_m18)s, %(cobc_m18)s, %(daterec_m18)s, %(tva_m18)s, %(compt_m18)s, %(datesaisie_m18)s, %(unite_m18)s, %(coefunite_m18)s, %(codeemp_m18)s, %(i1cleunik_m18)s), (%(code_projet_m19)s, %(fournisseur_m19)s, %(ffcleunik_m19)s, %(nofact_m19)s, %(cofou_m19)s, %(typebc_m19)s, %(naf_m19)s, %(lbcleunik_m19)s, %(prix_m19)s, %(prixmon_m19)s, %(comon_m19)s, %(qtefa_m19)s, %(cofa_m19)s, %(desa1_m19)s, %(cobc_m19)s, %(daterec_m19)s, %(tva_m19)s, %(compt_m19)s, %(datesaisie_m19)s, %(unite_m19)s, %(coefunite_m19)s, %(codeemp_m19)s, %(i1cleunik_m19)s), (%(code_projet_m20)s, %(fournisseur_m20)s, %(ffcleunik_m20)s, %(nofact_m20)s, %(cofou_m20)s, %(typebc_m20)s, %(naf_m20)s, %(lbcleunik_m20)s, %(prix_m20)s, %(prixmon_m20)s, %(comon_m20)s, %(qtefa_m20)s, %(cofa_m20)s, %(desa1_m20)s, %(cobc_m20)s, %(daterec_m20)s, %(tva_m20)s, %(compt_m20)s, %(datesaisie_m20)s, %(unite_m20)s, %(coefunite_m20)s, %(codeemp_m20)s, %(i1cleunik_m20)s), (%(code_projet_m21)s, %(fournisseur_m21)s, %(ffcleunik_m21)s, %(nofact_m21)s, %(cofou_m21)s, %(typebc_m21)s, %(naf_m21)s, %(lbcleunik_m21)s, %(prix_m21)s, %(prixmon_m21)s, %(comon_m21)s, %(qtefa_m21)s, %(cofa_m21)s, %(desa1_m21)s, %(cobc_m21)s, %(daterec_m21)s, %(tva_m21)s, %(compt_m21)s, %(datesaisie_m21)s, %(unite_m21)s, %(coefunite_m21)s, %(codeemp_m21)s, %(i1cleunik_m21)s), (%(code_projet_m22)s, %(fournisseur_m22)s, %(ffcleunik_m22)s, %(nofact_m22)s, %(cofou_m22)s, %(typebc_m22)s, %(naf_m22)s, %(lbcleunik_m22)s, %(prix_m22)s, %(prixmon_m22)s, %(comon_m22)s, %(qtefa_m22)s, %(cofa_m22)s, %(desa1_m22)s, %(cobc_m22)s, %(daterec_m22)s, %(tva_m22)s, %(compt_m22)s, %(datesaisie_m22)s, %(unite_m22)s, %(coefunite_m22)s, %(codeemp_m22)s, %(i1cleunik_m22)s), (%(code_projet_m23)s, %(fournisseur_m23)s, %(ffcleunik_m23)s, %(nofact_m23)s, %(cofou_m23)s, %(typebc_m23)s, %(naf_m23)s, %(lbcleunik_m23)s, %(prix_m23)s, %(prixmon_m23)s, %(comon_m23)s, %(qtefa_m23)s, %(cofa_m23)s, %(desa1_m23)s, %(cobc_m23)s, %(daterec_m23)s, %(tva_m23)s, %(compt_m23)s, %(datesaisie_m23)s, %(unite_m23)s, %(coefunite_m23)s, %(codeemp_m23)s, %(i1cleunik_m23)s), (%(code_projet_m24)s, %(fournisseur_m24)s, %(ffcleunik_m24)s, %(nofact_m24)s, %(cofou_m24)s, %(typebc_m24)s, %(naf_m24)s, %(lbcleunik_m24)s, %(prix_m24)s, %(prixmon_m24)s, %(comon_m24)s, %(qtefa_m24)s, %(cofa_m24)s, %(desa1_m24)s, %(cobc_m24)s, %(daterec_m24)s, %(tva_m24)s, %(compt_m24)s, %(datesaisie_m24)s, %(unite_m24)s, %(coefunite_m24)s, %(codeemp_m24)s, %(i1cleunik_m24)s), (%(code_projet_m25)s, %(fournisseur_m25)s, %(ffcleunik_m25)s, %(nofact_m25)s, %(cofou_m25)s, %(typebc_m25)s, %(naf_m25)s, %(lbcleunik_m25)s, %(prix_m25)s, %(prixmon_m25)s, %(comon_m25)s, %(qtefa_m25)s, %(cofa_m25)s, %(desa1_m25)s, %(cobc_m25)s, %(daterec_m25)s, %(tva_m25)s, %(compt_m25)s, %(datesaisie_m25)s, %(unite_m25)s, %(coefunite_m25)s, %(codeemp_m25)s, %(i1cleunik_m25)s), (%(code_projet_m26)s, %(fournisseur_m26)s, %(ffcleunik_m26)s, %(nofact_m26)s, %(cofou_m26)s, %(typebc_m26)s, %(naf_m26)s, %(lbcleunik_m26)s, %(prix_m26)s, %(prixmon_m26)s, %(comon_m26)s, %(qtefa_m26)s, %(cofa_m26)s, %(desa1_m26)s, %(cobc_m26)s, %(daterec_m26)s, %(tva_m26)s, %(compt_m26)s, %(datesaisie_m26)s, %(unite_m26)s, %(coefunite_m26)s, %(codeemp_m26)s, %(i1cleunik_m26)s), (%(code_projet_m27)s, %(fournisseur_m27)s, %(ffcleunik_m27)s, %(nofact_m27)s, %(cofou_m27)s, %(typebc_m27)s, %(naf_m27)s, %(lbcleunik_m27)s, %(prix_m27)s, %(prixmon_m27)s, %(comon_m27)s, %(qtefa_m27)s, %(cofa_m27)s, %(desa1_m27)s, %(cobc_m27)s, %(daterec_m27)s, %(tva_m27)s, %(compt_m27)s, %(datesaisie_m27)s, %(unite_m27)s, %(coefunite_m27)s, %(codeemp_m27)s, %(i1cleunik_m27)s), (%(code_projet_m28)s, %(fournisseur_m28)s, %(ffcleunik_m28)s, %(nofact_m28)s, %(cofou_m28)s, %(typebc_m28)s, %(naf_m28)s, %(lbcleunik_m28)s, %(prix_m28)s, %(prixmon_m28)s, %(comon_m28)s, %(qtefa_m28)s, %(cofa_m28)s, %(desa1_m28)s, %(cobc_m28)s, %(daterec_m28)s, %(tva_m28)s, %(compt_m28)s, %(datesaisie_m28)s, %(unite_m28)s, %(coefunite_m28)s, %(codeemp_m28)s, %(i1cleunik_m28)s), (%(code_projet_m29)s, %(fournisseur_m29)s, %(ffcleunik_m29)s, %(nofact_m29)s, %(cofou_m29)s, %(typebc_m29)s, %(naf_m29)s, %(lbcleunik_m29)s, %(prix_m29)s, %(prixmon_m29)s, %(comon_m29)s, %(qtefa_m29)s, %(cofa_m29)s, %(desa1_m29)s, %(cobc_m29)s, %(daterec_m29)s, %(tva_m29)s, %(compt_m29)s, %(datesaisie_m29)s, %(unite_m29)s, %(coefunite_m29)s, %(codeemp_m29)s, %(i1cleunik_m29)s), (%(code_projet_m30)s, %(fournisseur_m30)s, %(ffcleunik_m30)s, %(nofact_m30)s, %(cofou_m30)s, %(typebc_m30)s, %(naf_m30)s, %(lbcleunik_m30)s, %(prix_m30)s, %(prixmon_m30)s, %(comon_m30)s, %(qtefa_m30)s, %(cofa_m30)s, %(desa1_m30)s, %(cobc_m30)s, %(daterec_m30)s, %(tva_m30)s, %(compt_m30)s, %(datesaisie_m30)s, %(unite_m30)s, %(coefunite_m30)s, %(codeemp_m30)s, %(i1cleunik_m30)s), (%(code_projet_m31)s, %(fournisseur_m31)s, %(ffcleunik_m31)s, %(nofact_m31)s, %(cofou_m31)s, %(typebc_m31)s, %(naf_m31)s, %(lbcleunik_m31)s, %(prix_m31)s, %(prixmon_m31)s, %(comon_m31)s, %(qtefa_m31)s, %(cofa_m31)s, %(desa1_m31)s, %(cobc_m31)s, %(daterec_m31)s, %(tva_m31)s, %(compt_m31)s, %(datesaisie_m31)s, %(unite_m31)s, %(coefunite_m31)s, %(codeemp_m31)s, %(i1cleunik_m31)s), (%(code_projet_m32)s, %(fournisseur_m32)s, %(ffcleunik_m32)s, %(nofact_m32)s, %(cofou_m32)s, %(typebc_m32)s, %(naf_m32)s, %(lbcleunik_m32)s, %(prix_m32)s, %(prixmon_m32)s, %(comon_m32)s, %(qtefa_m32)s, %(cofa_m32)s, %(desa1_m32)s, %(cobc_m32)s, %(daterec_m32)s, %(tva_m32)s, %(compt_m32)s, %(datesaisie_m32)s, %(unite_m32)s, %(coefunite_m32)s, %(codeemp_m32)s, %(i1cleunik_m32)s), (%(code_projet_m33)s, %(fournisseur_m33)s, %(ffcleunik_m33)s, %(nofact_m33)s, %(cofou_m33)s, %(typebc_m33)s, %(naf_m33)s, %(lbcleunik_m33)s, %(prix_m33)s, %(prixmon_m33)s, %(comon_m33)s, %(qtefa_m33)s, %(cofa_m33)s, %(desa1_m33)s, %(cobc_m33)s, %(daterec_m33)s, %(tva_m33)s, %(compt_m33)s, %(datesaisie_m33)s, %(unite_m33)s, %(coefunite_m33)s, %(codeemp_m33)s, %(i1cleunik_m33)s), (%(code_projet_m34)s, %(fournisseur_m34)s, %(ffcleunik_m34)s, %(nofact_m34)s, %(cofou_m34)s, %(typebc_m34)s, %(naf_m34)s, %(lbcleunik_m34)s, %(prix_m34)s, %(prixmon_m34)s, %(comon_m34)s, %(qtefa_m34)s, %(cofa_m34)s, %(desa1_m34)s, %(cobc_m34)s, %(daterec_m34)s, %(tva_m34)s, %(compt_m34)s, %(datesaisie_m34)s, %(unite_m34)s, %(coefunite_m34)s, %(codeemp_m34)s, %(i1cleunik_m34)s), (%(code_projet_m35)s, %(fournisseur_m35)s, %(ffcleunik_m35)s, %(nofact_m35)s, %(cofou_m35)s, %(typebc_m35)s, %(naf_m35)s, %(lbcleunik_m35)s, %(prix_m35)s, %(prixmon_m35)s, %(comon_m35)s, %(qtefa_m35)s, %(cofa_m35)s, %(desa1_m35)s, %(cobc_m35)s, %(daterec_m35)s, %(tva_m35)s, %(compt_m35)s, %(datesaisie_m35)s, %(unite_m35)s, %(coefunite_m35)s, %(codeemp_m35)s, %(i1cleunik_m35)s), (%(code_projet_m36)s, %(fournisseur_m36)s, %(ffcleunik_m36)s, %(nofact_m36)s, %(cofou_m36)s, %(typebc_m36)s, %(naf_m36)s, %(lbcleunik_m36)s, %(prix_m36)s, %(prixmon_m36)s, %(comon_m36)s, %(qtefa_m36)s, %(cofa_m36)s, %(desa1_m36)s, %(cobc_m36)s, %(daterec_m36)s, %(tva_m36)s, %(compt_m36)s, %(datesaisie_m36)s, %(unite_m36)s, %(coefunite_m36)s, %(codeemp_m36)s, %(i1cleunik_m36)s), (%(code_projet_m37)s, %(fournisseur_m37)s, %(ffcleunik_m37)s, %(nofact_m37)s, %(cofou_m37)s, %(typebc_m37)s, %(naf_m37)s, %(lbcleunik_m37)s, %(prix_m37)s, %(prixmon_m37)s, %(comon_m37)s, %(qtefa_m37)s, %(cofa_m37)s, %(desa1_m37)s, %(cobc_m37)s, %(daterec_m37)s, %(tva_m37)s, %(compt_m37)s, %(datesaisie_m37)s, %(unite_m37)s, %(coefunite_m37)s, %(codeemp_m37)s, %(i1cleunik_m37)s), (%(code_projet_m38)s, %(fournisseur_m38)s, %(ffcleunik_m38)s, %(nofact_m38)s, %(cofou_m38)s, %(typebc_m38)s, %(naf_m38)s, %(lbcleunik_m38)s, %(prix_m38)s, %(prixmon_m38)s, %(comon_m38)s, %(qtefa_m38)s, %(cofa_m38)s, %(desa1_m38)s, %(cobc_m38)s, %(daterec_m38)s, %(tva_m38)s, %(compt_m38)s, %(datesaisie_m38)s, %(unite_m38)s, %(coefunite_m38)s, %(codeemp_m38)s, %(i1cleunik_m38)s), (%(code_projet_m39)s, %(fournisseur_m39)s, %(ffcleunik_m39)s, %(nofact_m39)s, %(cofou_m39)s, %(typebc_m39)s, %(naf_m39)s, %(lbcleunik_m39)s, %(prix_m39)s, %(prixmon_m39)s, %(comon_m39)s, %(qtefa_m39)s, %(cofa_m39)s, %(desa1_m39)s, %(cobc_m39)s, %(daterec_m39)s, %(tva_m39)s, %(compt_m39)s, %(datesaisie_m39)s, %(unite_m39)s, %(coefunite_m39)s, %(codeemp_m39)s, %(i1cleunik_m39)s), (%(code_projet_m40)s, %(fournisseur_m40)s, %(ffcleunik_m40)s, %(nofact_m40)s, %(cofou_m40)s, %(typebc_m40)s, %(naf_m40)s, %(lbcleunik_m40)s, %(prix_m40)s, %(prixmon_m40)s, %(comon_m40)s, %(qtefa_m40)s, %(cofa_m40)s, %(desa1_m40)s, %(cobc_m40)s, %(daterec_m40)s, %(tva_m40)s, %(compt_m40)s, %(datesaisie_m40)s, %(unite_m40)s, %(coefunite_m40)s, %(codeemp_m40)s, %(i1cleunik_m40)s), (%(code_projet_m41)s, %(fournisseur_m41)s, %(ffcleunik_m41)s, %(nofact_m41)s, %(cofou_m41)s, %(typebc_m41)s, %(naf_m41)s, %(lbcleunik_m41)s, %(prix_m41)s, %(prixmon_m41)s, %(comon_m41)s, %(qtefa_m41)s, %(cofa_m41)s, %(desa1_m41)s, %(cobc_m41)s, %(daterec_m41)s, %(tva_m41)s, %(compt_m41)s, %(datesaisie_m41)s, %(unite_m41)s, %(coefunite_m41)s, %(codeemp_m41)s, %(i1cleunik_m41)s), (%(code_projet_m42)s, %(fournisseur_m42)s, %(ffcleunik_m42)s, %(nofact_m42)s, %(cofou_m42)s, %(typebc_m42)s, %(naf_m42)s, %(lbcleunik_m42)s, %(prix_m42)s, %(prixmon_m42)s, %(comon_m42)s, %(qtefa_m42)s, %(cofa_m42)s, %(desa1_m42)s, %(cobc_m42)s, %(daterec_m42)s, %(tva_m42)s, %(compt_m42)s, %(datesaisie_m42)s, %(unite_m42)s, %(coefunite_m42)s, %(codeemp_m42)s, %(i1cleunik_m42)s), (%(code_projet_m43)s, %(fournisseur_m43)s, %(ffcleunik_m43)s, %(nofact_m43)s, %(cofou_m43)s, %(typebc_m43)s, %(naf_m43)s, %(lbcleunik_m43)s, %(prix_m43)s, %(prixmon_m43)s, %(comon_m43)s, %(qtefa_m43)s, %(cofa_m43)s, %(desa1_m43)s, %(cobc_m43)s, %(daterec_m43)s, %(tva_m43)s, %(compt_m43)s, %(datesaisie_m43)s, %(unite_m43)s, %(coefunite_m43)s, %(codeemp_m43)s, %(i1cleunik_m43)s), (%(code_projet_m44)s, %(fournisseur_m44)s, %(ffcleunik_m44)s, %(nofact_m44)s, %(cofou_m44)s, %(typebc_m44)s, %(naf_m44)s, %(lbcleunik_m44)s, %(prix_m44)s, %(prixmon_m44)s, %(comon_m44)s, %(qtefa_m44)s, %(cofa_m44)s, %(desa1_m44)s, %(cobc_m44)s, %(daterec_m44)s, %(tva_m44)s, %(compt_m44)s, %(datesaisie_m44)s, %(unite_m44)s, %(coefunite_m44)s, %(codeemp_m44)s, %(i1cleunik_m44)s), (%(code_projet_m45)s, %(fournisseur_m45)s, %(ffcleunik_m45)s, %(nofact_m45)s, %(cofou_m45)s, %(typebc_m45)s, %(naf_m45)s, %(lbcleunik_m45)s, %(prix_m45)s, %(prixmon_m45)s, %(comon_m45)s, %(qtefa_m45)s, %(cofa_m45)s, %(desa1_m45)s, %(cobc_m45)s, %(daterec_m45)s, %(tva_m45)s, %(compt_m45)s, %(datesaisie_m45)s, %(unite_m45)s, %(coefunite_m45)s, %(codeemp_m45)s, %(i1cleunik_m45)s), (%(code_projet_m46)s, %(fournisseur_m46)s, %(ffcleunik_m46)s, %(nofact_m46)s, %(cofou_m46)s, %(typebc_m46)s, %(naf_m46)s, %(lbcleunik_m46)s, %(prix_m46)s, %(prixmon_m46)s, %(comon_m46)s, %(qtefa_m46)s, %(cofa_m46)s, %(desa1_m46)s, %(cobc_m46)s, %(daterec_m46)s, %(tva_m46)s, %(compt_m46)s, %(datesaisie_m46)s, %(unite_m46)s, %(coefunite_m46)s, %(codeemp_m46)s, %(i1cleunik_m46)s), (%(code_projet_m47)s, %(fournisseur_m47)s, %(ffcleunik_m47)s, %(nofact_m47)s, %(cofou_m47)s, %(typebc_m47)s, %(naf_m47)s, %(lbcleunik_m47)s, %(prix_m47)s, %(prixmon_m47)s, %(comon_m47)s, %(qtefa_m47)s, %(cofa_m47)s, %(desa1_m47)s, %(cobc_m47)s, %(daterec_m47)s, %(tva_m47)s, %(compt_m47)s, %(datesaisie_m47)s, %(unite_m47)s, %(coefunite_m47)s, %(codeemp_m47)s, %(i1cleunik_m47)s), (%(code_projet_m48)s, %(fournisseur_m48)s, %(ffcleunik_m48)s, %(nofact_m48)s, %(cofou_m48)s, %(typebc_m48)s, %(naf_m48)s, %(lbcleunik_m48)s, %(prix_m48)s, %(prixmon_m48)s, %(comon_m48)s, %(qtefa_m48)s, %(cofa_m48)s, %(desa1_m48)s, %(cobc_m48)s, %(daterec_m48)s, %(tva_m48)s, %(compt_m48)s, %(datesaisie_m48)s, %(unite_m48)s, %(coefunite_m48)s, %(codeemp_m48)s, %(i1cleunik_m48)s), (%(code_projet_m49)s, %(fournisseur_m49)s, %(ffcleunik_m49)s, %(nofact_m49)s, %(cofou_m49)s, %(typebc_m49)s, %(naf_m49)s, %(lbcleunik_m49)s, %(prix_m49)s, %(prixmon_m49)s, %(comon_m49)s, %(qtefa_m49)s, %(cofa_m49)s, %(desa1_m49)s, %(cobc_m49)s, %(daterec_m49)s, %(tva_m49)s, %(compt_m49)s, %(datesaisie_m49)s, %(unite_m49)s, %(coefunite_m49)s, %(codeemp_m49)s, %(i1cleunik_m49)s), (%(code_projet_m50)s, %(fournisseur_m50)s, %(ffcleunik_m50)s, %(nofact_m50)s, %(cofou_m50)s, %(typebc_m50)s, %(naf_m50)s, %(lbcleunik_m50)s, %(prix_m50)s, %(prixmon_m50)s, %(comon_m50)s, %(qtefa_m50)s, %(cofa_m50)s, %(desa1_m50)s, %(cobc_m50)s, %(daterec_m50)s, %(tva_m50)s, %(compt_m50)s, %(datesaisie_m50)s, %(unite_m50)s, %(coefunite_m50)s, %(codeemp_m50)s, %(i1cleunik_m50)s), (%(code_projet_m51)s, %(fournisseur_m51)s, %(ffcleunik_m51)s, %(nofact_m51)s, %(cofou_m51)s, %(typebc_m51)s, %(naf_m51)s, %(lbcleunik_m51)s, %(prix_m51)s, %(prixmon_m51)s, %(comon_m51)s, %(qtefa_m51)s, %(cofa_m51)s, %(desa1_m51)s, %(cobc_m51)s, %(daterec_m51)s, %(tva_m51)s, %(compt_m51)s, %(datesaisie_m51)s, %(unite_m51)s, %(coefunite_m51)s, %(codeemp_m51)s, %(i1cleunik_m51)s), (%(code_projet_m52)s, %(fournisseur_m52)s, %(ffcleunik_m52)s, %(nofact_m52)s, %(cofou_m52)s, %(typebc_m52)s, %(naf_m52)s, %(lbcleunik_m52)s, %(prix_m52)s, %(prixmon_m52)s, %(comon_m52)s, %(qtefa_m52)s, %(cofa_m52)s, %(desa1_m52)s, %(cobc_m52)s, %(daterec_m52)s, %(tva_m52)s, %(compt_m52)s, %(datesaisie_m52)s, %(unite_m52)s, %(coefunite_m52)s, %(codeemp_m52)s, %(i1cleunik_m52)s), (%(code_projet_m53)s, %(fournisseur_m53)s, %(ffcleunik_m53)s, %(nofact_m53)s, %(cofou_m53)s, %(typebc_m53)s, %(naf_m53)s, %(lbcleunik_m53)s, %(prix_m53)s, %(prixmon_m53)s, %(comon_m53)s, %(qtefa_m53)s, %(cofa_m53)s, %(desa1_m53)s, %(cobc_m53)s, %(daterec_m53)s, %(tva_m53)s, %(compt_m53)s, %(datesaisie_m53)s, %(unite_m53)s, %(coefunite_m53)s, %(codeemp_m53)s, %(i1cleunik_m53)s), (%(code_projet_m54)s, %(fournisseur_m54)s, %(ffcleunik_m54)s, %(nofact_m54)s, %(cofou_m54)s, %(typebc_m54)s, %(naf_m54)s, %(lbcleunik_m54)s, %(prix_m54)s, %(prixmon_m54)s, %(comon_m54)s, %(qtefa_m54)s, %(cofa_m54)s, %(desa1_m54)s, %(cobc_m54)s, %(daterec_m54)s, %(tva_m54)s, %(compt_m54)s, %(datesaisie_m54)s, %(unite_m54)s, %(coefunite_m54)s, %(codeemp_m54)s, %(i1cleunik_m54)s), (%(code_projet_m55)s, %(fournisseur_m55)s, %(ffcleunik_m55)s, %(nofact_m55)s, %(cofou_m55)s, %(typebc_m55)s, %(naf_m55)s, %(lbcleunik_m55)s, %(prix_m55)s, %(prixmon_m55)s, %(comon_m55)s, %(qtefa_m55)s, %(cofa_m55)s, %(desa1_m55)s, %(cobc_m55)s, %(daterec_m55)s, %(tva_m55)s, %(compt_m55)s, %(datesaisie_m55)s, %(unite_m55)s, %(coefunite_m55)s, %(codeemp_m55)s, %(i1cleunik_m55)s), (%(code_projet_m56)s, %(fournisseur_m56)s, %(ffcleunik_m56)s, %(nofact_m56)s, %(cofou_m56)s, %(typebc_m56)s, %(naf_m56)s, %(lbcleunik_m56)s, %(prix_m56)s, %(prixmon_m56)s, %(comon_m56)s, %(qtefa_m56)s, %(cofa_m56)s, %(desa1_m56)s, %(cobc_m56)s, %(daterec_m56)s, %(tva_m56)s, %(compt_m56)s, %(datesaisie_m56)s, %(unite_m56)s, %(coefunite_m56)s, %(codeemp_m56)s, %(i1cleunik_m56)s), (%(code_projet_m57)s, %(fournisseur_m57)s, %(ffcleunik_m57)s, %(nofact_m57)s, %(cofou_m57)s, %(typebc_m57)s, %(naf_m57)s, %(lbcleunik_m57)s, %(prix_m57)s, %(prixmon_m57)s, %(comon_m57)s, %(qtefa_m57)s, %(cofa_m57)s, %(desa1_m57)s, %(cobc_m57)s, %(daterec_m57)s, %(tva_m57)s, %(compt_m57)s, %(datesaisie_m57)s, %(unite_m57)s, %(coefunite_m57)s, %(codeemp_m57)s, %(i1cleunik_m57)s), (%(code_projet_m58)s, %(fournisseur_m58)s, %(ffcleunik_m58)s, %(nofact_m58)s, %(cofou_m58)s, %(typebc_m58)s, %(naf_m58)s, %(lbcleunik_m58)s, %(prix_m58)s, %(prixmon_m58)s, %(comon_m58)s, %(qtefa_m58)s, %(cofa_m58)s, %(desa1_m58)s, %(cobc_m58)s, %(daterec_m58)s, %(tva_m58)s, %(compt_m58)s, %(datesaisie_m58)s, %(unite_m58)s, %(coefunite_m58)s, %(codeemp_m58)s, %(i1cleunik_m58)s), (%(code_projet_m59)s, %(fournisseur_m59)s, %(ffcleunik_m59)s, %(nofact_m59)s, %(cofou_m59)s, %(typebc_m59)s, %(naf_m59)s, %(lbcleunik_m59)s, %(prix_m59)s, %(prixmon_m59)s, %(comon_m59)s, %(qtefa_m59)s, %(cofa_m59)s, %(desa1_m59)s, %(cobc_m59)s, %(daterec_m59)s, %(tva_m59)s, %(compt_m59)s, %(datesaisie_m59)s, %(unite_m59)s, %(coefunite_m59)s, %(codeemp_m59)s, %(i1cleunik_m59)s), (%(code_projet_m60)s, %(fournisseur_m60)s, %(ffcleunik_m60)s, %(nofact_m60)s, %(cofou_m60)s, %(typebc_m60)s, %(naf_m60)s, %(lbcleunik_m60)s, %(prix_m60)s, %(prixmon_m60)s, %(comon_m60)s, %(qtefa_m60)s, %(cofa_m60)s, %(desa1_m60)s, %(cobc_m60)s, %(daterec_m60)s, %(tva_m60)s, %(compt_m60)s, %(datesaisie_m60)s, %(unite_m60)s, %(coefunite_m60)s, %(codeemp_m60)s, %(i1cleunik_m60)s), (%(code_projet_m61)s, %(fournisseur_m61)s, %(ffcleunik_m61)s, %(nofact_m61)s, %(cofou_m61)s, %(typebc_m61)s, %(naf_m61)s, %(lbcleunik_m61)s, %(prix_m61)s, %(prixmon_m61)s, %(comon_m61)s, %(qtefa_m61)s, %(cofa_m61)s, %(desa1_m61)s, %(cobc_m61)s, %(daterec_m61)s, %(tva_m61)s, %(compt_m61)s, %(datesaisie_m61)s, %(unite_m61)s, %(coefunite_m61)s, %(codeemp_m61)s, %(i1cleunik_m61)s), (%(code_projet_m62)s, %(fournisseur_m62)s, %(ffcleunik_m62)s, %(nofact_m62)s, %(cofou_m62)s, %(typebc_m62)s, %(naf_m62)s, %(lbcleunik_m62)s, %(prix_m62)s, %(prixmon_m62)s, %(comon_m62)s, %(qtefa_m62)s, %(cofa_m62)s, %(desa1_m62)s, %(cobc_m62)s, %(daterec_m62)s, %(tva_m62)s, %(compt_m62)s, %(datesaisie_m62)s, %(unite_m62)s, %(coefunite_m62)s, %(codeemp_m62)s, %(i1cleunik_m62)s), (%(code_projet_m63)s, %(fournisseur_m63)s, %(ffcleunik_m63)s, %(nofact_m63)s, %(cofou_m63)s, %(typebc_m63)s, %(naf_m63)s, %(lbcleunik_m63)s, %(prix_m63)s, %(prixmon_m63)s, %(comon_m63)s, %(qtefa_m63)s, %(cofa_m63)s, %(desa1_m63)s, %(cobc_m63)s, %(daterec_m63)s, %(tva_m63)s, %(compt_m63)s, %(datesaisie_m63)s, %(unite_m63)s, %(coefunite_m63)s, %(codeemp_m63)s, %(i1cleunik_m63)s), (%(code_projet_m64)s, %(fournisseur_m64)s, %(ffcleunik_m64)s, %(nofact_m64)s, %(cofou_m64)s, %(typebc_m64)s, %(naf_m64)s, %(lbcleunik_m64)s, %(prix_m64)s, %(prixmon_m64)s, %(comon_m64)s, %(qtefa_m64)s, %(cofa_m64)s, %(desa1_m64)s, %(cobc_m64)s, %(daterec_m64)s, %(tva_m64)s, %(compt_m64)s, %(datesaisie_m64)s, %(unite_m64)s, %(coefunite_m64)s, %(codeemp_m64)s, %(i1cleunik_m64)s), (%(code_projet_m65)s, %(fournisseur_m65)s, %(ffcleunik_m65)s, %(nofact_m65)s, %(cofou_m65)s, %(typebc_m65)s, %(naf_m65)s, %(lbcleunik_m65)s, %(prix_m65)s, %(prixmon_m65)s, %(comon_m65)s, %(qtefa_m65)s, %(cofa_m65)s, %(desa1_m65)s, %(cobc_m65)s, %(daterec_m65)s, %(tva_m65)s, %(compt_m65)s, %(datesaisie_m65)s, %(unite_m65)s, %(coefunite_m65)s, %(codeemp_m65)s, %(i1cleunik_m65)s), (%(code_projet_m66)s, %(fournisseur_m66)s, %(ffcleunik_m66)s, %(nofact_m66)s, %(cofou_m66)s, %(typebc_m66)s, %(naf_m66)s, %(lbcleunik_m66)s, %(prix_m66)s, %(prixmon_m66)s, %(comon_m66)s, %(qtefa_m66)s, %(cofa_m66)s, %(desa1_m66)s, %(cobc_m66)s, %(daterec_m66)s, %(tva_m66)s, %(compt_m66)s, %(datesaisie_m66)s, %(unite_m66)s, %(coefunite_m66)s, %(codeemp_m66)s, %(i1cleunik_m66)s), (%(code_projet_m67)s, %(fournisseur_m67)s, %(ffcleunik_m67)s, %(nofact_m67)s, %(cofou_m67)s, %(typebc_m67)s, %(naf_m67)s, %(lbcleunik_m67)s, %(prix_m67)s, %(prixmon_m67)s, %(comon_m67)s, %(qtefa_m67)s, %(cofa_m67)s, %(desa1_m67)s, %(cobc_m67)s, %(daterec_m67)s, %(tva_m67)s, %(compt_m67)s, %(datesaisie_m67)s, %(unite_m67)s, %(coefunite_m67)s, %(codeemp_m67)s, %(i1cleunik_m67)s), (%(code_projet_m68)s, %(fournisseur_m68)s, %(ffcleunik_m68)s, %(nofact_m68)s, %(cofou_m68)s, %(typebc_m68)s, %(naf_m68)s, %(lbcleunik_m68)s, %(prix_m68)s, %(prixmon_m68)s, %(comon_m68)s, %(qtefa_m68)s, %(cofa_m68)s, %(desa1_m68)s, %(cobc_m68)s, %(daterec_m68)s, %(tva_m68)s, %(compt_m68)s, %(datesaisie_m68)s, %(unite_m68)s, %(coefunite_m68)s, %(codeemp_m68)s, %(i1cleunik_m68)s), (%(code_projet_m69)s, %(fournisseur_m69)s, %(ffcleunik_m69)s, %(nofact_m69)s, %(cofou_m69)s, %(typebc_m69)s, %(naf_m69)s, %(lbcleunik_m69)s, %(prix_m69)s, %(prixmon_m69)s, %(comon_m69)s, %(qtefa_m69)s, %(cofa_m69)s, %(desa1_m69)s, %(cobc_m69)s, %(daterec_m69)s, %(tva_m69)s, %(compt_m69)s, %(datesaisie_m69)s, %(unite_m69)s, %(coefunite_m69)s, %(codeemp_m69)s, %(i1cleunik_m69)s), (%(code_projet_m70)s, %(fournisseur_m70)s, %(ffcleunik_m70)s, %(nofact_m70)s, %(cofou_m70)s, %(typebc_m70)s, %(naf_m70)s, %(lbcleunik_m70)s, %(prix_m70)s, %(prixmon_m70)s, %(comon_m70)s, %(qtefa_m70)s, %(cofa_m70)s, %(desa1_m70)s, %(cobc_m70)s, %(daterec_m70)s, %(tva_m70)s, %(compt_m70)s, %(datesaisie_m70)s, %(unite_m70)s, %(coefunite_m70)s, %(codeemp_m70)s, %(i1cleunik_m70)s), (%(code_projet_m71)s, %(fournisseur_m71)s, %(ffcleunik_m71)s, %(nofact_m71)s, %(cofou_m71)s, %(typebc_m71)s, %(naf_m71)s, %(lbcleunik_m71)s, %(prix_m71)s, %(prixmon_m71)s, %(comon_m71)s, %(qtefa_m71)s, %(cofa_m71)s, %(desa1_m71)s, %(cobc_m71)s, %(daterec_m71)s, %(tva_m71)s, %(compt_m71)s, %(datesaisie_m71)s, %(unite_m71)s, %(coefunite_m71)s, %(codeemp_m71)s, %(i1cleunik_m71)s), (%(code_projet_m72)s, %(fournisseur_m72)s, %(ffcleunik_m72)s, %(nofact_m72)s, %(cofou_m72)s, %(typebc_m72)s, %(naf_m72)s, %(lbcleunik_m72)s, %(prix_m72)s, %(prixmon_m72)s, %(comon_m72)s, %(qtefa_m72)s, %(cofa_m72)s, %(desa1_m72)s, %(cobc_m72)s, %(daterec_m72)s, %(tva_m72)s, %(compt_m72)s, %(datesaisie_m72)s, %(unite_m72)s, %(coefunite_m72)s, %(codeemp_m72)s, %(i1cleunik_m72)s), (%(code_projet_m73)s, %(fournisseur_m73)s, %(ffcleunik_m73)s, %(nofact_m73)s, %(cofou_m73)s, %(typebc_m73)s, %(naf_m73)s, %(lbcleunik_m73)s, %(prix_m73)s, %(prixmon_m73)s, %(comon_m73)s, %(qtefa_m73)s, %(cofa_m73)s, %(desa1_m73)s, %(cobc_m73)s, %(daterec_m73)s, %(tva_m73)s, %(compt_m73)s, %(datesaisie_m73)s, %(unite_m73)s, %(coefunite_m73)s, %(codeemp_m73)s, %(i1cleunik_m73)s), (%(code_projet_m74)s, %(fournisseur_m74)s, %(ffcleunik_m74)s, %(nofact_m74)s, %(cofou_m74)s, %(typebc_m74)s, %(naf_m74)s, %(lbcleunik_m74)s, %(prix_m74)s, %(prixmon_m74)s, %(comon_m74)s, %(qtefa_m74)s, %(cofa_m74)s, %(desa1_m74)s, %(cobc_m74)s, %(daterec_m74)s, %(tva_m74)s, %(compt_m74)s, %(datesaisie_m74)s, %(unite_m74)s, %(coefunite_m74)s, %(codeemp_m74)s, %(i1cleunik_m74)s), (%(code_projet_m75)s, %(fournisseur_m75)s, %(ffcleunik_m75)s, %(nofact_m75)s, %(cofou_m75)s, %(typebc_m75)s, %(naf_m75)s, %(lbcleunik_m75)s, %(prix_m75)s, %(prixmon_m75)s, %(comon_m75)s, %(qtefa_m75)s, %(cofa_m75)s, %(desa1_m75)s, %(cobc_m75)s, %(daterec_m75)s, %(tva_m75)s, %(compt_m75)s, %(datesaisie_m75)s, %(unite_m75)s, %(coefunite_m75)s, %(codeemp_m75)s, %(i1cleunik_m75)s), (%(code_projet_m76)s, %(fournisseur_m76)s, %(ffcleunik_m76)s, %(nofact_m76)s, %(cofou_m76)s, %(typebc_m76)s, %(naf_m76)s, %(lbcleunik_m76)s, %(prix_m76)s, %(prixmon_m76)s, %(comon_m76)s, %(qtefa_m76)s, %(cofa_m76)s, %(desa1_m76)s, %(cobc_m76)s, %(daterec_m76)s, %(tva_m76)s, %(compt_m76)s, %(datesaisie_m76)s, %(unite_m76)s, %(coefunite_m76)s, %(codeemp_m76)s, %(i1cleunik_m76)s), (%(code_projet_m77)s, %(fournisseur_m77)s, %(ffcleunik_m77)s, %(nofact_m77)s, %(cofou_m77)s, %(typebc_m77)s, %(naf_m77)s, %(lbcleunik_m77)s, %(prix_m77)s, %(prixmon_m77)s, %(comon_m77)s, %(qtefa_m77)s, %(cofa_m77)s, %(desa1_m77)s, %(cobc_m77)s, %(daterec_m77)s, %(tva_m77)s, %(compt_m77)s, %(datesaisie_m77)s, %(unite_m77)s, %(coefunite_m77)s, %(codeemp_m77)s, %(i1cleunik_m77)s), (%(code_projet_m78)s, %(fournisseur_m78)s, %(ffcleunik_m78)s, %(nofact_m78)s, %(cofou_m78)s, %(typebc_m78)s, %(naf_m78)s, %(lbcleunik_m78)s, %(prix_m78)s, %(prixmon_m78)s, %(comon_m78)s, %(qtefa_m78)s, %(cofa_m78)s, %(desa1_m78)s, %(cobc_m78)s, %(daterec_m78)s, %(tva_m78)s, %(compt_m78)s, %(datesaisie_m78)s, %(unite_m78)s, %(coefunite_m78)s, %(codeemp_m78)s, %(i1cleunik_m78)s), (%(code_projet_m79)s, %(fournisseur_m79)s, %(ffcleunik_m79)s, %(nofact_m79)s, %(cofou_m79)s, %(typebc_m79)s, %(naf_m79)s, %(lbcleunik_m79)s, %(prix_m79)s, %(prixmon_m79)s, %(comon_m79)s, %(qtefa_m79)s, %(cofa_m79)s, %(desa1_m79)s, %(cobc_m79)s, %(daterec_m79)s, %(tva_m79)s, %(compt_m79)s, %(datesaisie_m79)s, %(unite_m79)s, %(coefunite_m79)s, %(codeemp_m79)s, %(i1cleunik_m79)s), (%(code_projet_m80)s, %(fournisseur_m80)s, %(ffcleunik_m80)s, %(nofact_m80)s, %(cofou_m80)s, %(typebc_m80)s, %(naf_m80)s, %(lbcleunik_m80)s, %(prix_m80)s, %(prixmon_m80)s, %(comon_m80)s, %(qtefa_m80)s, %(cofa_m80)s, %(desa1_m80)s, %(cobc_m80)s, %(daterec_m80)s, %(tva_m80)s, %(compt_m80)s, %(datesaisie_m80)s, %(unite_m80)s, %(coefunite_m80)s, %(codeemp_m80)s, %(i1cleunik_m80)s), (%(code_projet_m81)s, %(fournisseur_m81)s, %(ffcleunik_m81)s, %(nofact_m81)s, %(cofou_m81)s, %(typebc_m81)s, %(naf_m81)s, %(lbcleunik_m81)s, %(prix_m81)s, %(prixmon_m81)s, %(comon_m81)s, %(qtefa_m81)s, %(cofa_m81)s, %(desa1_m81)s, %(cobc_m81)s, %(daterec_m81)s, %(tva_m81)s, %(compt_m81)s, %(datesaisie_m81)s, %(unite_m81)s, %(coefunite_m81)s, %(codeemp_m81)s, %(i1cleunik_m81)s), (%(code_projet_m82)s, %(fournisseur_m82)s, %(ffcleunik_m82)s, %(nofact_m82)s, %(cofou_m82)s, %(typebc_m82)s, %(naf_m82)s, %(lbcleunik_m82)s, %(prix_m82)s, %(prixmon_m82)s, %(comon_m82)s, %(qtefa_m82)s, %(cofa_m82)s, %(desa1_m82)s, %(cobc_m82)s, %(daterec_m82)s, %(tva_m82)s, %(compt_m82)s, %(datesaisie_m82)s, %(unite_m82)s, %(coefunite_m82)s, %(codeemp_m82)s, %(i1cleunik_m82)s), (%(code_projet_m83)s, %(fournisseur_m83)s, %(ffcleunik_m83)s, %(nofact_m83)s, %(cofou_m83)s, %(typebc_m83)s, %(naf_m83)s, %(lbcleunik_m83)s, %(prix_m83)s, %(prixmon_m83)s, %(comon_m83)s, %(qtefa_m83)s, %(cofa_m83)s, %(desa1_m83)s, %(cobc_m83)s, %(daterec_m83)s, %(tva_m83)s, %(compt_m83)s, %(datesaisie_m83)s, %(unite_m83)s, %(coefunite_m83)s, %(codeemp_m83)s, %(i1cleunik_m83)s), (%(code_projet_m84)s, %(fournisseur_m84)s, %(ffcleunik_m84)s, %(nofact_m84)s, %(cofou_m84)s, %(typebc_m84)s, %(naf_m84)s, %(lbcleunik_m84)s, %(prix_m84)s, %(prixmon_m84)s, %(comon_m84)s, %(qtefa_m84)s, %(cofa_m84)s, %(desa1_m84)s, %(cobc_m84)s, %(daterec_m84)s, %(tva_m84)s, %(compt_m84)s, %(datesaisie_m84)s, %(unite_m84)s, %(coefunite_m84)s, %(codeemp_m84)s, %(i1cleunik_m84)s), (%(code_projet_m85)s, %(fournisseur_m85)s, %(ffcleunik_m85)s, %(nofact_m85)s, %(cofou_m85)s, %(typebc_m85)s, %(naf_m85)s, %(lbcleunik_m85)s, %(prix_m85)s, %(prixmon_m85)s, %(comon_m85)s, %(qtefa_m85)s, %(cofa_m85)s, %(desa1_m85)s, %(cobc_m85)s, %(daterec_m85)s, %(tva_m85)s, %(compt_m85)s, %(datesaisie_m85)s, %(unite_m85)s, %(coefunite_m85)s, %(codeemp_m85)s, %(i1cleunik_m85)s), (%(code_projet_m86)s, %(fournisseur_m86)s, %(ffcleunik_m86)s, %(nofact_m86)s, %(cofou_m86)s, %(typebc_m86)s, %(naf_m86)s, %(lbcleunik_m86)s, %(prix_m86)s, %(prixmon_m86)s, %(comon_m86)s, %(qtefa_m86)s, %(cofa_m86)s, %(desa1_m86)s, %(cobc_m86)s, %(daterec_m86)s, %(tva_m86)s, %(compt_m86)s, %(datesaisie_m86)s, %(unite_m86)s, %(coefunite_m86)s, %(codeemp_m86)s, %(i1cleunik_m86)s), (%(code_projet_m87)s, %(fournisseur_m87)s, %(ffcleunik_m87)s, %(nofact_m87)s, %(cofou_m87)s, %(typebc_m87)s, %(naf_m87)s, %(lbcleunik_m87)s, %(prix_m87)s, %(prixmon_m87)s, %(comon_m87)s, %(qtefa_m87)s, %(cofa_m87)s, %(desa1_m87)s, %(cobc_m87)s, %(daterec_m87)s, %(tva_m87)s, %(compt_m87)s, %(datesaisie_m87)s, %(unite_m87)s, %(coefunite_m87)s, %(codeemp_m87)s, %(i1cleunik_m87)s), (%(code_projet_m88)s, %(fournisseur_m88)s, %(ffcleunik_m88)s, %(nofact_m88)s, %(cofou_m88)s, %(typebc_m88)s, %(naf_m88)s, %(lbcleunik_m88)s, %(prix_m88)s, %(prixmon_m88)s, %(comon_m88)s, %(qtefa_m88)s, %(cofa_m88)s, %(desa1_m88)s, %(cobc_m88)s, %(daterec_m88)s, %(tva_m88)s, %(compt_m88)s, %(datesaisie_m88)s, %(unite_m88)s, %(coefunite_m88)s, %(codeemp_m88)s, %(i1cleunik_m88)s), (%(code_projet_m89)s, %(fournisseur_m89)s, %(ffcleunik_m89)s, %(nofact_m89)s, %(cofou_m89)s, %(typebc_m89)s, %(naf_m89)s, %(lbcleunik_m89)s, %(prix_m89)s, %(prixmon_m89)s, %(comon_m89)s, %(qtefa_m89)s, %(cofa_m89)s, %(desa1_m89)s, %(cobc_m89)s, %(daterec_m89)s, %(tva_m89)s, %(compt_m89)s, %(datesaisie_m89)s, %(unite_m89)s, %(coefunite_m89)s, %(codeemp_m89)s, %(i1cleunik_m89)s), (%(code_projet_m90)s, %(fournisseur_m90)s, %(ffcleunik_m90)s, %(nofact_m90)s, %(cofou_m90)s, %(typebc_m90)s, %(naf_m90)s, %(lbcleunik_m90)s, %(prix_m90)s, %(prixmon_m90)s, %(comon_m90)s, %(qtefa_m90)s, %(cofa_m90)s, %(desa1_m90)s, %(cobc_m90)s, %(daterec_m90)s, %(tva_m90)s, %(compt_m90)s, %(datesaisie_m90)s, %(unite_m90)s, %(coefunite_m90)s, %(codeemp_m90)s, %(i1cleunik_m90)s), (%(code_projet_m91)s, %(fournisseur_m91)s, %(ffcleunik_m91)s, %(nofact_m91)s, %(cofou_m91)s, %(typebc_m91)s, %(naf_m91)s, %(lbcleunik_m91)s, %(prix_m91)s, %(prixmon_m91)s, %(comon_m91)s, %(qtefa_m91)s, %(cofa_m91)s, %(desa1_m91)s, %(cobc_m91)s, %(daterec_m91)s, %(tva_m91)s, %(compt_m91)s, %(datesaisie_m91)s, %(unite_m91)s, %(coefunite_m91)s, %(codeemp_m91)s, %(i1cleunik_m91)s), (%(code_projet_m92)s, %(fournisseur_m92)s, %(ffcleunik_m92)s, %(nofact_m92)s, %(cofou_m92)s, %(typebc_m92)s, %(naf_m92)s, %(lbcleunik_m92)s, %(prix_m92)s, %(prixmon_m92)s, %(comon_m92)s, %(qtefa_m92)s, %(cofa_m92)s, %(desa1_m92)s, %(cobc_m92)s, %(daterec_m92)s, %(tva_m92)s, %(compt_m92)s, %(datesaisie_m92)s, %(unite_m92)s, %(coefunite_m92)s, %(codeemp_m92)s, %(i1cleunik_m92)s), (%(code_projet_m93)s, %(fournisseur_m93)s, %(ffcleunik_m93)s, %(nofact_m93)s, %(cofou_m93)s, %(typebc_m93)s, %(naf_m93)s, %(lbcleunik_m93)s, %(prix_m93)s, %(prixmon_m93)s, %(comon_m93)s, %(qtefa_m93)s, %(cofa_m93)s, %(desa1_m93)s, %(cobc_m93)s, %(daterec_m93)s, %(tva_m93)s, %(compt_m93)s, %(datesaisie_m93)s, %(unite_m93)s, %(coefunite_m93)s, %(codeemp_m93)s, %(i1cleunik_m93)s), (%(code_projet_m94)s, %(fournisseur_m94)s, %(ffcleunik_m94)s, %(nofact_m94)s, %(cofou_m94)s, %(typebc_m94)s, %(naf_m94)s, %(lbcleunik_m94)s, %(prix_m94)s, %(prixmon_m94)s, %(comon_m94)s, %(qtefa_m94)s, %(cofa_m94)s, %(desa1_m94)s, %(cobc_m94)s, %(daterec_m94)s, %(tva_m94)s, %(compt_m94)s, %(datesaisie_m94)s, %(unite_m94)s, %(coefunite_m94)s, %(codeemp_m94)s, %(i1cleunik_m94)s), (%(code_projet_m95)s, %(fournisseur_m95)s, %(ffcleunik_m95)s, %(nofact_m95)s, %(cofou_m95)s, %(typebc_m95)s, %(naf_m95)s, %(lbcleunik_m95)s, %(prix_m95)s, %(prixmon_m95)s, %(comon_m95)s, %(qtefa_m95)s, %(cofa_m95)s, %(desa1_m95)s, %(cobc_m95)s, %(daterec_m95)s, %(tva_m95)s, %(compt_m95)s, %(datesaisie_m95)s, %(unite_m95)s, %(coefunite_m95)s, %(codeemp_m95)s, %(i1cleunik_m95)s), (%(code_projet_m96)s, %(fournisseur_m96)s, %(ffcleunik_m96)s, %(nofact_m96)s, %(cofou_m96)s, %(typebc_m96)s, %(naf_m96)s, %(lbcleunik_m96)s, %(prix_m96)s, %(prixmon_m96)s, %(comon_m96)s, %(qtefa_m96)s, %(cofa_m96)s, %(desa1_m96)s, %(cobc_m96)s, %(daterec_m96)s, %(tva_m96)s, %(compt_m96)s, %(datesaisie_m96)s, %(unite_m96)s, %(coefunite_m96)s, %(codeemp_m96)s, %(i1cleunik_m96)s), (%(code_projet_m97)s, %(fournisseur_m97)s, %(ffcleunik_m97)s, %(nofact_m97)s, %(cofou_m97)s, %(typebc_m97)s, %(naf_m97)s, %(lbcleunik_m97)s, %(prix_m97)s, %(prixmon_m97)s, %(comon_m97)s, %(qtefa_m97)s, %(cofa_m97)s, %(desa1_m97)s, %(cobc_m97)s, %(daterec_m97)s, %(tva_m97)s, %(compt_m97)s, %(datesaisie_m97)s, %(unite_m97)s, %(coefunite_m97)s, %(codeemp_m97)s, %(i1cleunik_m97)s), (%(code_projet_m98)s, %(fournisseur_m98)s, %(ffcleunik_m98)s, %(nofact_m98)s, %(cofou_m98)s, %(typebc_m98)s, %(naf_m98)s, %(lbcleunik_m98)s, %(prix_m98)s, %(prixmon_m98)s, %(comon_m98)s, %(qtefa_m98)s, %(cofa_m98)s, %(desa1_m98)s, %(cobc_m98)s, %(daterec_m98)s, %(tva_m98)s, %(compt_m98)s, %(datesaisie_m98)s, %(unite_m98)s, %(coefunite_m98)s, %(codeemp_m98)s, %(i1cleunik_m98)s), (%(code_projet_m99)s, %(fournisseur_m99)s, %(ffcleunik_m99)s, %(nofact_m99)s, %(cofou_m99)s, %(typebc_m99)s, %(naf_m99)s, %(lbcleunik_m99)s, %(prix_m99)s, %(prixmon_m99)s, %(comon_m99)s, %(qtefa_m99)s, %(cofa_m99)s, %(desa1_m99)s, %(cobc_m99)s, %(daterec_m99)s, %(tva_m99)s, %(compt_m99)s, %(datesaisie_m99)s, %(unite_m99)s, %(coefunite_m99)s, %(codeemp_m99)s, %(i1cleunik_m99)s), (%(code_projet_m100)s, %(fournisseur_m100)s, %(ffcleunik_m100)s, %(nofact_m100)s, %(cofou_m100)s, %(typebc_m100)s, %(naf_m100)s, %(lbcleunik_m100)s, %(prix_m100)s, %(prixmon_m100)s, %(comon_m100)s, %(qtefa_m100)s, %(cofa_m100)s, %(desa1_m100)s, %(cobc_m100)s, %(daterec_m100)s, %(tva_m100)s, %(compt_m100)s, %(datesaisie_m100)s, %(unite_m100)s, %(coefunite_m100)s, %(codeemp_m100)s, %(i1cleunik_m100)s), (%(code_projet_m101)s, %(fournisseur_m101)s, %(ffcleunik_m101)s, %(nofact_m101)s, %(cofou_m101)s, %(typebc_m101)s, %(naf_m101)s, %(lbcleunik_m101)s, %(prix_m101)s, %(prixmon_m101)s, %(comon_m101)s, %(qtefa_m101)s, %(cofa_m101)s, %(desa1_m101)s, %(cobc_m101)s, %(daterec_m101)s, %(tva_m101)s, %(compt_m101)s, %(datesaisie_m101)s, %(unite_m101)s, %(coefunite_m101)s, %(codeemp_m101)s, %(i1cleunik_m101)s), (%(code_projet_m102)s, %(fournisseur_m102)s, %(ffcleunik_m102)s, %(nofact_m102)s, %(cofou_m102)s, %(typebc_m102)s, %(naf_m102)s, %(lbcleunik_m102)s, %(prix_m102)s, %(prixmon_m102)s, %(comon_m102)s, %(qtefa_m102)s, %(cofa_m102)s, %(desa1_m102)s, %(cobc_m102)s, %(daterec_m102)s, %(tva_m102)s, %(compt_m102)s, %(datesaisie_m102)s, %(unite_m102)s, %(coefunite_m102)s, %(codeemp_m102)s, %(i1cleunik_m102)s), (%(code_projet_m103)s, %(fournisseur_m103)s, %(ffcleunik_m103)s, %(nofact_m103)s, %(cofou_m103)s, %(typebc_m103)s, %(naf_m103)s, %(lbcleunik_m103)s, %(prix_m103)s, %(prixmon_m103)s, %(comon_m103)s, %(qtefa_m103)s, %(cofa_m103)s, %(desa1_m103)s, %(cobc_m103)s, %(daterec_m103)s, %(tva_m103)s, %(compt_m103)s, %(datesaisie_m103)s, %(unite_m103)s, %(coefunite_m103)s, %(codeemp_m103)s, %(i1cleunik_m103)s), (%(code_projet_m104)s, %(fournisseur_m104)s, %(ffcleunik_m104)s, %(nofact_m104)s, %(cofou_m104)s, %(typebc_m104)s, %(naf_m104)s, %(lbcleunik_m104)s, %(prix_m104)s, %(prixmon_m104)s, %(comon_m104)s, %(qtefa_m104)s, %(cofa_m104)s, %(desa1_m104)s, %(cobc_m104)s, %(daterec_m104)s, %(tva_m104)s, %(compt_m104)s, %(datesaisie_m104)s, %(unite_m104)s, %(coefunite_m104)s, %(codeemp_m104)s, %(i1cleunik_m104)s), (%(code_projet_m105)s, %(fournisseur_m105)s, %(ffcleunik_m105)s, %(nofact_m105)s, %(cofou_m105)s, %(typebc_m105)s, %(naf_m105)s, %(lbcleunik_m105)s, %(prix_m105)s, %(prixmon_m105)s, %(comon_m105)s, %(qtefa_m105)s, %(cofa_m105)s, %(desa1_m105)s, %(cobc_m105)s, %(daterec_m105)s, %(tva_m105)s, %(compt_m105)s, %(datesaisie_m105)s, %(unite_m105)s, %(coefunite_m105)s, %(codeemp_m105)s, %(i1cleunik_m105)s), (%(code_projet_m106)s, %(fournisseur_m106)s, %(ffcleunik_m106)s, %(nofact_m106)s, %(cofou_m106)s, %(typebc_m106)s, %(naf_m106)s, %(lbcleunik_m106)s, %(prix_m106)s, %(prixmon_m106)s, %(comon_m106)s, %(qtefa_m106)s, %(cofa_m106)s, %(desa1_m106)s, %(cobc_m106)s, %(daterec_m106)s, %(tva_m106)s, %(compt_m106)s, %(datesaisie_m106)s, %(unite_m106)s, %(coefunite_m106)s, %(codeemp_m106)s, %(i1cleunik_m106)s), (%(code_projet_m107)s, %(fournisseur_m107)s, %(ffcleunik_m107)s, %(nofact_m107)s, %(cofou_m107)s, %(typebc_m107)s, %(naf_m107)s, %(lbcleunik_m107)s, %(prix_m107)s, %(prixmon_m107)s, %(comon_m107)s, %(qtefa_m107)s, %(cofa_m107)s, %(desa1_m107)s, %(cobc_m107)s, %(daterec_m107)s, %(tva_m107)s, %(compt_m107)s, %(datesaisie_m107)s, %(unite_m107)s, %(coefunite_m107)s, %(codeemp_m107)s, %(i1cleunik_m107)s), (%(code_projet_m108)s, %(fournisseur_m108)s, %(ffcleunik_m108)s, %(nofact_m108)s, %(cofou_m108)s, %(typebc_m108)s, %(naf_m108)s, %(lbcleunik_m108)s, %(prix_m108)s, %(prixmon_m108)s, %(comon_m108)s, %(qtefa_m108)s, %(cofa_m108)s, %(desa1_m108)s, %(cobc_m108)s, %(daterec_m108)s, %(tva_m108)s, %(compt_m108)s, %(datesaisie_m108)s, %(unite_m108)s, %(coefunite_m108)s, %(codeemp_m108)s, %(i1cleunik_m108)s), (%(code_projet_m109)s, %(fournisseur_m109)s, %(ffcleunik_m109)s, %(nofact_m109)s, %(cofou_m109)s, %(typebc_m109)s, %(naf_m109)s, %(lbcleunik_m109)s, %(prix_m109)s, %(prixmon_m109)s, %(comon_m109)s, %(qtefa_m109)s, %(cofa_m109)s, %(desa1_m109)s, %(cobc_m109)s, %(daterec_m109)s, %(tva_m109)s, %(compt_m109)s, %(datesaisie_m109)s, %(unite_m109)s, %(coefunite_m109)s, %(codeemp_m109)s, %(i1cleunik_m109)s), (%(code_projet_m110)s, %(fournisseur_m110)s, %(ffcleunik_m110)s, %(nofact_m110)s, %(cofou_m110)s, %(typebc_m110)s, %(naf_m110)s, %(lbcleunik_m110)s, %(prix_m110)s, %(prixmon_m110)s, %(comon_m110)s, %(qtefa_m110)s, %(cofa_m110)s, %(desa1_m110)s, %(cobc_m110)s, %(daterec_m110)s, %(tva_m110)s, %(compt_m110)s, %(datesaisie_m110)s, %(unite_m110)s, %(coefunite_m110)s, %(codeemp_m110)s, %(i1cleunik_m110)s), (%(code_projet_m111)s, %(fournisseur_m111)s, %(ffcleunik_m111)s, %(nofact_m111)s, %(cofou_m111)s, %(typebc_m111)s, %(naf_m111)s, %(lbcleunik_m111)s, %(prix_m111)s, %(prixmon_m111)s, %(comon_m111)s, %(qtefa_m111)s, %(cofa_m111)s, %(desa1_m111)s, %(cobc_m111)s, %(daterec_m111)s, %(tva_m111)s, %(compt_m111)s, %(datesaisie_m111)s, %(unite_m111)s, %(coefunite_m111)s, %(codeemp_m111)s, %(i1cleunik_m111)s), (%(code_projet_m112)s, %(fournisseur_m112)s, %(ffcleunik_m112)s, %(nofact_m112)s, %(cofou_m112)s, %(typebc_m112)s, %(naf_m112)s, %(lbcleunik_m112)s, %(prix_m112)s, %(prixmon_m112)s, %(comon_m112)s, %(qtefa_m112)s, %(cofa_m112)s, %(desa1_m112)s, %(cobc_m112)s, %(daterec_m112)s, %(tva_m112)s, %(compt_m112)s, %(datesaisie_m112)s, %(unite_m112)s, %(coefunite_m112)s, %(codeemp_m112)s, %(i1cleunik_m112)s), (%(code_projet_m113)s, %(fournisseur_m113)s, %(ffcleunik_m113)s, %(nofact_m113)s, %(cofou_m113)s, %(typebc_m113)s, %(naf_m113)s, %(lbcleunik_m113)s, %(prix_m113)s, %(prixmon_m113)s, %(comon_m113)s, %(qtefa_m113)s, %(cofa_m113)s, %(desa1_m113)s, %(cobc_m113)s, %(daterec_m113)s, %(tva_m113)s, %(compt_m113)s, %(datesaisie_m113)s, %(unite_m113)s, %(coefunite_m113)s, %(codeemp_m113)s, %(i1cleunik_m113)s), (%(code_projet_m114)s, %(fournisseur_m114)s, %(ffcleunik_m114)s, %(nofact_m114)s, %(cofou_m114)s, %(typebc_m114)s, %(naf_m114)s, %(lbcleunik_m114)s, %(prix_m114)s, %(prixmon_m114)s, %(comon_m114)s, %(qtefa_m114)s, %(cofa_m114)s, %(desa1_m114)s, %(cobc_m114)s, %(daterec_m114)s, %(tva_m114)s, %(compt_m114)s, %(datesaisie_m114)s, %(unite_m114)s, %(coefunite_m114)s, %(codeemp_m114)s, %(i1cleunik_m114)s), (%(code_projet_m115)s, %(fournisseur_m115)s, %(ffcleunik_m115)s, %(nofact_m115)s, %(cofou_m115)s, %(typebc_m115)s, %(naf_m115)s, %(lbcleunik_m115)s, %(prix_m115)s, %(prixmon_m115)s, %(comon_m115)s, %(qtefa_m115)s, %(cofa_m115)s, %(desa1_m115)s, %(cobc_m115)s, %(daterec_m115)s, %(tva_m115)s, %(compt_m115)s, %(datesaisie_m115)s, %(unite_m115)s, %(coefunite_m115)s, %(codeemp_m115)s, %(i1cleunik_m115)s), (%(code_projet_m116)s, %(fournisseur_m116)s, %(ffcleunik_m116)s, %(nofact_m116)s, %(cofou_m116)s, %(typebc_m116)s, %(naf_m116)s, %(lbcleunik_m116)s, %(prix_m116)s, %(prixmon_m116)s, %(comon_m116)s, %(qtefa_m116)s, %(cofa_m116)s, %(desa1_m116)s, %(cobc_m116)s, %(daterec_m116)s, %(tva_m116)s, %(compt_m116)s, %(datesaisie_m116)s, %(unite_m116)s, %(coefunite_m116)s, %(codeemp_m116)s, %(i1cleunik_m116)s), (%(code_projet_m117)s, %(fournisseur_m117)s, %(ffcleunik_m117)s, %(nofact_m117)s, %(cofou_m117)s, %(typebc_m117)s, %(naf_m117)s, %(lbcleunik_m117)s, %(prix_m117)s, %(prixmon_m117)s, %(comon_m117)s, %(qtefa_m117)s, %(cofa_m117)s, %(desa1_m117)s, %(cobc_m117)s, %(daterec_m117)s, %(tva_m117)s, %(compt_m117)s, %(datesaisie_m117)s, %(unite_m117)s, %(coefunite_m117)s, %(codeemp_m117)s, %(i1cleunik_m117)s), (%(code_projet_m118)s, %(fournisseur_m118)s, %(ffcleunik_m118)s, %(nofact_m118)s, %(cofou_m118)s, %(typebc_m118)s, %(naf_m118)s, %(lbcleunik_m118)s, %(prix_m118)s, %(prixmon_m118)s, %(comon_m118)s, %(qtefa_m118)s, %(cofa_m118)s, %(desa1_m118)s, %(cobc_m118)s, %(daterec_m118)s, %(tva_m118)s, %(compt_m118)s, %(datesaisie_m118)s, %(unite_m118)s, %(coefunite_m118)s, %(codeemp_m118)s, %(i1cleunik_m118)s), (%(code_projet_m119)s, %(fournisseur_m119)s, %(ffcleunik_m119)s, %(nofact_m119)s, %(cofou_m119)s, %(typebc_m119)s, %(naf_m119)s, %(lbcleunik_m119)s, %(prix_m119)s, %(prixmon_m119)s, %(comon_m119)s, %(qtefa_m119)s, %(cofa_m119)s, %(desa1_m119)s, %(cobc_m119)s, %(daterec_m119)s, %(tva_m119)s, %(compt_m119)s, %(datesaisie_m119)s, %(unite_m119)s, %(coefunite_m119)s, %(codeemp_m119)s, %(i1cleunik_m119)s), (%(code_projet_m120)s, %(fournisseur_m120)s, %(ffcleunik_m120)s, %(nofact_m120)s, %(cofou_m120)s, %(typebc_m120)s, %(naf_m120)s, %(lbcleunik_m120)s, %(prix_m120)s, %(prixmon_m120)s, %(comon_m120)s, %(qtefa_m120)s, %(cofa_m120)s, %(desa1_m120)s, %(cobc_m120)s, %(daterec_m120)s, %(tva_m120)s, %(compt_m120)s, %(datesaisie_m120)s, %(unite_m120)s, %(coefunite_m120)s, %(codeemp_m120)s, %(i1cleunik_m120)s), (%(code_projet_m121)s, %(fournisseur_m121)s, %(ffcleunik_m121)s, %(nofact_m121)s, %(cofou_m121)s, %(typebc_m121)s, %(naf_m121)s, %(lbcleunik_m121)s, %(prix_m121)s, %(prixmon_m121)s, %(comon_m121)s, %(qtefa_m121)s, %(cofa_m121)s, %(desa1_m121)s, %(cobc_m121)s, %(daterec_m121)s, %(tva_m121)s, %(compt_m121)s, %(datesaisie_m121)s, %(unite_m121)s, %(coefunite_m121)s, %(codeemp_m121)s, %(i1cleunik_m121)s), (%(code_projet_m122)s, %(fournisseur_m122)s, %(ffcleunik_m122)s, %(nofact_m122)s, %(cofou_m122)s, %(typebc_m122)s, %(naf_m122)s, %(lbcleunik_m122)s, %(prix_m122)s, %(prixmon_m122)s, %(comon_m122)s, %(qtefa_m122)s, %(cofa_m122)s, %(desa1_m122)s, %(cobc_m122)s, %(daterec_m122)s, %(tva_m122)s, %(compt_m122)s, %(datesaisie_m122)s, %(unite_m122)s, %(coefunite_m122)s, %(codeemp_m122)s, %(i1cleunik_m122)s), (%(code_projet_m123)s, %(fournisseur_m123)s, %(ffcleunik_m123)s, %(nofact_m123)s, %(cofou_m123)s, %(typebc_m123)s, %(naf_m123)s, %(lbcleunik_m123)s, %(prix_m123)s, %(prixmon_m123)s, %(comon_m123)s, %(qtefa_m123)s, %(cofa_m123)s, %(desa1_m123)s, %(cobc_m123)s, %(daterec_m123)s, %(tva_m123)s, %(compt_m123)s, %(datesaisie_m123)s, %(unite_m123)s, %(coefunite_m123)s, %(codeemp_m123)s, %(i1cleunik_m123)s), (%(code_projet_m124)s, %(fournisseur_m124)s, %(ffcleunik_m124)s, %(nofact_m124)s, %(cofou_m124)s, %(typebc_m124)s, %(naf_m124)s, %(lbcleunik_m124)s, %(prix_m124)s, %(prixmon_m124)s, %(comon_m124)s, %(qtefa_m124)s, %(cofa_m124)s, %(desa1_m124)s, %(cobc_m124)s, %(daterec_m124)s, %(tva_m124)s, %(compt_m124)s, %(datesaisie_m124)s, %(unite_m124)s, %(coefunite_m124)s, %(codeemp_m124)s, %(i1cleunik_m124)s), (%(code_projet_m125)s, %(fournisseur_m125)s, %(ffcleunik_m125)s, %(nofact_m125)s, %(cofou_m125)s, %(typebc_m125)s, %(naf_m125)s, %(lbcleunik_m125)s, %(prix_m125)s, %(prixmon_m125)s, %(comon_m125)s, %(qtefa_m125)s, %(cofa_m125)s, %(desa1_m125)s, %(cobc_m125)s, %(daterec_m125)s, %(tva_m125)s, %(compt_m125)s, %(datesaisie_m125)s, %(unite_m125)s, %(coefunite_m125)s, %(codeemp_m125)s, %(i1cleunik_m125)s), (%(code_projet_m126)s, %(fournisseur_m126)s, %(ffcleunik_m126)s, %(nofact_m126)s, %(cofou_m126)s, %(typebc_m126)s, %(naf_m126)s, %(lbcleunik_m126)s, %(prix_m126)s, %(prixmon_m126)s, %(comon_m126)s, %(qtefa_m126)s, %(cofa_m126)s, %(desa1_m126)s, %(cobc_m126)s, %(daterec_m126)s, %(tva_m126)s, %(compt_m126)s, %(datesaisie_m126)s, %(unite_m126)s, %(coefunite_m126)s, %(codeemp_m126)s, %(i1cleunik_m126)s)]\n",
      "[parameters: {'code_projet_m0': 'C213178', 'fournisseur_m0': 'AEROTEC BLAGNAC', 'ffcleunik_m0': datetime.date(1905, 10, 8), 'nofact_m0': '2262023', 'cofou_m0': '00017', 'typebc_m0': 3, 'naf_m0': 1945, 'lbcleunik_m0': '1518', 'prix_m0': None, 'prixmon_m0': None, 'comon_m0': 9, 'qtefa_m0': 1, 'cofa_m0': 'EQUIPMT', 'desa1_m0': 'C213178-089', 'cobc_m0': '1580', 'daterec_m0': datetime.date(2023, 1, 2), 'tva_m0': 2, 'compt_m0': 6011000000, 'datesaisie_m0': datetime.date(2023, 1, 2), 'unite_m0': 'u', 'coefunite_m0': True, 'codeemp_m0': 'IVI', 'i1cleunik_m0': None, 'code_projet_m1': 'C202695', 'fournisseur_m1': 'SURUGUE MICKAEL', 'ffcleunik_m1': datetime.date(1905, 10, 9), 'nofact_m1': 'NDF23-006', 'cofou_m1': 'MSU', 'typebc_m1': 3, 'naf_m1': 1216, 'lbcleunik_m1': None, 'prix_m1': datetime.datetime(1900, 4, 13, 20, 24), 'prixmon_m1': datetime.datetime(1900, 4, 13, 20, 24), 'comon_m1': 9, 'qtefa_m1': 1, 'cofa_m1': 'MISSION', 'desa1_m1': 'A/R GRAULHET 15/12/22 PC6', 'cobc_m1': None, 'daterec_m1': datetime.date(2023, 1, 4), 'tva_m1': 2, 'compt_m1': 6256000000, 'datesaisie_m1': datetime.date(2023, 1, 12), 'unite_m1': 'u', 'coefunite_m1': True, 'codeemp_m1': 'AOD', 'i1cleunik_m1': None, 'code_projet_m2': 'C202695', 'fournisseur_m2': 'SURUGUE MICKAEL', 'ffcleunik_m2': datetime.date(1905, 10, 10), 'nofact_m2': 'NDF23-007' ... 2821 parameters truncated ... 'unite_m124': 'u', 'coefunite_m124': True, 'codeemp_m124': 'AOD', 'i1cleunik_m124': None, 'code_projet_m125': 'C212810', 'fournisseur_m125': 'FEDEX', 'ffcleunik_m125': datetime.date(1906, 2, 10), 'nofact_m125': '117649965', 'cofou_m125': '00079', 'typebc_m125': 3, 'naf_m125': 697, 'lbcleunik_m125': '1744', 'prix_m125': None, 'prixmon_m125': None, 'comon_m125': 9, 'qtefa_m125': 1, 'cofa_m125': 'DOUANE', 'desa1_m125': 'F 117649965', 'cobc_m125': '1672', 'daterec_m125': datetime.date(2023, 1, 18), 'tva_m125': 2, 'compt_m125': 6353000000, 'datesaisie_m125': datetime.date(2023, 1, 24), 'unite_m125': 'u', 'coefunite_m125': True, 'codeemp_m125': 'AOD', 'i1cleunik_m125': None, 'code_projet_m126': '2', 'fournisseur_m126': 'TOTALENERGIES MARKETING FRANCE', 'ffcleunik_m126': datetime.date(1906, 2, 11), 'nofact_m126': 'F3197104', 'cofou_m126': '00329', 'typebc_m126': 3, 'naf_m126': 1, 'lbcleunik_m126': None, 'prix_m126': datetime.datetime(1901, 8, 6, 15, 50, 24), 'prixmon_m126': datetime.datetime(1901, 8, 6, 15, 50, 24), 'comon_m126': 9, 'qtefa_m126': 1, 'cofa_m126': 'EQUIPMT', 'desa1_m126': 'PÉAGES ET CARBURANTS VÉHICULES', 'cobc_m126': None, 'daterec_m126': datetime.date(2023, 1, 15), 'tva_m126': 2, 'compt_m126': 6011000000, 'datesaisie_m126': datetime.date(2023, 1, 24), 'unite_m126': 'u', 'coefunite_m126': True, 'codeemp_m126': 'AOD', 'i1cleunik_m126': None}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/9h9h)\n",
      "\n",
      "Done. Feuilles analysées & importées: 1\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, unicodedata, warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# --- DB: SQLAlchemy\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy import types as satypes\n",
    "from sqlalchemy.exc import OperationalError\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "# ============== CONFIG ==============\n",
    "FILE_PATH = r\"C:\\globasoft\\aerotech\\fic\\FNP AEC projets - source.xlsx\"\n",
    "SHOW_SAMPLE = True\n",
    "TARGET_SCHEMA   = \"public\"\n",
    "IF_EXISTS_MODE  = \"replace\"   # \"replace\" ou \"append\"\n",
    "\n",
    "# ============== LOG ==============\n",
    "def now(): return datetime.now().strftime(\"%H:%M:%S\")\n",
    "def log(msg): print(f\"[{now()}] {msg}\", flush=True)\n",
    "\n",
    "# ============== ACCÈS DB ==============\n",
    "REQUIRED_KEYS = (\"PG_HOST\",\"PG_PORT\",\"PG_DB\",\"PG_USER\",\"PG_PASS\")\n",
    "\n",
    "def _collect_pg_config():\n",
    "    cfg, g = {}, globals()\n",
    "    for k in REQUIRED_KEYS:\n",
    "        if k in g and g[k]:\n",
    "            cfg[k] = g[k]\n",
    "    for k in REQUIRED_KEYS:\n",
    "        if k not in cfg or not cfg[k]:\n",
    "            v = os.getenv(k)\n",
    "            if v:\n",
    "                cfg[k] = v\n",
    "    if not cfg.get(\"PG_HOST\"):\n",
    "        cfg[\"PG_HOST\"] = \"dpg-d3jq6apr0fns738f81i0-a.frankfurt-postgres.render.com\"\n",
    "    cfg[\"PG_PORT\"] = int(cfg.get(\"PG_PORT\", 5432))\n",
    "    missing = [k for k in REQUIRED_KEYS if not cfg.get(k)]\n",
    "    if missing:\n",
    "        raise RuntimeError(\"Paramètres DB manquants: \" + \", \".join(missing))\n",
    "    return cfg\n",
    "\n",
    "def get_engine():\n",
    "    g = globals()\n",
    "    if \"engine\" in g and g[\"engine\"] is not None:\n",
    "        return g[\"engine\"]\n",
    "    cfg = _collect_pg_config()\n",
    "    conn_str = (\n",
    "        f\"postgresql+psycopg2://{cfg['PG_USER']}:{quote_plus(cfg['PG_PASS'])}\"\n",
    "        f\"@{cfg['PG_HOST']}:{cfg['PG_PORT']}/{cfg['PG_DB']}\"\n",
    "    )\n",
    "    eng = create_engine(\n",
    "        conn_str,\n",
    "        connect_args={\n",
    "            \"sslmode\": \"require\",\n",
    "            \"connect_timeout\": 5,\n",
    "            \"keepalives\": 1,\n",
    "            \"keepalives_idle\": 30,\n",
    "            \"keepalives_interval\": 10,\n",
    "            \"keepalives_count\": 3,\n",
    "        },\n",
    "        pool_pre_ping=True,\n",
    "        pool_recycle=1800,\n",
    "        pool_size=5,\n",
    "        max_overflow=5,\n",
    "    )\n",
    "    return eng\n",
    "\n",
    "# ============== UTILS ==============\n",
    "def strip_accents_lower(s):\n",
    "    if s is None or (isinstance(s, float) and pd.isna(s)): return \"\"\n",
    "    s = unicodedata.normalize(\"NFKD\", str(s))\n",
    "    s = \"\".join(c for c in s if not unicodedata.combining(c))\n",
    "    return s.lower().strip()\n",
    "\n",
    "def snake_id(s):\n",
    "    s = strip_accents_lower(s)\n",
    "    s = re.sub(r\"[\\s\\.\\-]+\", \"_\", s)\n",
    "    s = re.sub(r\"[^a-z0-9_]\", \"_\", s)\n",
    "    return re.sub(r\"_+\", \"_\", s).strip(\"_\") or \"col\"\n",
    "\n",
    "def pg_ident(name: str, maxlen=63) -> str:\n",
    "    return name[:maxlen]\n",
    "\n",
    "def parse_number_like(series: pd.Series) -> pd.Series:\n",
    "    x = series.astype(\"string\").str.replace(\"\\u00A0\",\" \", regex=False).str.replace(\" \",\"\", regex=False)\n",
    "    x = x.str.replace(r\"(?<=\\d)\\.(?=\\d{3}(?:\\D|$))\",\"\", regex=True)\n",
    "    x = x.str.replace(\",\",\".\", regex=False)\n",
    "    return pd.to_numeric(x, errors=\"coerce\")\n",
    "\n",
    "# ============== HEADER PICK + NORMALIZE ==============\n",
    "HEADER_HINTS = (\n",
    "    \"projet\",\"projets\",\"code\",\"id\",\"date\",\"mois\",\"année\",\"client\",\"fournisseur\",\"libelle\",\"libellé\",\n",
    "    \"montant\",\"quantite\",\"qté\",\"qte\",\"prix\",\"ttc\",\"ht\",\"statut\",\"status\",\"site\",\"type\",\"categorie\",\n",
    "    \"echeance\",\"échéance\",\"délai\",\"delai\",\"commentaire\",\"ref\",\"réf\"\n",
    ")\n",
    "\n",
    "def choose_header_row(df: pd.DataFrame, scan=25) -> int:\n",
    "    limit = min(len(df), scan)\n",
    "    cand_idx, cand_hits = None, -1\n",
    "    for i in range(limit):\n",
    "        row = df.iloc[i].astype(str)\n",
    "        hits = 0\n",
    "        for v in row:\n",
    "            t = strip_accents_lower(v)\n",
    "            if t and any(k in t for k in HEADER_HINTS):\n",
    "                hits += 1\n",
    "        if hits >= 2 and hits > cand_hits:\n",
    "            cand_idx, cand_hits = i, hits\n",
    "    if cand_idx is not None:\n",
    "        return cand_idx\n",
    "    best, idx = -1, 0\n",
    "    for i in range(limit):\n",
    "        row = df.iloc[i].astype(str)\n",
    "        non_empty = row.map(lambda x: x.strip()!=\"\").sum()\n",
    "        texty = row.map(lambda x: bool(re.search(r\"[A-Za-zÀ-ÿ]\", x))).sum()\n",
    "        score = non_empty*2 + texty\n",
    "        if score > best: best, idx = score, i\n",
    "    return idx\n",
    "\n",
    "def normalize_columns(header_vals):\n",
    "    cols, seen = [], {}\n",
    "    for v in header_vals:\n",
    "        s = snake_id(v) if (v is not None and str(v).strip()!=\"\") else \"col\"\n",
    "        seen[s] = seen.get(s,0)+1\n",
    "        cols.append(s if seen[s]==1 else f\"{s}_{seen[s]}\")\n",
    "    return cols\n",
    "\n",
    "def drop_empty_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.dropna(axis=1, how=\"all\")\n",
    "    blank_cols = [c for c in df.columns if df[c].dropna().astype(str).str.strip().eq(\"\").all()]\n",
    "    if blank_cols:\n",
    "        df = df.drop(columns=blank_cols)\n",
    "    return df\n",
    "\n",
    "# ============== INFÉRENCE TYPES ==============\n",
    "MAP_TRUE  = {\"true\",\"vrai\",\"oui\",\"yes\",\"1\",\"y\",\"o\"}\n",
    "MAP_FALSE = {\"false\",\"faux\",\"non\",\"no\",\"0\",\"n\"}\n",
    "\n",
    "DATE_TOKEN_RE = re.compile(\n",
    "    r\"(?:\\d{4}[-/\\.]\\d{1,2}[-/\\.]\\d{1,2})|(?:\\d{1,2}[-/\\.]\\d{1,2}[-/\\.]\\d{2,4})|\"\n",
    "    r\"(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec|janv|févr|fevr|avr|mai|juin|juil|sept|oct|nov|d[ée]c)\",\n",
    "    re.I\n",
    ")\n",
    "ISO_DATE_RE = re.compile(r\"^\\d{4}-\\d{2}-\\d{2}(?:[ T]\\d{2}:\\d{2}:\\d{2})?$\")\n",
    "COLNAME_DATE_HINTS = (\"date\",\"dt\",\"heure\",\"time\",\"echeance\",\"échéance\")\n",
    "\n",
    "def excel_serial_to_datetime(series: pd.Series) -> pd.Series:\n",
    "    vals = pd.to_numeric(series, errors=\"coerce\").astype(\"float64\")\n",
    "    vals[~np.isfinite(vals)] = np.nan\n",
    "    lower, upper = 60.0, 106750.0\n",
    "    mask = (vals >= lower) & (vals <= upper)\n",
    "    vals = vals.where(mask, np.nan)\n",
    "    base = pd.Timestamp(\"1899-12-30\")\n",
    "    td = pd.to_timedelta(vals, unit=\"D\", errors=\"coerce\")\n",
    "    dt = base + td\n",
    "    return pd.to_datetime(dt, errors=\"coerce\")\n",
    "\n",
    "def infer_col(col: pd.Series):\n",
    "    \"\"\"Retourne (serie_castée, TAG) avec vrais dtypes pandas, pas des strings formatées.\"\"\"\n",
    "    s = col.copy()\n",
    "    ss = s.astype(\"string\").str.strip()\n",
    "    ss = ss.where(~ss.fillna(\"\").eq(\"0\"), pd.NA)\n",
    "\n",
    "    # ISO\n",
    "    iso_mask = ss.fillna(\"\").str.match(ISO_DATE_RE)\n",
    "    if iso_mask.mean() >= 0.5:\n",
    "        dt_iso = pd.to_datetime(ss.where(iso_mask), errors=\"coerce\", dayfirst=False)\n",
    "        ok = dt_iso.notna().mean() if len(ss) else 0.0\n",
    "        if ok >= 0.5:\n",
    "            has_time = (dt_iso.dt.time.astype(str) != \"00:00:00\").mean() > 0.2\n",
    "            return (dt_iso, \"DATETIME\" if has_time else \"DATE\")\n",
    "\n",
    "    # Excel serial\n",
    "    as_num = pd.to_numeric(ss, errors=\"coerce\")\n",
    "    if len(ss):\n",
    "        safe_mask = (as_num >= 60) & (as_num <= 106750)\n",
    "        safe_ratio = safe_mask.mean()\n",
    "    else:\n",
    "        safe_ratio = 0.0\n",
    "    if (as_num.notna().mean() if len(ss) else 0.0) >= 0.9 and safe_ratio >= 0.7:\n",
    "        parsed = excel_serial_to_datetime(as_num)\n",
    "        ok = parsed.notna().mean() if len(ss) else 0.0\n",
    "        if ok >= 0.7:\n",
    "            has_time = (parsed.dt.time.astype(str) != \"00:00:00\").mean() > 0.2\n",
    "            return (parsed, \"DATETIME\" if has_time else \"DATE\")\n",
    "\n",
    "    # tokens / nom “datey”\n",
    "    colname_hint = any(h in strip_accents_lower(s.name or \"\") for h in COLNAME_DATE_HINTS)\n",
    "    date_token_ratio = ss.fillna(\"\").str.contains(DATE_TOKEN_RE, na=False).mean()\n",
    "    looks_datey = colname_hint or (date_token_ratio >= 0.30)\n",
    "    if looks_datey:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", message=\"Could not infer format.*\", category=UserWarning)\n",
    "            dt1 = pd.to_datetime(ss, errors=\"coerce\", dayfirst=True,  cache=True)\n",
    "            dt2 = pd.to_datetime(ss, errors=\"coerce\", dayfirst=False, cache=True)\n",
    "        dt = dt2 if dt2.notna().sum() > dt1.notna().sum() else dt1\n",
    "        ok = dt.notna().mean() if len(ss) else 0.0\n",
    "        ok_thresh = 0.50 if colname_hint else 0.70\n",
    "        if ok >= ok_thresh:\n",
    "            has_time = (dt.dt.time.astype(str) != \"00:00:00\").mean() > 0.2\n",
    "            return (dt, \"DATETIME\" if has_time else \"DATE\")\n",
    "\n",
    "    # bool\n",
    "    mb = ss.str.lower().map(lambda x: True if x in MAP_TRUE else (False if x in MAP_FALSE else pd.NA))\n",
    "    if (mb.notna().mean() if len(ss) else 0) >= 0.98:\n",
    "        return mb.astype(\"boolean\"), \"BOOL\"\n",
    "\n",
    "    # nombre\n",
    "    nums = parse_number_like(ss)\n",
    "    if (nums.notna().mean() if len(ss.dropna()) else 0) >= 0.85:\n",
    "        nz = nums.dropna()\n",
    "        if len(nz) and (np.mod(nz, 1) == 0).all():\n",
    "            return nums.astype(\"Int64\"), \"INT\"\n",
    "        return nums.astype(\"Float64\"), \"FLOAT\"\n",
    "\n",
    "    # texte\n",
    "    return ss.astype(\"string\"), \"STRING\"\n",
    "\n",
    "def sa_type(tag: str):\n",
    "    return {\n",
    "        \"DATE\": satypes.Date(),\n",
    "        \"DATETIME\": satypes.DateTime(),  # timestamp without time zone\n",
    "        \"INT\": satypes.Integer(),\n",
    "        \"FLOAT\": satypes.Float(precision=53),\n",
    "        \"BOOL\": satypes.Boolean(),\n",
    "        \"STRING\": satypes.Text()\n",
    "    }.get(tag, satypes.Text())\n",
    "\n",
    "def prepare_for_sql(df: pd.DataFrame, schema_tags: dict):\n",
    "    out = df.copy()\n",
    "    for c, tag in schema_tags.items():\n",
    "        if tag == \"DATE\":\n",
    "            out[c] = pd.to_datetime(out[c], errors=\"coerce\").dt.date\n",
    "        elif tag == \"DATETIME\":\n",
    "            out[c] = pd.to_datetime(out[c], errors=\"coerce\")\n",
    "    dtype_map = {c: sa_type(tag) for c, tag in schema_tags.items()}\n",
    "    return out, dtype_map\n",
    "\n",
    "# ============== MAIN ==============\n",
    "def main():\n",
    "    xlsx = Path(FILE_PATH)\n",
    "    log(f\"Fichier: {xlsx}\")\n",
    "    if not xlsx.exists():\n",
    "        log(\"[error] Fichier introuvable\"); return\n",
    "\n",
    "    try:\n",
    "        sheets = pd.read_excel(xlsx, sheet_name=None, engine=\"openpyxl\", header=None)\n",
    "    except Exception as e:\n",
    "        log(f\"[error] Lecture échouée: {e}\"); return\n",
    "\n",
    "    # Connexion DB\n",
    "    try:\n",
    "        engine = get_engine()\n",
    "        with engine.connect() as conn:\n",
    "            ver = conn.execute(text(\"select version();\")).scalar()\n",
    "            log(\"[ok] Connecté PostgreSQL\")\n",
    "            log(ver)\n",
    "    except (OperationalError, RuntimeError) as e:\n",
    "        log(f\"[error] Connexion PostgreSQL échouée: {e}\")\n",
    "        return\n",
    "\n",
    "    file_base = snake_id(xlsx.stem)\n",
    "    done = 0\n",
    "\n",
    "    for name, raw in sheets.items():\n",
    "        log(f\"\\n[feuille] {name}: shape initiale={raw.shape}\")\n",
    "\n",
    "        raw = raw.dropna(how=\"all\", axis=0).dropna(how=\"all\", axis=1)\n",
    "        log(f\"[feuille] {name}: après drop vides -> {raw.shape}\")\n",
    "        if raw.empty:\n",
    "            log(f\"[feuille] {name}: vide, on passe.\"); continue\n",
    "\n",
    "        h = choose_header_row(raw, scan=25)\n",
    "        log(f\"[feuille] {name}: header choisi à la ligne {h}\")\n",
    "        cols = normalize_columns(raw.iloc[h].tolist())\n",
    "        log(f\"[feuille] {name}: colonnes normalisées -> {', '.join(cols)}\")\n",
    "\n",
    "        df = raw.iloc[h+1:].copy()\n",
    "        df.columns = cols\n",
    "        df = df.dropna(how=\"all\")\n",
    "        df = drop_empty_columns(df)\n",
    "        log(f\"[feuille] {name}: shape après nettoyage colonnes -> {df.shape}\")\n",
    "        if df.empty:\n",
    "            log(f\"[feuille] {name}: vide après normalisation, on passe.\"); continue\n",
    "\n",
    "        # Inférence types\n",
    "        schema = {}\n",
    "        for c in df.columns:\n",
    "            casted, tag = infer_col(df[c])\n",
    "            df[c] = casted\n",
    "            schema[c] = tag\n",
    "\n",
    "        # Nom de table: public.<file> si 1 feuille, sinon public.<file>__<sheet>\n",
    "        sheet_base = snake_id(name)\n",
    "        table_name = file_base if len(sheets) == 1 else f\"{file_base}__{sheet_base}\"\n",
    "        table_name = pg_ident(table_name)\n",
    "\n",
    "        # Affichage\n",
    "        print(f\"\\n--- Feuille: {name} -> {TARGET_SCHEMA}.{table_name} ---\")\n",
    "        print(f\"rows={len(df)} | cols={df.shape[1]}\")\n",
    "        print(\"Colonnes:\", \", \".join(df.columns.astype(str)))\n",
    "        print(\"\\nSchema détecté:\")\n",
    "        for c in df.columns:\n",
    "            print(f\"  - {c}: {schema[c]} -> {sa_type(schema[c]).__class__.__name__}\")\n",
    "\n",
    "        if SHOW_SAMPLE:\n",
    "            with pd.option_context(\"display.max_columns\", 120, \"display.width\", 220):\n",
    "                print(\"\\nSample (top 10):\")\n",
    "                print(df.head(10))\n",
    "\n",
    "        # Insertion DB\n",
    "        try:\n",
    "            df_sql, dtype_map = prepare_for_sql(df, schema)\n",
    "            df_sql.to_sql(\n",
    "                name=table_name,\n",
    "                con=engine,\n",
    "                schema=TARGET_SCHEMA,\n",
    "                if_exists=IF_EXISTS_MODE,\n",
    "                index=False,\n",
    "                dtype=dtype_map,\n",
    "                method=\"multi\",\n",
    "                chunksize=1000\n",
    "            )\n",
    "            log(f\"[ok] Inserted into {TARGET_SCHEMA}.{table_name}\")\n",
    "            done += 1\n",
    "        except Exception as e:\n",
    "            log(f\"[error] Échec insertion {TARGET_SCHEMA}.{table_name}: {e}\")\n",
    "\n",
    "    print(f\"\\nDone. Feuilles analysées & importées: {done}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb1a388-6d54-45d3-9317-41e9bc0826c9",
   "metadata": {},
   "source": [
    "# Relevé pointages AEB.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b77832e-161e-444c-9c0f-26345bd8376b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:54:35] Fichier: C:\\globasoft\\aerotech\\fic\\Relevé pointages AEB.xlsx\n",
      "[15:54:35] [ok] Connecté PostgreSQL\n",
      "[15:54:35] PostgreSQL 17.6 (Debian 17.6-1.pgdg12+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14+deb12u1) 12.2.0, 64-bit\n",
      "[15:54:38] \n",
      "[feuille] Sheet1: shape initiale=(8980, 27)\n",
      "[15:54:38] [feuille] Sheet1: après drop vides -> (8980, 27)\n",
      "[15:54:38] [feuille] Sheet1: header choisi à la ligne 0\n",
      "[15:54:38] [feuille] Sheet1: shape après en-têtes -> (8979, 27)\n",
      "\n",
      "--- Feuille: Sheet1 -> public.releve_pointages_aeb (SCHÉMA SOURCE STRICT) ---\n",
      "rows=8979 | cols=27\n",
      "\n",
      "Mapping colonnes (Excel → nom_pg) :\n",
      "  - Trigramme  ->  trigramme\n",
      "  - NOM  ->  nom\n",
      "  - DATE  ->  date\n",
      "  - Cat Pointage  ->  cat_pointage\n",
      "  - N° DOSSIER  ->  n_dossier\n",
      "  - CATEGORIE  ->  categorie\n",
      "  - OT  ->  ot\n",
      "  - ATA  ->  ata\n",
      "  - Type de tâche  ->  type_de_tache\n",
      "  - Commentaires  ->  commentaires\n",
      "  - Hrs  ->  hrs\n",
      "  - Hrs supp  ->  hrs_supp\n",
      "  - Heures Totals  ->  heures_totals\n",
      "  - Société  ->  societe\n",
      "  - SERVICE  ->  service\n",
      "  - Code Projet  ->  code_projet\n",
      "  - TYPE APPAREIL  ->  type_appareil\n",
      "  - Client  ->  client\n",
      "  - BU  ->  bu\n",
      "  - IMMAT  ->  immat\n",
      "  - WP  ->  wp\n",
      "  - SEMAINE  ->  semaine\n",
      "  - MOIS  ->  mois\n",
      "  - ANNEE  ->  annee\n",
      "  - Cat point  ->  cat_point\n",
      "  - ANNEE - SEMAINE  ->  annee_semaine\n",
      "  - Mois.  ->  mois_2\n",
      "\n",
      "Schema détecté (types PostgreSQL) :\n",
      "  - trigramme: Text  (source: Trigramme, tag: STRING)\n",
      "  - nom: Text  (source: NOM, tag: STRING)\n",
      "  - date: Date  (source: DATE, tag: DATE)\n",
      "  - cat_pointage: Text  (source: Cat Pointage, tag: STRING)\n",
      "  - n_dossier: Text  (source: N° DOSSIER, tag: STRING)\n",
      "  - categorie: Text  (source: CATEGORIE, tag: STRING)\n",
      "  - ot: Text  (source: OT, tag: STRING)\n",
      "  - ata: Text  (source: ATA, tag: STRING)\n",
      "  - type_de_tache: Text  (source: Type de tâche, tag: STRING)\n",
      "  - commentaires: Text  (source: Commentaires, tag: STRING)\n",
      "  - hrs: Float  (source: Hrs, tag: FLOAT)\n",
      "  - hrs_supp: Float  (source: Hrs supp, tag: FLOAT)\n",
      "  - heures_totals: Float  (source: Heures Totals, tag: FLOAT)\n",
      "  - societe: Text  (source: Société, tag: STRING)\n",
      "  - service: Text  (source: SERVICE, tag: STRING)\n",
      "  - code_projet: Text  (source: Code Projet, tag: STRING)\n",
      "  - type_appareil: Text  (source: TYPE APPAREIL, tag: STRING)\n",
      "  - client: Text  (source: Client, tag: STRING)\n",
      "  - bu: Text  (source: BU, tag: STRING)\n",
      "  - immat: Text  (source: IMMAT, tag: STRING)\n",
      "  - wp: Text  (source: WP, tag: STRING)\n",
      "  - semaine: Integer  (source: SEMAINE, tag: INT)\n",
      "  - mois: Integer  (source: MOIS, tag: INT)\n",
      "  - annee: Date  (source: ANNEE, tag: DATE)\n",
      "  - cat_point: Text  (source: Cat point, tag: STRING)\n",
      "  - annee_semaine: Text  (source: ANNEE - SEMAINE, tag: STRING)\n",
      "  - mois_2: Text  (source: Mois., tag: STRING)\n",
      "\n",
      "Sample (top 10) :\n",
      "   Trigramme                    NOM       DATE Cat Pointage      N° DOSSIER CATEGORIE      OT   ATA Type de tâche      Commentaires  Hrs  Hrs supp  Heures Totals Société            SERVICE Code Projet TYPE APPAREIL                 Client    BU    IMMAT  \\\n",
      "1        GLE          GALTIE Franck 2025-01-18      Dossier  B0200AEB240326      <NA>  OE-INT  <NA>          <NA>  GESTION CHANTIER  1.5      <NA>            1.5     AEB        MAINTENANCE     B240199        B200GT  GIE AIRNET\n",
      "(NICOLLIN)     0   F-HDLN   \n",
      "2        BAD       ADJEROUD Bastian 2025-01-01      Absence            <NA>      <NA>    <NA>  <NA>          <NA>             FERIE  8.0      <NA>            8.0     AEB               CAMO        <NA>          <NA>                   <NA>  <NA>  Absence   \n",
      "3        BLY          BAILLY Célian 2025-01-01      Absence            <NA>      <NA>    <NA>  <NA>          <NA>        Jour férié  8.0      <NA>            8.0     AEB        MAINTENANCE        <NA>          <NA>                   <NA>  <NA>  Absence   \n",
      "4        MBJ  BEN JOMAA Mohamed Ali 2025-01-01      Absence            <NA>      <NA>    <NA>  <NA>          <NA>             Férié  8.0      <NA>            8.0     AEB               CAMO        <NA>          <NA>                   <NA>  <NA>  Absence   \n",
      "5        CCE         CEZERAC Cédric 2025-01-01      Absence            <NA>      <NA>    <NA>  <NA>          <NA>             FERIE  8.0      <NA>            8.0     AEY        MAINTENANCE        <NA>          <NA>                   <NA>  <NA>  Absence   \n",
      "6        CTR         COUTURIER Yves 2025-01-01      Absence            <NA>      <NA>    <NA>  <NA>          <NA>     ARRET MALADIE  8.0      <NA>            8.0     AEB        MAINTENANCE        <NA>          <NA>                   <NA>  <NA>  Absence   \n",
      "7        NDO      DONNADIEU Nicolas 2025-01-01      Absence            <NA>      <NA>    <NA>  <NA>          <NA>             FERIE  8.0      <NA>            8.0     AEY  ACHATS/LOGISTIQUE        <NA>          <NA>                   <NA>  <NA>  Absence   \n",
      "8        DQE     DUQUESNE Guillaume 2025-01-01      Absence            <NA>      <NA>    <NA>  <NA>          <NA>             FERIE  8.0      <NA>            8.0     AEB        MAINTENANCE        <NA>          <NA>                   <NA>  <NA>  Absence   \n",
      "9        FCX     FAUCHEUX Guillaume 2025-01-01      Absence      JOUR FERIE      <NA>    <NA>  <NA>          <NA>             FERIE  8.0      <NA>            8.0     AEB   BUREAU TECHNIQUE        <NA>          <NA>                   <NA>  <NA>  Absence   \n",
      "10       GLE          GALTIE Franck 2025-01-01      Absence            <NA>      <NA>    <NA>  <NA>          <NA>             FERIE  8.0      <NA>            8.0     AEB        MAINTENANCE        <NA>          <NA>                   <NA>  <NA>  Absence   \n",
      "\n",
      "         WP  SEMAINE  MOIS      ANNEE   Cat point ANNEE - SEMAINE    Mois.  \n",
      "1      2372        3     1 1905-07-17  FACTURABLE          2025-3  Janvier  \n",
      "2   Absence        1     1 1905-07-17     ABSENCE          2025-1  Janvier  \n",
      "3   Absence        1     1 1905-07-17     ABSENCE          2025-1  Janvier  \n",
      "4   Absence        1     1 1905-07-17     ABSENCE          2025-1  Janvier  \n",
      "5   Absence        1     1 1905-07-17     ABSENCE          2025-1  Janvier  \n",
      "6   Absence        1     1 1905-07-17     ABSENCE          2025-1  Janvier  \n",
      "7   Absence        1     1 1905-07-17     ABSENCE          2025-1  Janvier  \n",
      "8   Absence        1     1 1905-07-17     ABSENCE          2025-1  Janvier  \n",
      "9   Absence        1     1 1905-07-17     ABSENCE          2025-1  Janvier  \n",
      "10  Absence        1     1 1905-07-17     ABSENCE          2025-1  Janvier  \n",
      "[15:54:50] [ok] Inserted into public.releve_pointages_aeb\n",
      "\n",
      "Done. Feuilles analysées & importées: 1\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, unicodedata, warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# --- DB: SQLAlchemy\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy import types as satypes\n",
    "from sqlalchemy.exc import OperationalError\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "# ============== CONFIG ==============\n",
    "FILE_PATH = r\"C:\\globasoft\\aerotech\\fic\\Relevé pointages AEB.xlsx\"\n",
    "SHOW_SAMPLE = True\n",
    "STRICT_SOURCE_SCHEMA = True      # on suit EXACTEMENT le fichier (pas d'ajout/remap)\n",
    "TARGET_SCHEMA = \"public\"\n",
    "IF_EXISTS_MODE = \"replace\"       # \"replace\" ou \"append\"\n",
    "\n",
    "# ============== LOG ==============\n",
    "def now(): return datetime.now().strftime(\"%H:%M:%S\")\n",
    "def log(msg): print(f\"[{now()}] {msg}\", flush=True)\n",
    "\n",
    "# ============== ACCÈS DB ==============\n",
    "REQUIRED_KEYS = (\"PG_HOST\",\"PG_PORT\",\"PG_DB\",\"PG_USER\",\"PG_PASS\")\n",
    "\n",
    "def _collect_pg_config():\n",
    "    cfg, g = {}, globals()\n",
    "    # 1) prendre éventuels globals (si définis dans un 1er bloc)\n",
    "    for k in REQUIRED_KEYS:\n",
    "        if k in g and g[k]:\n",
    "            cfg[k] = g[k]\n",
    "    # 2) compléter via variables d'environnement\n",
    "    for k in REQUIRED_KEYS:\n",
    "        if k not in cfg or not cfg[k]:\n",
    "            v = os.getenv(k)\n",
    "            if v:\n",
    "                cfg[k] = v\n",
    "    # défauts pratiques (Render)\n",
    "    if not cfg.get(\"PG_HOST\"):\n",
    "        cfg[\"PG_HOST\"] = \"dpg-d3jq6apr0fns738f81i0-a.frankfurt-postgres.render.com\"\n",
    "    cfg[\"PG_PORT\"] = int(cfg.get(\"PG_PORT\", 5432))\n",
    "    missing = [k for k in REQUIRED_KEYS if not cfg.get(k)]\n",
    "    if missing:\n",
    "        raise RuntimeError(\"Paramètres DB manquants: \" + \", \".join(missing))\n",
    "    return cfg\n",
    "\n",
    "def get_engine():\n",
    "    g = globals()\n",
    "    if \"engine\" in g and g[\"engine\"] is not None:\n",
    "        return g[\"engine\"]\n",
    "    cfg = _collect_pg_config()\n",
    "    conn_str = (\n",
    "        f\"postgresql+psycopg2://{cfg['PG_USER']}:{quote_plus(cfg['PG_PASS'])}\"\n",
    "        f\"@{cfg['PG_HOST']}:{cfg['PG_PORT']}/{cfg['PG_DB']}\"\n",
    "    )\n",
    "    eng = create_engine(\n",
    "        conn_str,\n",
    "        connect_args={\n",
    "            \"sslmode\": \"require\",\n",
    "            \"connect_timeout\": 5,\n",
    "            \"keepalives\": 1,\n",
    "            \"keepalives_idle\": 30,\n",
    "            \"keepalives_interval\": 10,\n",
    "            \"keepalives_count\": 3,\n",
    "        },\n",
    "        pool_pre_ping=True,\n",
    "        pool_recycle=1800,\n",
    "        pool_size=5,\n",
    "        max_overflow=5,\n",
    "    )\n",
    "    return eng\n",
    "\n",
    "# ============== UTILS ==============\n",
    "def strip_accents_lower(s):\n",
    "    if s is None or (isinstance(s, float) and pd.isna(s)): return \"\"\n",
    "    s = unicodedata.normalize(\"NFKD\", str(s))\n",
    "    s = \"\".join(c for c in s if not unicodedata.combining(c))\n",
    "    return s.lower().strip()\n",
    "\n",
    "def snake_id(s):\n",
    "    s = strip_accents_lower(s)\n",
    "    s = re.sub(r\"[\\s\\.\\-]+\", \"_\", s)\n",
    "    s = re.sub(r\"[^a-z0-9_]\", \"_\", s)\n",
    "    return re.sub(r\"_+\", \"_\", s).strip(\"_\") or \"col\"\n",
    "\n",
    "def make_unique_columns(cols):\n",
    "    out, seen = [], {}\n",
    "    for c in cols:\n",
    "        if c not in seen:\n",
    "            seen[c] = 1\n",
    "            out.append(c)\n",
    "        else:\n",
    "            seen[c] += 1\n",
    "            out.append(f\"{c}_{seen[c]}\")\n",
    "    return out\n",
    "\n",
    "def parse_number_like(series: pd.Series) -> pd.Series:\n",
    "    x = series.astype(\"string\").str.replace(\"\\u00A0\",\" \", regex=False).str.replace(\" \",\"\", regex=False)\n",
    "    x = x.str.replace(r\"(?<=\\d)\\.(?=\\d{3}(?:\\D|$))\",\"\", regex=True)\n",
    "    x = x.str.replace(\",\",\".\", regex=False)\n",
    "    return pd.to_numeric(x, errors=\"coerce\")\n",
    "\n",
    "def drop_empty_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.dropna(axis=1, how=\"all\")\n",
    "    blank_idx = []\n",
    "    for j in range(df.shape[1]):\n",
    "        s = df.iloc[:, j]\n",
    "        if s.dropna().astype(str).str.strip().eq(\"\").all():\n",
    "            blank_idx.append(j)\n",
    "    if blank_idx:\n",
    "        log(f\"[drop_empty_columns] suppression colonnes blanches (pos): {blank_idx}\")\n",
    "        df = df.drop(df.columns[blank_idx], axis=1)\n",
    "    return df\n",
    "\n",
    "# ============== HEADER PICK ==============\n",
    "HEADER_HINTS = (\n",
    "    # génériques\n",
    "    \"projet\",\"projets\",\"code\",\"id\",\"réf\",\"ref\",\"libelle\",\"libellé\",\"intitulé\",\n",
    "    \"client\",\"fournisseur\",\"chef de projet\",\"cp\",\"cdp\",\"manager\",\n",
    "    \"statut\",\"status\",\"phase\",\"categorie\",\"catégorie\",\"type\",\n",
    "    \"date\",\"heure\",\"time\",\"période\",\"periode\",\"echeance\",\"échéance\",\n",
    "    \"budget\",\"montant\",\"cout\",\"coût\",\"prix\",\"ht\",\"ttc\",\"avancement\",\"progress\",\"%\",\"taux\",\n",
    "    \"site\",\"section analytique\",\"analytique\",\"commentaire\",\"observations\",\"notes\",\"remarques\",\n",
    "    # spécifiques vus dans le fichier de pointage\n",
    "    \"trigramme\",\"nom\",\"cat pointage\",\"n° dossier\",\"categorie\",\"ot\",\"ata\",\"type de tâche\",\"commentaires\",\n",
    "    \"bu\",\"immat\",\"wp\",\"semaine\",\"mois\",\"annee\",\"année\",\"cat point\",\"annee - semaine\",\"mois.\"\n",
    ")\n",
    "\n",
    "def choose_header_row(df: pd.DataFrame, scan=25) -> int:\n",
    "    limit = min(len(df), scan)\n",
    "    cand_idx, cand_hits = None, -1\n",
    "    for i in range(limit):\n",
    "        row = df.iloc[i].astype(str)\n",
    "        hits = 0\n",
    "        for v in row:\n",
    "            t = strip_accents_lower(v)\n",
    "            if t and any(k in t for k in HEADER_HINTS):\n",
    "                hits += 1\n",
    "        if hits >= 2 and hits > cand_hits:\n",
    "            cand_idx, cand_hits = i, hits\n",
    "    if cand_idx is not None:\n",
    "        return cand_idx\n",
    "\n",
    "    best, idx = -1, 0\n",
    "    for i in range(limit):\n",
    "        row = df.iloc[i].astype(str)\n",
    "        non_empty = row.map(lambda x: x.strip()!=\"\").sum()\n",
    "        texty = row.map(lambda x: bool(re.search(r\"[A-Za-zÀ-ÿ]\", x))).sum()\n",
    "        score = non_empty*2 + texty\n",
    "        if score > best: best, idx = score, i\n",
    "    return idx\n",
    "\n",
    "# ============== INFÉRENCE TYPES (→ PostgreSQL) ==============\n",
    "MAP_TRUE  = {\"true\",\"vrai\",\"oui\",\"yes\",\"1\",\"y\",\"o\"}\n",
    "MAP_FALSE = {\"false\",\"faux\",\"non\",\"no\",\"0\",\"n\"}\n",
    "\n",
    "DATE_TOKEN_RE = re.compile(\n",
    "    r\"(?:\\d{4}[-/\\.]\\d{1,2}[-/\\.]\\d{1,2})|(?:\\d{1,2}[-/\\.]\\d{1,2}[-/\\.]\\d{2,4})|\"\n",
    "    r\"(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec|janv|févr|fevr|avr|mai|juin|juil|sept|oct|nov|d[ée]c)\",\n",
    "    re.I\n",
    ")\n",
    "ISO_DATE_RE = re.compile(r\"^\\d{4}-\\d{2}-\\d{2}(?:[ T]\\d{2}:\\d{2}:\\d{2})?$\")\n",
    "COLNAME_DATE_HINTS = (\"date\",\"dt\",\"heure\",\"time\",\"echeance\",\"échéance\",\"debut\",\"début\",\"fin\",\"période\",\"periode\",\"semaine\",\"mois\",\"année\",\"annee\")\n",
    "\n",
    "AMOUNT_NAME_HINTS = (\n",
    "    \"montant\",\"debit\",\"débit\",\"credit\",\"crédit\",\"solde\",\"budget\",\"ht\",\"ttc\",\n",
    "    \"amount\",\"total\",\"prix\",\"coût\",\"cout\",\"heures\",\"h\"\n",
    ")\n",
    "CODE_LIKE_HINTS = (\"code\",\"nature\",\"plan\",\"compte\",\"sop\",\"section\",\"niveau\",\"trigramme\",\"immat\",\"ot\",\"ata\",\"wp\",\"n° dossier\",\"n_dossier\",\"dossier\",\"cat point\",\"cat pointage\")\n",
    "\n",
    "def colname_has(hints, name):\n",
    "    n = strip_accents_lower(name or \"\")\n",
    "    return any(h in n for h in hints)\n",
    "\n",
    "def excel_serial_to_datetime(series: pd.Series) -> pd.Series:\n",
    "    vals = pd.to_numeric(series, errors=\"coerce\").astype(\"float64\")\n",
    "    vals[~np.isfinite(vals)] = np.nan\n",
    "    lower, upper = 60.0, 60000.0  # ~ 1900..2064\n",
    "    mask = (vals >= lower) & (vals <= upper)\n",
    "    n_out = int((~mask & ~pd.isna(vals)).sum())\n",
    "    if n_out:\n",
    "        log(f\"[excel_serial_to_datetime] valeurs hors fenêtre [{int(lower)}, {int(upper)}] -> NaN: {n_out}\")\n",
    "    base = pd.Timestamp(\"1899-12-30\")\n",
    "    td = pd.to_timedelta(vals.where(mask, np.nan), unit=\"D\", errors=\"coerce\")\n",
    "    dt = base + td\n",
    "    return pd.to_datetime(dt, errors=\"coerce\")\n",
    "\n",
    "def infer_col(col: pd.Series):\n",
    "    \"\"\"\n",
    "    Retourne (serie_casted, tag) avec tag ∈ {\"DATE\",\"DATETIME\",\"INT\",\"FLOAT\",\"BOOL\",\"STRING\"}.\n",
    "    On renvoie de VRAIS dtype pandas (datetime/int/float/bool/string), pas des strings formatées.\n",
    "    \"\"\"\n",
    "    s = col.copy()\n",
    "    ss = s.astype(\"string\").str.strip()\n",
    "\n",
    "    # 0) ISO direct\n",
    "    iso_mask = ss.fillna(\"\").str.match(ISO_DATE_RE)\n",
    "    if len(ss) and iso_mask.mean() >= 0.5:\n",
    "        dt_iso = pd.to_datetime(ss.where(iso_mask), errors=\"coerce\", dayfirst=False)\n",
    "        ok = dt_iso.notna().mean()\n",
    "        if ok >= 0.5:\n",
    "            has_time = (dt_iso.dt.time.astype(str) != \"00:00:00\").mean() > 0.2\n",
    "            return (dt_iso, \"DATETIME\" if has_time else \"DATE\")\n",
    "\n",
    "    # 1) Excel serial dates (restreint)\n",
    "    as_num = pd.to_numeric(ss, errors=\"coerce\")\n",
    "    safe_mask = (as_num >= 60) & (as_num <= 60000)\n",
    "    safe_ratio = safe_mask.mean() if len(ss) else 0.0\n",
    "\n",
    "    colname_hint = colname_has(COLNAME_DATE_HINTS, s.name)\n",
    "    high_vals_ratio = (as_num >= 20000).mean() if len(ss) else 0.0  # 20000 ~ 1954\n",
    "\n",
    "    if (as_num.notna().mean() if len(ss) else 0.0) >= 0.9 and safe_ratio >= 0.7 and (colname_hint or high_vals_ratio >= 0.2):\n",
    "        parsed = excel_serial_to_datetime(as_num)\n",
    "        ok = parsed.notna().mean() if len(ss) else 0.0\n",
    "        if ok >= 0.7:\n",
    "            has_time = (parsed.dt.time.astype(str) != \"00:00:00\").mean() > 0.2\n",
    "            return (parsed, \"DATETIME\" if has_time else \"DATE\")\n",
    "\n",
    "    # 2) tokens de date / nom “datey”\n",
    "    date_token_ratio = ss.fillna(\"\").str.contains(DATE_TOKEN_RE, na=False).mean()\n",
    "    looks_datey = colname_hint or (date_token_ratio >= 0.30)\n",
    "    if looks_datey:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", message=\"Could not infer format.*\", category=UserWarning)\n",
    "            dt1 = pd.to_datetime(ss, errors=\"coerce\", dayfirst=True,  cache=True)\n",
    "            dt2 = pd.to_datetime(ss, errors=\"coerce\", dayfirst=False, cache=True)\n",
    "        dt = dt2 if dt2.notna().sum() > dt1.notna().sum() else dt1\n",
    "        ok = dt.notna().mean() if len(ss) else 0.0\n",
    "        ok_thresh = 0.50 if colname_hint else 0.70\n",
    "        if ok >= ok_thresh:\n",
    "            has_time = (dt.dt.time.astype(str) != \"00:00:00\").mean() > 0.2\n",
    "            return (dt, \"DATETIME\" if has_time else \"DATE\")\n",
    "\n",
    "    # 3) bool strict\n",
    "    mb = ss.str.lower().map(lambda x: True if x in MAP_TRUE else (False if x in MAP_FALSE else pd.NA))\n",
    "    if len(ss) and mb.notna().mean() >= 0.98:\n",
    "        return mb.astype(\"boolean\"), \"BOOL\"\n",
    "\n",
    "    # 3bis) colonnes monétaires / heures\n",
    "    if colname_has(AMOUNT_NAME_HINTS, s.name):\n",
    "        nums_hint = parse_number_like(ss)\n",
    "        if nums_hint.notna().any():\n",
    "            nz = nums_hint.dropna()\n",
    "            if len(nz) and (np.mod(nz, 1) == 0).all():\n",
    "                return nums_hint.astype(\"Int64\"), \"INT\"\n",
    "            return nums_hint.astype(\"Float64\"), \"FLOAT\"\n",
    "\n",
    "    # 3ter) colonnes \"code-like\" : garder du texte\n",
    "    if colname_has(CODE_LIKE_HINTS, s.name):\n",
    "        return ss.astype(\"string\"), \"STRING\"\n",
    "\n",
    "    # 4) nombre générique\n",
    "    nums = parse_number_like(ss)\n",
    "    if (nums.notna().mean() if len(ss) else 0) >= 0.85:\n",
    "        nz = nums.dropna()\n",
    "        if len(nz) and (np.mod(nz, 1) == 0).all():\n",
    "            return nums.astype(\"Int64\"), \"INT\"\n",
    "        return nums.astype(\"Float64\"), \"FLOAT\"\n",
    "\n",
    "    # 5) texte\n",
    "    return ss.astype(\"string\"), \"STRING\"\n",
    "\n",
    "def sa_type(tag: str):\n",
    "    return {\n",
    "        \"DATE\": satypes.Date(),\n",
    "        \"DATETIME\": satypes.DateTime(),    # timestamp without time zone\n",
    "        \"INT\": satypes.Integer(),\n",
    "        \"FLOAT\": satypes.Float(precision=53),\n",
    "        \"BOOL\": satypes.Boolean(),\n",
    "        \"STRING\": satypes.Text()\n",
    "    }.get(tag, satypes.Text())\n",
    "\n",
    "def prepare_for_sql(df: pd.DataFrame, schema_tags: dict):\n",
    "    out = df.copy()\n",
    "    for c, tag in schema_tags.items():\n",
    "        if tag == \"DATE\":\n",
    "            out[c] = pd.to_datetime(out[c], errors=\"coerce\").dt.date\n",
    "        elif tag == \"DATETIME\":\n",
    "            out[c] = pd.to_datetime(out[c], errors=\"coerce\")\n",
    "    dtype_map = {c: sa_type(tag) for c, tag in schema_tags.items()}\n",
    "    return out, dtype_map\n",
    "\n",
    "def pg_ident(name: str, maxlen=63) -> str:\n",
    "    return name[:maxlen]\n",
    "\n",
    "# ============== MAIN ==============\n",
    "def main():\n",
    "    xlsx = Path(FILE_PATH)\n",
    "    log(f\"Fichier: {xlsx}\")\n",
    "    if not xlsx.exists():\n",
    "        log(\"[error] Fichier introuvable\"); return\n",
    "\n",
    "    # Connexion DB\n",
    "    try:\n",
    "        engine = get_engine()\n",
    "        with engine.connect() as conn:\n",
    "            ver = conn.execute(text(\"select version();\")).scalar()\n",
    "            log(\"[ok] Connecté PostgreSQL\")\n",
    "            log(ver)\n",
    "    except (OperationalError, RuntimeError) as e:\n",
    "        log(f\"[error] Connexion PostgreSQL échouée: {e}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        sheets = pd.read_excel(xlsx, sheet_name=None, engine=\"openpyxl\", header=None)\n",
    "    except Exception as e:\n",
    "        log(f\"[error] Lecture échouée: {e}\"); return\n",
    "\n",
    "    file_base = snake_id(xlsx.stem)\n",
    "    done = 0\n",
    "\n",
    "    for name, raw in sheets.items():\n",
    "        log(f\"\\n[feuille] {name}: shape initiale={raw.shape}\")\n",
    "\n",
    "        # nettoyage vide\n",
    "        raw = raw.dropna(how=\"all\", axis=0).dropna(how=\"all\", axis=1)\n",
    "        log(f\"[feuille] {name}: après drop vides -> {raw.shape}\")\n",
    "        if raw.empty:\n",
    "            log(f\"[feuille] {name}: vide, on passe.\")\n",
    "            continue\n",
    "\n",
    "        # repère l'entête dans le brut (schéma source strict)\n",
    "        h = choose_header_row(raw, scan=25)\n",
    "        log(f\"[feuille] {name}: header choisi à la ligne {h}\")\n",
    "\n",
    "        # ===== VUE SOURCE STRICTE =====\n",
    "        df_src = raw.iloc[h+1:].copy()\n",
    "        src_cols_original = raw.iloc[h].tolist()  # libellés EXACTS du fichier\n",
    "        df_src.columns = src_cols_original\n",
    "        df_src = df_src.dropna(how=\"all\").copy()\n",
    "        df_src = drop_empty_columns(df_src)\n",
    "        log(f\"[feuille] {name}: shape après en-têtes -> {df_src.shape}\")\n",
    "        if df_src.empty:\n",
    "            log(f\"[feuille] {name}: vide après normalisation, on passe.\")\n",
    "            continue\n",
    "\n",
    "        # noms PostgreSQL correspondants (snake_case + unicité)\n",
    "        pg_cols = make_unique_columns([snake_id(c) for c in df_src.columns])\n",
    "\n",
    "        # inférence STRICTE sur colonnes d'origine\n",
    "        schema_src = {}\n",
    "        casted_df = df_src.copy()\n",
    "        for c in list(df_src.columns):\n",
    "            casted, tag = infer_col(df_src[c])\n",
    "            casted_df[c] = casted\n",
    "            schema_src[c] = tag\n",
    "\n",
    "        # affichage (mapping & schéma)\n",
    "        table_base = file_base if len(sheets) == 1 else f\"{file_base}__{snake_id(name)}\"\n",
    "        table_name = pg_ident(table_base)\n",
    "\n",
    "        print(f\"\\n--- Feuille: {name} -> {TARGET_SCHEMA}.{table_name} (SCHÉMA SOURCE STRICT) ---\")\n",
    "        print(f\"rows={len(casted_df)} | cols={casted_df.shape[1]}\")\n",
    "        print(\"\\nMapping colonnes (Excel → nom_pg) :\")\n",
    "        for src_name, pg_name in zip(df_src.columns, pg_cols):\n",
    "            print(f\"  - {src_name}  ->  {pg_name}\")\n",
    "        print(\"\\nSchema détecté (types PostgreSQL) :\")\n",
    "        for src_name, pg_name in zip(df_src.columns, pg_cols):\n",
    "            tag = schema_src.get(src_name, \"STRING\")\n",
    "            print(f\"  - {pg_name}: {sa_type(tag).__class__.__name__}  (source: {src_name}, tag: {tag})\")\n",
    "\n",
    "        if SHOW_SAMPLE:\n",
    "            with pd.option_context(\"display.max_columns\", 180, \"display.width\", 260):\n",
    "                print(\"\\nSample (top 10) :\")\n",
    "                print(casted_df.head(10))\n",
    "\n",
    "        # ===== INSERTION DB (schéma strict) =====\n",
    "        try:\n",
    "            # renommer les colonnes pour la table Postgres\n",
    "            df_for_sql = casted_df.copy()\n",
    "            df_for_sql.columns = pg_cols\n",
    "\n",
    "            # préparer dtypes & mapping\n",
    "            schema_sql = {pg: schema_src[src] for src, pg in zip(df_src.columns, pg_cols)}\n",
    "            df_sql, dtype_map = prepare_for_sql(df_for_sql, schema_sql)\n",
    "\n",
    "            # to_sql\n",
    "            df_sql.to_sql(\n",
    "                name=table_name,\n",
    "                con=engine,\n",
    "                schema=TARGET_SCHEMA,\n",
    "                if_exists=IF_EXISTS_MODE,\n",
    "                index=False,\n",
    "                dtype=dtype_map,\n",
    "                method=\"multi\",\n",
    "                chunksize=1000\n",
    "            )\n",
    "            log(f\"[ok] Inserted into {TARGET_SCHEMA}.{table_name}\")\n",
    "            done += 1\n",
    "        except Exception as e:\n",
    "            log(f\"[error] Échec insertion {TARGET_SCHEMA}.{table_name}: {e}\")\n",
    "\n",
    "    print(f\"\\nDone. Feuilles analysées & importées: {done}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03eef39-a59e-42e3-89de-29289b1d2da5",
   "metadata": {},
   "source": [
    "# Suivi Projets AEC - source.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebafa3aa-24bf-410f-8d3d-02507da60b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:59:09] Fichier: C:\\globasoft\\aerotech\\fic\\Suivi Projets AEC - source.xlsx\n",
      "[15:59:09] [ok] Connecté PostgreSQL\n",
      "[15:59:09] PostgreSQL 17.6 (Debian 17.6-1.pgdg12+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14+deb12u1) 12.2.0, 64-bit\n",
      "[15:59:10] \n",
      "[feuille] 2025mai: shape initiale=(226, 82)\n",
      "[15:59:10] [feuille] 2025mai: après drop vides -> (226, 82)\n",
      "[15:59:10] [feuille] 2025mai: header choisi à la ligne 3\n",
      "[15:59:10] [feuille] 2025mai: shape après affectation des en-têtes -> (222, 75)\n",
      "\n",
      "--- Feuille: 2025mai -> public.suivi_projets_aec_source (SCHÉMA SOURCE STRICT / PostgreSQL) ---\n",
      "rows=222 | cols=75\n",
      "\n",
      "Mapping colonnes (Excel → nom_pg) :\n",
      "  - Comments  ->  comments\n",
      "  - REVUE RAF  ->  revue_raf\n",
      "  - GTM  ->  gtm\n",
      "  - Statut suivi de projets  ->  statut_suivi_de_projets\n",
      "  - Top custo  ->  top_custo\n",
      "  - Num Projets  ->  num_projets\n",
      "  - Réunion RAF  ->  reunion_raf\n",
      "  - CdP  ->  cdp\n",
      "  - Date fin  ->  date_fin\n",
      "  - Total Budget\n",
      "€  ->  total_budget\n",
      "  - Ecart Budget M-1\n",
      "€  ->  ecart_budget_m_1\n",
      "  - Total Dépensé Engagé\n",
      "€  ->  total_depense_engage\n",
      "  - Total Dépensé Enregistré\n",
      "€  ->  total_depense_enregistre\n",
      "  - Total Marge Projeté\n",
      "%  ->  total_marge_projete\n",
      "  - Ecart Marge Projeté M-1\n",
      "%  ->  ecart_marge_projete_m_1\n",
      "  - Objectif de marge %  ->  objectif_de_marge\n",
      "  - Budget Heures\n",
      "Hrs  ->  budget_heures_hrs\n",
      "  - Réel Heures Internes\n",
      "Hrs  ->  reel_heures_internes_hrs\n",
      "  - Réel Heures ST\n",
      "Hrs  ->  reel_heures_st_hrs\n",
      "  - RAF Heures\n",
      "Hrs  ->  raf_heures_hrs\n",
      "  - RAF Heures M-1\n",
      "Hrs  ->  raf_heures_m_1_hrs\n",
      "  - Ecart Heures vs M-1\n",
      "Hrs  ->  ecart_heures_vs_m_1_hrs\n",
      "  - Budget Heures Valorisées\n",
      "€  ->  budget_heures_valorisees\n",
      "  - Réel Heures Valorisées\n",
      "€  ->  reel_heures_valorisees\n",
      "  - RAF Heures Valorisées\n",
      "€  ->  raf_heures_valorisees\n",
      "  - Marge prévisionnelle Heures\n",
      "%  ->  marge_previsionnelle_heures\n",
      "  - Budget Achat HT\n",
      "€  ->  budget_achat_ht\n",
      "  - Prévi HA coûts = nomenaf  ->  previ_ha_couts_nomenaf\n",
      "  - Achats commandés HT\n",
      "€  ->  achats_commandes_ht\n",
      "  - Achats enregistrés HT\n",
      "€  ->  achats_enregistres_ht\n",
      "  - Commandé-Enregistré yc FNP  ->  commande_enregistre_yc_fnp\n",
      "  - dont FNP à date (€ HT)  ->  dont_fnp_a_date_ht\n",
      "  - RAF Achats\n",
      "€  ->  raf_achats\n",
      "  - RAF Achats M-1\n",
      "€  ->  raf_achats_m_1\n",
      "  - Ecart Achats vs M-1\n",
      "€  ->  ecart_achats_vs_m_1\n",
      "  - Int Commandé OT\n",
      "€  ->  int_commande_ot\n",
      "  - Int Réalisé OT\n",
      "€  ->  int_realise_ot\n",
      "  - RAF Int OT\n",
      "€  ->  raf_int_ot\n",
      "  - RAF OT M-1\n",
      "€  ->  raf_ot_m_1\n",
      "  - Ecart Int OT vs M-1\n",
      "€  ->  ecart_int_ot_vs_m_1\n",
      "  - Marge prévisionnelle Achats\n",
      "%  ->  marge_previsionnelle_achats\n",
      "  - Budget Mission\n",
      " €  ->  budget_mission\n",
      "  - Prévisionnel Missions\n",
      "€  ->  previsionnel_missions\n",
      "  - Réel Mission\n",
      "€  ->  reel_mission\n",
      "  - RAF Mission\n",
      "€  ->  raf_mission\n",
      "  - RAF Mission M-1\n",
      "€  ->  raf_mission_m_1\n",
      "  - Ecart Mission vs M-1\n",
      "€  ->  ecart_mission_vs_m_1\n",
      "  - Marge prévisionnelle Mission\n",
      "%  ->  marge_previsionnelle_mission\n",
      "  - Provisions pour risques  ->  provisions_pour_risques\n",
      "  - Facturation globale projet à date (€ HT)   ->  facturation_globale_projet_a_date_ht\n",
      "  - CA fin N-1  ->  ca_fin_n_1\n",
      "  - CA N à date (€ HT)   ->  ca_n_a_date_ht\n",
      "  - Consommé global Enregistré à date (€ HT)  ->  consomme_global_enregistre_a_date_ht\n",
      "  - RaF Global à terminaison à date (€ HT)  ->  raf_global_a_terminaison_a_date_ht\n",
      "  - Avancement Global Financier basé sur Enregistré à date (%)  ->  avancement_global_financier_base_sur_enregistre_a_date\n",
      "  - Avancement Global Facturation à date (%)  ->  avancement_global_facturation_a_date\n",
      "  - PCA basé sur Enregistré à date (€)  ->  pca_base_sur_enregistre_a_date\n",
      "  - FAE basé sur Enregistré à date (€)  ->  fae_base_sur_enregistre_a_date\n",
      "  - Valeur vente Ingenieur (€ HT)  ->  valeur_vente_ingenieur_ht\n",
      "  - Objectif fin d'année  ->  objectif_fin_d_annee\n",
      "  - Cohérence Budget  ->  coherence_budget\n",
      "  - ecart couts à terminaison vs M-1  ->  ecart_couts_a_terminaison_vs_m_1\n",
      "  - écart avancement  ->  ecart_avancement\n",
      "  - CA Y  ->  ca_y\n",
      "  - Charges Y  ->  charges_y\n",
      "  - Marge Y  ->  marge_y\n",
      "  - Facturation Y  ->  facturation_y\n",
      "  - CA mois  ->  ca_mois\n",
      "  - Charges mois  ->  charges_mois\n",
      "  - Marge mois  ->  marge_mois\n",
      "  - Facturation mois  ->  facturation_mois\n",
      "  - Remaining Forecast  ->  remaining_forecast\n",
      "  - hrs à fin s21  ->  hrs_a_fin_s21\n",
      "  - RaF (h) MO à fin s21  ->  raf_h_mo_a_fin_s21\n",
      "  - RaF (h) MO à fin s22  ->  raf_h_mo_a_fin_s22\n",
      "\n",
      "Schema détecté (types PostgreSQL) :\n",
      "  - comments: Text  (source: Comments, tag: STRING)\n",
      "  - revue_raf: Text  (source: REVUE RAF, tag: STRING)\n",
      "  - gtm: Text  (source: GTM, tag: STRING)\n",
      "  - statut_suivi_de_projets: Text  (source: Statut suivi de projets, tag: STRING)\n",
      "  - top_custo: Text  (source: Top custo, tag: STRING)\n",
      "  - num_projets: Text  (source: Num Projets, tag: STRING)\n",
      "  - reunion_raf: Text  (source: Réunion RAF, tag: STRING)\n",
      "  - cdp: Text  (source: CdP, tag: STRING)\n",
      "  - date_fin: Text  (source: Date fin, tag: STRING)\n",
      "  - total_budget: Float  (source: Total Budget\n",
      "€, tag: FLOAT)\n",
      "  - ecart_budget_m_1: Float  (source: Ecart Budget M-1\n",
      "€, tag: FLOAT)\n",
      "  - total_depense_engage: Float  (source: Total Dépensé Engagé\n",
      "€, tag: FLOAT)\n",
      "  - total_depense_enregistre: Float  (source: Total Dépensé Enregistré\n",
      "€, tag: FLOAT)\n",
      "  - total_marge_projete: Float  (source: Total Marge Projeté\n",
      "%, tag: FLOAT)\n",
      "  - ecart_marge_projete_m_1: Float  (source: Ecart Marge Projeté M-1\n",
      "%, tag: FLOAT)\n",
      "  - objectif_de_marge: Float  (source: Objectif de marge %, tag: FLOAT)\n",
      "  - budget_heures_hrs: Float  (source: Budget Heures\n",
      "Hrs, tag: FLOAT)\n",
      "  - reel_heures_internes_hrs: Float  (source: Réel Heures Internes\n",
      "Hrs, tag: FLOAT)\n",
      "  - reel_heures_st_hrs: Float  (source: Réel Heures ST\n",
      "Hrs, tag: FLOAT)\n",
      "  - raf_heures_hrs: Float  (source: RAF Heures\n",
      "Hrs, tag: FLOAT)\n",
      "  - raf_heures_m_1_hrs: Float  (source: RAF Heures M-1\n",
      "Hrs, tag: FLOAT)\n",
      "  - ecart_heures_vs_m_1_hrs: Float  (source: Ecart Heures vs M-1\n",
      "Hrs, tag: FLOAT)\n",
      "  - budget_heures_valorisees: Float  (source: Budget Heures Valorisées\n",
      "€, tag: FLOAT)\n",
      "  - reel_heures_valorisees: Float  (source: Réel Heures Valorisées\n",
      "€, tag: FLOAT)\n",
      "  - raf_heures_valorisees: Float  (source: RAF Heures Valorisées\n",
      "€, tag: FLOAT)\n",
      "  - marge_previsionnelle_heures: Float  (source: Marge prévisionnelle Heures\n",
      "%, tag: FLOAT)\n",
      "  - budget_achat_ht: Float  (source: Budget Achat HT\n",
      "€, tag: FLOAT)\n",
      "  - previ_ha_couts_nomenaf: Float  (source: Prévi HA coûts = nomenaf, tag: FLOAT)\n",
      "  - achats_commandes_ht: Float  (source: Achats commandés HT\n",
      "€, tag: FLOAT)\n",
      "  - achats_enregistres_ht: Float  (source: Achats enregistrés HT\n",
      "€, tag: FLOAT)\n",
      "  - commande_enregistre_yc_fnp: Float  (source: Commandé-Enregistré yc FNP, tag: FLOAT)\n",
      "  - dont_fnp_a_date_ht: Float  (source: dont FNP à date (€ HT), tag: FLOAT)\n",
      "  - raf_achats: Float  (source: RAF Achats\n",
      "€, tag: FLOAT)\n",
      "  - raf_achats_m_1: Float  (source: RAF Achats M-1\n",
      "€, tag: FLOAT)\n",
      "  - ecart_achats_vs_m_1: Float  (source: Ecart Achats vs M-1\n",
      "€, tag: FLOAT)\n",
      "  - int_commande_ot: Float  (source: Int Commandé OT\n",
      "€, tag: FLOAT)\n",
      "  - int_realise_ot: Float  (source: Int Réalisé OT\n",
      "€, tag: FLOAT)\n",
      "  - raf_int_ot: Float  (source: RAF Int OT\n",
      "€, tag: FLOAT)\n",
      "  - raf_ot_m_1: Float  (source: RAF OT M-1\n",
      "€, tag: FLOAT)\n",
      "  - ecart_int_ot_vs_m_1: Float  (source: Ecart Int OT vs M-1\n",
      "€, tag: FLOAT)\n",
      "  - marge_previsionnelle_achats: Float  (source: Marge prévisionnelle Achats\n",
      "%, tag: FLOAT)\n",
      "  - budget_mission: Float  (source: Budget Mission\n",
      " €, tag: FLOAT)\n",
      "  - previsionnel_missions: Float  (source: Prévisionnel Missions\n",
      "€, tag: FLOAT)\n",
      "  - reel_mission: Float  (source: Réel Mission\n",
      "€, tag: FLOAT)\n",
      "  - raf_mission: Float  (source: RAF Mission\n",
      "€, tag: FLOAT)\n",
      "  - raf_mission_m_1: Float  (source: RAF Mission M-1\n",
      "€, tag: FLOAT)\n",
      "  - ecart_mission_vs_m_1: Float  (source: Ecart Mission vs M-1\n",
      "€, tag: FLOAT)\n",
      "  - marge_previsionnelle_mission: Float  (source: Marge prévisionnelle Mission\n",
      "%, tag: FLOAT)\n",
      "  - provisions_pour_risques: Integer  (source: Provisions pour risques, tag: INT)\n",
      "  - facturation_globale_projet_a_date_ht: Float  (source: Facturation globale projet à date (€ HT) , tag: FLOAT)\n",
      "  - ca_fin_n_1: Float  (source: CA fin N-1, tag: FLOAT)\n",
      "  - ca_n_a_date_ht: Float  (source: CA N à date (€ HT) , tag: FLOAT)\n",
      "  - consomme_global_enregistre_a_date_ht: Float  (source: Consommé global Enregistré à date (€ HT), tag: FLOAT)\n",
      "  - raf_global_a_terminaison_a_date_ht: Float  (source: RaF Global à terminaison à date (€ HT), tag: FLOAT)\n",
      "  - avancement_global_financier_base_sur_enregistre_a_date: Float  (source: Avancement Global Financier basé sur Enregistré à date (%), tag: FLOAT)\n",
      "  - avancement_global_facturation_a_date: Float  (source: Avancement Global Facturation à date (%), tag: FLOAT)\n",
      "  - pca_base_sur_enregistre_a_date: Float  (source: PCA basé sur Enregistré à date (€), tag: FLOAT)\n",
      "  - fae_base_sur_enregistre_a_date: Float  (source: FAE basé sur Enregistré à date (€), tag: FLOAT)\n",
      "  - valeur_vente_ingenieur_ht: Float  (source: Valeur vente Ingenieur (€ HT), tag: FLOAT)\n",
      "  - objectif_fin_d_annee: Float  (source: Objectif fin d'année, tag: FLOAT)\n",
      "  - coherence_budget: Float  (source: Cohérence Budget, tag: FLOAT)\n",
      "  - ecart_couts_a_terminaison_vs_m_1: Float  (source: ecart couts à terminaison vs M-1, tag: FLOAT)\n",
      "  - ecart_avancement: Float  (source: écart avancement, tag: FLOAT)\n",
      "  - ca_y: Float  (source: CA Y, tag: FLOAT)\n",
      "  - charges_y: Float  (source: Charges Y, tag: FLOAT)\n",
      "  - marge_y: Float  (source: Marge Y, tag: FLOAT)\n",
      "  - facturation_y: Float  (source: Facturation Y, tag: FLOAT)\n",
      "  - ca_mois: Float  (source: CA mois, tag: FLOAT)\n",
      "  - charges_mois: Float  (source: Charges mois, tag: FLOAT)\n",
      "  - marge_mois: Float  (source: Marge mois, tag: FLOAT)\n",
      "  - facturation_mois: Float  (source: Facturation mois, tag: FLOAT)\n",
      "  - remaining_forecast: Float  (source: Remaining Forecast, tag: FLOAT)\n",
      "  - hrs_a_fin_s21: Float  (source: hrs à fin s21, tag: FLOAT)\n",
      "  - raf_h_mo_a_fin_s21: Float  (source: RaF (h) MO à fin s21, tag: FLOAT)\n",
      "  - raf_h_mo_a_fin_s22: Float  (source: RaF (h) MO à fin s22, tag: FLOAT)\n",
      "\n",
      "Sample (top 10) :\n",
      "                                             Comments REVUE RAF        GTM Statut suivi de projets Top custo Num Projets         Réunion RAF   CdP Date fin  Total Budget\\n€  Ecart Budget M-1\\n€  Total Dépensé Engagé\\n€  Total Dépensé Enregistré\\n€  \\\n",
      "4   s35 : à annuler - s22/s52 : spéléo zombie à po...      <NA>      ROTOR                    <NA>    autres     C181320              Rotors  <NA>     <NA>             <NA>                 <NA>                     <NA>                         <NA>   \n",
      "5   s22 : annulé à indexer sur facturé (2024)- dis...      <NA>  A/L & STC                  Annulé    autres     C181556  Cabines & Systèmes  <NA>     <NA>             <NA>                 <NA>                     <NA>                         <NA>   \n",
      "6   s15 : ramené au facturé (0) - s09/s48 : invest...      <NA>        MRO                    <NA>      DGAC     C181592                   ?  <NA>     <NA>             <NA>                 <NA>                     <NA>                         <NA>   \n",
      "7   s22 : annulé à indexer sur facturé - discussio...      <NA>  A/L & STC                  Annulé    autres     C181688  Cabines & Systèmes  <NA>     <NA>             <NA>                 <NA>                     <NA>                         <NA>   \n",
      "8   s48 : annulé - s40: standby chez client final....      <NA>  A/L & STC                  Annulé    autres     C191860  Cabines & Systèmes  <NA>     <NA>             <NA>                 <NA>                     <NA>                         <NA>   \n",
      "9   s22 : facturation supérieure au budget -s05 : ...      <NA>      ROTOR                    <NA>    autres     C192026          Programmes  <NA>     <NA>              0.0                  0.0                     <NA>                         <NA>   \n",
      "10  s22 : négo client pour facturer le consommé ( ...      <NA>  A/L & STC                  Annulé    autres     C202607  Cabines & Systèmes  <NA>     <NA>             <NA>                 <NA>                     <NA>                         <NA>   \n",
      "11  s48 : annulé s44/40/35/26/22/13/09/05/48 : sta...      <NA>  A/L & STC                  Annulé    autres     C202681  Cabines & Systèmes  <NA>     <NA>             <NA>                 <NA>                     <NA>                         <NA>   \n",
      "12  s22 : à annuler commandé à indexer sur facturé...      <NA>  A/L & STC       Terminé à annuler    autres     C212935  Cabines & Systèmes  <NA>     <NA>             <NA>                 <NA>                     <NA>                         <NA>   \n",
      "13                                                            Y      ROTOR                    <NA>   Babcock     C202747              Rotors  <NA>     <NA>             <NA>                 <NA>                     <NA>                         <NA>   \n",
      "\n",
      "    Total Marge Projeté\\n%  Ecart Marge Projeté M-1\\n%  Objectif de marge %  Budget Heures\\nHrs  Réel Heures Internes\\nHrs  Réel Heures ST\\nHrs  RAF Heures\\nHrs  RAF Heures M-1\\nHrs  Ecart Heures vs M-1\\nHrs  Budget Heures Valorisées\\n€  \\\n",
      "4                     <NA>                        <NA>                 <NA>                 0.0                        0.0                  0.0              3.0                  0.0                       0.0                          0.0   \n",
      "5                     <NA>                        <NA>                 <NA>                 0.0                        0.0                  0.0             29.5                  0.0                       0.0                          0.0   \n",
      "6                     <NA>                        <NA>                 <NA>                 0.0                        0.0                  0.0              5.0                  0.0                       0.0                          0.0   \n",
      "7                     <NA>                        <NA>                 <NA>                 0.0                        0.0                  0.0            172.5                  0.0                       0.0                          0.0   \n",
      "8                     <NA>                        <NA>                 <NA>                 0.0                        0.0                  0.0             32.5                  0.0                       0.0                          0.0   \n",
      "9                      0.0                         0.0                  0.0                 0.0                        0.0                  0.0           1970.5                  0.0                       0.0                          0.0   \n",
      "10                    <NA>                        <NA>                 <NA>                 0.0                        0.0                  0.0            418.5                  0.0                       0.0                          0.0   \n",
      "11                    <NA>                        <NA>                 <NA>                 0.0                        0.0                  0.0             18.5                  0.0                       0.0                          0.0   \n",
      "12                    <NA>                        <NA>                 <NA>                 0.0                        0.0                  0.0            361.0                  0.0                       0.0                         <NA>   \n",
      "13                    <NA>                        <NA>                 <NA>                <NA>                        0.0                  0.0        144.01875                  0.0                       0.0                         <NA>   \n",
      "\n",
      "    Réel Heures Valorisées\\n€  RAF Heures Valorisées\\n€  Marge prévisionnelle Heures\\n%  Budget Achat HT\\n€  Prévi HA coûts = nomenaf  Achats commandés HT\\n€  Achats enregistrés HT\\n€  Commandé-Enregistré yc FNP  dont FNP à date (€ HT)  RAF Achats\\n€  \\\n",
      "4                        <NA>                     143.4                             0.0                 0.0                       0.0                     0.0                       0.0                         0.0                     0.0            0.0   \n",
      "5                        <NA>                    1410.1                             0.0                <NA>                       0.0                     0.0                       0.0                         0.0                     0.0            0.0   \n",
      "6                        <NA>                     239.0                             0.0                 0.0                       0.0                     0.0                       0.0                         0.0                     0.0            0.0   \n",
      "7                        <NA>                    8245.5                             0.0                <NA>                       0.0                     0.0                       0.0                         0.0                     0.0            0.0   \n",
      "8                        <NA>                    1553.5                             0.0                 0.0                       0.0                     0.0                       0.0                         0.0                     0.0            0.0   \n",
      "9                        <NA>                   94189.9                             0.0                 0.0                       0.0               -10590.32                    192.12                   -10782.44                  192.12            0.0   \n",
      "10                       <NA>                   20004.3                             0.0                <NA>                       0.0                     0.0                       0.0                         0.0                     0.0            0.0   \n",
      "11                       <NA>                     884.3                             0.0                 0.0                       0.0                     0.0                       0.0                         0.0                     0.0            0.0   \n",
      "12                       <NA>                   17255.8                            <NA>                 0.0                       0.0                     0.0                       0.0                         0.0                     0.0            0.0   \n",
      "13                       <NA>                6884.09625                            <NA>                 0.0                       0.0                     0.0                       0.0                         0.0                     0.0            0.0   \n",
      "\n",
      "    RAF Achats M-1\\n€  Ecart Achats vs M-1\\n€  Int Commandé OT\\n€  Int Réalisé OT\\n€  RAF Int OT\\n€  RAF OT M-1\\n€  Ecart Int OT vs M-1\\n€  Marge prévisionnelle Achats\\n%  Budget Mission\\n €  Prévisionnel Missions\\n€  Réel Mission\\n€  RAF Mission\\n€  \\\n",
      "4                 0.0                     0.0                 0.0                0.0            0.0            0.0                     0.0                             0.0                 0.0                       0.0              0.0             0.0   \n",
      "5                 0.0                     0.0                 0.0                0.0            0.0            0.0                     0.0                            <NA>                 0.0                       0.0              0.0             0.0   \n",
      "6                 0.0                     0.0                 0.0                0.0            0.0            0.0                     0.0                             0.0                 0.0                       0.0              0.0             0.0   \n",
      "7                 0.0                     0.0                 0.0                0.0            0.0            0.0                     0.0                            <NA>                 0.0                       0.0              0.0             0.0   \n",
      "8                 0.0                     0.0                 0.0                0.0            0.0            0.0                     0.0                             0.0                 0.0                       0.0              0.0             0.0   \n",
      "9                 0.0               -10590.32                 0.0             195.25            0.0            0.0                     0.0                             0.0                 0.0                       0.0              0.0             0.0   \n",
      "10                0.0                     0.0                 0.0                0.0            0.0            0.0                     0.0                            <NA>                 0.0                       0.0              0.0             0.0   \n",
      "11                0.0                     0.0                 0.0                0.0            0.0            0.0                     0.0                             0.0                 0.0                       0.0              0.0             0.0   \n",
      "12                0.0                     0.0                 0.0                0.0            0.0            0.0                     0.0                             0.0                 0.0                       0.0              0.0             0.0   \n",
      "13                0.0                     0.0                 0.0                0.0            0.0            0.0                     0.0                             0.0                 0.0                       0.0              0.0             0.0   \n",
      "\n",
      "    RAF Mission M-1\\n€  Ecart Mission vs M-1\\n€  Marge prévisionnelle Mission\\n%  Provisions pour risques  Facturation globale projet à date (€ HT)   CA fin N-1  CA N à date (€ HT)   Consommé global Enregistré à date (€ HT)  \\\n",
      "4                  0.0                      0.0                              0.0                        0                                        0.0         0.0                 <NA>                                      <NA>   \n",
      "5                  0.0                      0.0                              0.0                        0                                        0.0         0.0                 <NA>                                      <NA>   \n",
      "6                  0.0                      0.0                              0.0                        0                                        0.0         0.0                 <NA>                                      <NA>   \n",
      "7                  0.0                      0.0                              0.0                        0                                        0.0         0.0                 <NA>                                      <NA>   \n",
      "8                  0.0                      0.0                              0.0                        0                                        0.0         0.0                 <NA>                                      <NA>   \n",
      "9                  0.0                      0.0                              0.0                        0                                        0.0         0.0                 <NA>                                      <NA>   \n",
      "10                 0.0                      0.0                              0.0                        0                                        0.0         0.0                 <NA>                                      <NA>   \n",
      "11                 0.0                      0.0                              0.0                        0                                        0.0         0.0                 <NA>                                      <NA>   \n",
      "12                 0.0                      0.0                              0.0                        0                                        0.0         0.0                 <NA>                                      <NA>   \n",
      "13                 0.0                      0.0                              0.0                        0                                        0.0         0.0                 <NA>                                      <NA>   \n",
      "\n",
      "    RaF Global à terminaison à date (€ HT)  Avancement Global Financier basé sur Enregistré à date (%)  Avancement Global Facturation à date (%)  PCA basé sur Enregistré à date (€)  FAE basé sur Enregistré à date (€)  Valeur vente Ingenieur (€ HT)  \\\n",
      "4                                    143.4                                               <NA>                                               <NA>                                <NA>                                <NA>                      93.052109   \n",
      "5                                   1410.1                                               <NA>                                               <NA>                                <NA>                                <NA>                      96.010408   \n",
      "6                                    239.0                                               <NA>                                               <NA>                                <NA>                                <NA>                      93.023256   \n",
      "7                                   8245.5                                               <NA>                                               <NA>                                <NA>                                <NA>                       96.35122   \n",
      "8                                   1553.5                                               <NA>                                               <NA>                                <NA>                                <NA>                      96.006144   \n",
      "9                                 83212.21                                               <NA>                                                0.0                                <NA>                                <NA>                          95.04   \n",
      "10                                 20004.3                                               <NA>                                               <NA>                                <NA>                                <NA>                      96.069869   \n",
      "11                                   884.3                                               <NA>                                               <NA>                                <NA>                                <NA>                           95.0   \n",
      "12                                 17255.8                                               <NA>                                               <NA>                                <NA>                                <NA>                       96.02649   \n",
      "13                              6884.09625                                               <NA>                                               <NA>                                <NA>                                <NA>                           96.0   \n",
      "\n",
      "    Objectif fin d'année  Cohérence Budget  ecart couts à terminaison vs M-1  écart avancement  CA Y  Charges Y  Marge Y  Facturation Y  CA mois  Charges mois  Marge mois  Facturation mois  Remaining Forecast  hrs à fin s21  RaF (h) MO à fin s21  \\\n",
      "4                    0.5              <NA>                              <NA>              <NA>  <NA>       <NA>     <NA>            0.0     <NA>          <NA>        <NA>               0.0                <NA>            3.0                   0.0   \n",
      "5                   <NA>              <NA>                              <NA>              <NA>  <NA>       <NA>     <NA>            0.0     <NA>          <NA>        <NA>               0.0                <NA>           29.5                   0.0   \n",
      "6                    1.0              <NA>                              <NA>              <NA>  <NA>       <NA>     <NA>            0.0     <NA>          <NA>        <NA>               0.0                <NA>            5.0                   0.0   \n",
      "7                    1.0              <NA>                              <NA>              <NA>  <NA>       <NA>     <NA>            0.0     <NA>          <NA>        <NA>               0.0                <NA>          172.5                   0.0   \n",
      "8                   <NA>              <NA>                              <NA>              <NA>  <NA>       <NA>     <NA>            0.0     <NA>          <NA>        <NA>               0.0                <NA>           32.5                   0.0   \n",
      "9                    1.0               0.0                              <NA>              <NA>  <NA>       <NA>     <NA>            0.0     <NA>          <NA>        <NA>               0.0                <NA>         1970.5                   0.0   \n",
      "10                  <NA>              <NA>                              <NA>              <NA>  <NA>       <NA>     <NA>            0.0     <NA>          <NA>        <NA>               0.0                <NA>          418.5                   0.0   \n",
      "11                  <NA>              <NA>                              <NA>              <NA>  <NA>       <NA>     <NA>            0.0     <NA>          <NA>        <NA>               0.0                <NA>           18.5                   0.0   \n",
      "12                  <NA>              <NA>                              <NA>              <NA>  <NA>       <NA>     <NA>            0.0     <NA>          <NA>        <NA>               0.0                <NA>          361.0                   0.0   \n",
      "13                   1.0              <NA>                              <NA>              <NA>  <NA>       <NA>     <NA>            0.0     <NA>          <NA>        <NA>               0.0                <NA>          144.0               0.01875   \n",
      "\n",
      "    RaF (h) MO à fin s22  \n",
      "4                   -3.0  \n",
      "5                  -29.5  \n",
      "6                   -5.0  \n",
      "7                 -172.5  \n",
      "8                  -32.5  \n",
      "9                -1970.5  \n",
      "10                -418.5  \n",
      "11                 -18.5  \n",
      "12                -361.0  \n",
      "13                -144.0  \n",
      "[15:59:11] [ok] Inserted into public.suivi_projets_aec_source\n",
      "\n",
      "Done. Feuilles analysées & importées: 1\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, unicodedata, warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# --- DB: SQLAlchemy\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy import types as satypes\n",
    "from sqlalchemy.exc import OperationalError\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "# ============== CONFIG ==============\n",
    "FILE_PATH = r\"C:\\globasoft\\aerotech\\fic\\Suivi Projets AEC - source.xlsx\"\n",
    "SHOW_SAMPLE = True\n",
    "TARGET_SCHEMA = \"public\"\n",
    "IF_EXISTS_MODE = \"replace\"  # \"replace\" ou \"append\"\n",
    "\n",
    "# (optionnel) masquer un warning bruyant de pandas\n",
    "warnings.filterwarnings(\"ignore\", message=r\"Parsing dates in %Y-%m-%d %H:%M:%S format.*\", category=UserWarning)\n",
    "\n",
    "# ============== LOG ==============\n",
    "def now(): return datetime.now().strftime(\"%H:%M:%S\")\n",
    "def log(msg): print(f\"[{now()}] {msg}\", flush=True)\n",
    "\n",
    "# ============== ACCÈS DB ==============\n",
    "REQUIRED_KEYS = (\"PG_HOST\",\"PG_PORT\",\"PG_DB\",\"PG_USER\",\"PG_PASS\")\n",
    "\n",
    "def _collect_pg_config():\n",
    "    cfg, g = {}, globals()\n",
    "    # 1) prendre éventuels globals (si définis dans un 1er bloc)\n",
    "    for k in REQUIRED_KEYS:\n",
    "        if k in g and g[k]:\n",
    "            cfg[k] = g[k]\n",
    "    # 2) compléter via variables d'environnement\n",
    "    for k in REQUIRED_KEYS:\n",
    "        if k not in cfg or not cfg[k]:\n",
    "            v = os.getenv(k)\n",
    "            if v:\n",
    "                cfg[k] = v\n",
    "    # défauts pratiques (Render)\n",
    "    if not cfg.get(\"PG_HOST\"):\n",
    "        cfg[\"PG_HOST\"] = \"dpg-d3jq6apr0fns738f81i0-a.frankfurt-postgres.render.com\"\n",
    "    cfg[\"PG_PORT\"] = int(cfg.get(\"PG_PORT\", 5432))\n",
    "    missing = [k for k in REQUIRED_KEYS if not cfg.get(k)]\n",
    "    if missing:\n",
    "        raise RuntimeError(\"Paramètres DB manquants: \" + \", \".join(missing))\n",
    "    return cfg\n",
    "\n",
    "def get_engine():\n",
    "    g = globals()\n",
    "    if \"engine\" in g and g[\"engine\"] is not None:\n",
    "        return g[\"engine\"]\n",
    "    cfg = _collect_pg_config()\n",
    "    conn_str = (\n",
    "        f\"postgresql+psycopg2://{cfg['PG_USER']}:{quote_plus(cfg['PG_PASS'])}\"\n",
    "        f\"@{cfg['PG_HOST']}:{cfg['PG_PORT']}/{cfg['PG_DB']}\"\n",
    "    )\n",
    "    eng = create_engine(\n",
    "        conn_str,\n",
    "        connect_args={\n",
    "            \"sslmode\": \"require\",\n",
    "            \"connect_timeout\": 5,\n",
    "            \"keepalives\": 1,\n",
    "            \"keepalives_idle\": 30,\n",
    "            \"keepalives_interval\": 10,\n",
    "            \"keepalives_count\": 3,\n",
    "        },\n",
    "        pool_pre_ping=True,\n",
    "        pool_recycle=1800,\n",
    "        pool_size=5,\n",
    "        max_overflow=5,\n",
    "    )\n",
    "    return eng\n",
    "\n",
    "# ============== UTILS ==============\n",
    "def strip_accents_lower(s):\n",
    "    if s is None or (isinstance(s, float) and pd.isna(s)): return \"\"\n",
    "    s = unicodedata.normalize(\"NFKD\", str(s))\n",
    "    s = \"\".join(c for c in s if not unicodedata.combining(c))\n",
    "    return s.lower().strip()\n",
    "\n",
    "def snake_id(s):\n",
    "    s = strip_accents_lower(s)\n",
    "    s = re.sub(r\"[\\s\\.\\-]+\", \"_\", s)\n",
    "    s = re.sub(r\"[^a-z0-9_]\", \"_\", s)\n",
    "    return re.sub(r\"_+\", \"_\", s).strip(\"_\") or \"col\"\n",
    "\n",
    "def make_unique_columns(cols):\n",
    "    out, seen = [], {}\n",
    "    for c in cols:\n",
    "        if c not in seen:\n",
    "            seen[c] = 1\n",
    "            out.append(c)\n",
    "        else:\n",
    "            seen[c] += 1\n",
    "            out.append(f\"{c}_{seen[c]}\")\n",
    "    return out\n",
    "\n",
    "def _preclean_numeric_strings(x: pd.Series) -> pd.Series:\n",
    "    s = x.astype(\"string\")\n",
    "    s = s.str.replace(r\"^(true|false|yes|no|vrai|faux)$\", \"\", flags=re.I, regex=True)\n",
    "    s = s.str.replace(\"\\u00A0\",\" \", regex=False).str.replace(\" \",\"\", regex=False)\n",
    "    s = s.str.replace(r\"(?<=\\d)\\.(?=\\d{3}(?:\\D|$))\",\"\", regex=True)  # 1.234 -> 1234\n",
    "    s = s.str.replace(\",\",\".\", regex=False)  # 1,23 -> 1.23\n",
    "    return s\n",
    "\n",
    "def parse_number_like(series: pd.Series) -> pd.Series:\n",
    "    s = _preclean_numeric_strings(series)\n",
    "    return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "def drop_empty_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.dropna(axis=1, how=\"all\")\n",
    "    blank_idx = []\n",
    "    for j in range(df.shape[1]):\n",
    "        s = df.iloc[:, j]\n",
    "        if s.dropna().astype(str).str.strip().eq(\"\").all():\n",
    "            blank_idx.append(j)\n",
    "    if blank_idx:\n",
    "        log(f\"[drop_empty_columns] suppression colonnes blanches (pos): {blank_idx}\")\n",
    "        df = df.drop(df.columns[blank_idx], axis=1)\n",
    "    return df\n",
    "\n",
    "# ============== HEADER PICK ==============\n",
    "HEADER_HINTS = (\n",
    "    \"projet\",\"projets\",\"code\",\"id\",\"réf\",\"ref\",\"libelle\",\"libellé\",\"intitulé\",\n",
    "    \"client\",\"fournisseur\",\"chef de projet\",\"cp\",\"cdp\",\"manager\",\n",
    "    \"statut\",\"status\",\"phase\",\"categorie\",\"catégorie\",\"type\",\n",
    "    \"date\",\"heure\",\"time\",\"période\",\"periode\",\"echeance\",\"échéance\",\"fin\",\"début\",\"debut\",\n",
    "    \"budget\",\"montant\",\"cout\",\"coût\",\"prix\",\"ht\",\"ttc\",\"avancement\",\"progress\",\"%\",\"taux\",\n",
    "    \"site\",\"section analytique\",\"analytique\",\"commentaire\",\"observations\",\"notes\",\"remarques\",\n",
    "    \"comments\",\"revue raf\",\"statut clipper\",\"gtm\",\"pôle\",\"pole\",\n",
    "    \"remaining forecast\",\"facturation mois\",\"hrs\",\"heures\",\"(h)\",\n",
    "    \"ca \",\"charges\",\"marge\",\"achats\",\"commandé\",\"enregistré\",\"fnp\",\"int\",\"raf\"\n",
    ")\n",
    "\n",
    "def choose_header_row(df: pd.DataFrame, scan=30) -> int:\n",
    "    limit = min(len(df), scan)\n",
    "    cand_idx, cand_hits = None, -1\n",
    "    for i in range(limit):\n",
    "        row = df.iloc[i].astype(str)\n",
    "        hits = 0\n",
    "        for v in row:\n",
    "            t = strip_accents_lower(v)\n",
    "            if t and any(k in t for k in HEADER_HINTS):\n",
    "                hits += 1\n",
    "        if hits >= 2 and hits > cand_hits:\n",
    "            cand_idx, cand_hits = i, hits\n",
    "    if cand_idx is not None:\n",
    "        return cand_idx\n",
    "    best, idx = -1, 0\n",
    "    for i in range(limit):\n",
    "        row = df.iloc[i].astype(str)\n",
    "        non_empty = row.map(lambda x: x.strip()!=\"\").sum()\n",
    "        texty = row.map(lambda x: bool(re.search(r\"[A-Za-zÀ-ÿ]\", x))).sum()\n",
    "        score = non_empty*2 + texty\n",
    "        if score > best: best, idx = score, i\n",
    "    return idx\n",
    "\n",
    "# ============== INFÉRENCE TYPES (→ PostgreSQL) ==============\n",
    "MAP_TRUE  = {\"true\",\"vrai\",\"oui\",\"yes\",\"1\",\"y\",\"o\"}\n",
    "MAP_FALSE = {\"false\",\"faux\",\"non\",\"no\",\"0\",\"n\"}\n",
    "\n",
    "DATE_TOKEN_RE = re.compile(\n",
    "    r\"(?:\\d{4}[-/\\.]\\d{1,2}[-/\\.]\\d{1,2})|(?:\\d{1,2}[-/\\.]\\d{1,2}[-/\\.]\\d{2,4})|\"\n",
    "    r\"(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec|janv|févr|fevr|avr|mai|juin|juil|sept|oct|nov|d[ée]c)\",\n",
    "    re.I\n",
    ")\n",
    "ISO_DATE_RE = re.compile(r\"^\\d{4}-\\d{2}-\\d{2}(?:[ T]\\d{2}:\\d{2}:\\d{2})?$\")\n",
    "\n",
    "DATE_NAME_HINTS   = (\"date\",\"dt\",\"heure\",\"time\",\"echeance\",\"échéance\",\"debut\",\"début\",\"fin\",\"période\",\"periode\",\"semaine\",\"mois\",\"année\",\"annee\")\n",
    "MONEY_NAME_HINTS  = (\"€\",\"ht\",\"budget\",\"montant\",\"amount\",\"total\",\"prix\",\"coût\",\"cout\",\"facturation\",\"forecast\",\"achats\",\"commandé\",\"enregistré\",\"fnp\",\"ca \",\"charges\",\"marge\",\"int\",\"raf\")\n",
    "HOUR_NAME_HINTS   = (\"heures\",\"hrs\",\"(h)\",\" h \")\n",
    "PERCENT_NAME_HINTS= (\"%\", \"taux\", \"marge\", \"avancement\", \"écart\", \"ecart\", \"pourcent\")\n",
    "CODE_LIKE_HINTS   = (\"code\",\"nature\",\"plan\",\"compte\",\"sop\",\"section\",\"niveau\",\"trigramme\",\"immat\",\"ot\",\"ata\",\"wp\",\"n° dossier\",\"n_dossier\",\"dossier\",\"cat point\",\"cat pointage\",\"statut clipper\",\"gtm\",\"pôle\",\"pole\",\"comments\",\"cdp\",\"top custo\",\"réunion raf\",\"reunion raf\",\"statut suivi de projets\",\"statut suivi de projet\")\n",
    "\n",
    "def colname_has(hints, name):\n",
    "    n = strip_accents_lower(name or \"\")\n",
    "    return any(h in n for h in hints)\n",
    "\n",
    "def excel_serial_to_datetime(series: pd.Series) -> pd.Series:\n",
    "    vals = pd.to_numeric(series, errors=\"coerce\").astype(\"float64\")\n",
    "    vals[~np.isfinite(vals)] = np.nan\n",
    "    lower, upper = 60.0, 60000.0  # ~ 1900..2064\n",
    "    mask = (vals >= lower) & (vals <= upper)\n",
    "    n_out = int((~mask & ~pd.isna(vals)).sum())\n",
    "    if n_out:\n",
    "        log(f\"[excel_serial_to_datetime] valeurs hors fenêtre [{int(lower)}, {int(upper)}] -> NaN: {n_out}\")\n",
    "    base = pd.Timestamp(\"1899-12-30\")\n",
    "    td = pd.to_timedelta(vals.where(mask, np.nan), unit=\"D\", errors=\"coerce\")\n",
    "    dt = base + td\n",
    "    return pd.to_datetime(dt, errors=\"coerce\")\n",
    "\n",
    "def infer_col(col: pd.Series):\n",
    "    \"\"\"\n",
    "    Retourne (serie_casted, tag) avec tag ∈ {\"DATE\",\"DATETIME\",\"INT\",\"FLOAT\",\"BOOL\",\"STRING\"}.\n",
    "    PRÉCÉDENCE EN-TÊTE > CONTENU. Renvoie de VRAIS dtypes pandas (datetime/int/float/bool/string),\n",
    "    pas de strings formatées pour les dates.\n",
    "    \"\"\"\n",
    "    s = col.copy()\n",
    "    ss = s.astype(\"string\").str.strip()\n",
    "    name = s.name or \"\"\n",
    "\n",
    "    # 1) Colonnes monétaires / métriques -> float\n",
    "    if colname_has(MONEY_NAME_HINTS, name):\n",
    "        nums = parse_number_like(ss)\n",
    "        if nums.notna().any():\n",
    "            return nums.astype(\"Float64\"), \"FLOAT\"\n",
    "\n",
    "    # 2) Heures -> float\n",
    "    if colname_has(HOUR_NAME_HINTS, name):\n",
    "        nums = parse_number_like(ss)\n",
    "        if nums.notna().any():\n",
    "            return nums.astype(\"Float64\"), \"FLOAT\"\n",
    "\n",
    "    # 3) % / taux -> float\n",
    "    if (\"%\" in (name or \"\")) or colname_has(PERCENT_NAME_HINTS, name):\n",
    "        nums = parse_number_like(ss)\n",
    "        if nums.notna().any():\n",
    "            return nums.astype(\"Float64\"), \"FLOAT\"\n",
    "\n",
    "    # 4) Dates ISO explicites -> datetime/date (pandas)\n",
    "    iso_mask = ss.fillna(\"\").str.match(ISO_DATE_RE)\n",
    "    if len(ss) and iso_mask.mean() >= 0.5:\n",
    "        dt_iso = pd.to_datetime(ss.where(iso_mask), errors=\"coerce\", dayfirst=False)\n",
    "        ok = dt_iso.notna().mean()\n",
    "        if ok >= 0.5:\n",
    "            has_time = (dt_iso.dt.time.astype(str) != \"00:00:00\").mean() > 0.2\n",
    "            return (dt_iso, \"DATETIME\" if has_time else \"DATE\")\n",
    "\n",
    "    # 5) Excel serial -> datetime/date (seulement si nom datey)\n",
    "    if colname_has(DATE_NAME_HINTS, name):\n",
    "        as_num = pd.to_numeric(ss, errors=\"coerce\")\n",
    "        safe_mask = (as_num >= 60) & (as_num <= 60000)\n",
    "        if (as_num.notna().mean() if len(ss) else 0.0) >= 0.9 and safe_mask.mean() >= 0.7:\n",
    "            parsed = excel_serial_to_datetime(as_num)\n",
    "            ok = parsed.notna().mean() if len(ss) else 0.0\n",
    "            if ok >= 0.7:\n",
    "                has_time = (parsed.dt.time.astype(str) != \"00:00:00\").mean() > 0.2\n",
    "                return (parsed, \"DATETIME\" if has_time else \"DATE\")\n",
    "\n",
    "    # 6) Tokens de date\n",
    "    date_token_ratio = ss.fillna(\"\").str.contains(DATE_TOKEN_RE, na=False).mean()\n",
    "    if colname_has(DATE_NAME_HINTS, name) or (date_token_ratio >= 0.30):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", message=\"Could not infer format.*\", category=UserWarning)\n",
    "            dt1 = pd.to_datetime(ss, errors=\"coerce\", dayfirst=True,  cache=True)\n",
    "            dt2 = pd.to_datetime(ss, errors=\"coerce\", dayfirst=False, cache=True)\n",
    "        dt = dt2 if dt2.notna().sum() > dt1.notna().sum() else dt1\n",
    "        ok = dt.notna().mean() if len(ss) else 0.0\n",
    "        ok_thresh = 0.50 if colname_has(DATE_NAME_HINTS, name) else 0.70\n",
    "        if ok >= ok_thresh:\n",
    "            has_time = (dt.dt.time.astype(str) != \"00:00:00\").mean() > 0.2\n",
    "            return (dt, \"DATETIME\" if has_time else \"DATE\")\n",
    "\n",
    "    # 7) Bool strict\n",
    "    mb = ss.str.lower().map(lambda x: True if x in MAP_TRUE else (False if x in MAP_FALSE else pd.NA))\n",
    "    if len(ss) and mb.notna().mean() >= 0.98:\n",
    "        return mb.astype(\"boolean\"), \"BOOL\"\n",
    "\n",
    "    # 8) Nombre générique\n",
    "    nums = parse_number_like(ss)\n",
    "    if (nums.notna().mean() if len(ss) else 0) >= 0.85:\n",
    "        nz = nums.dropna()\n",
    "        if len(nz) and (np.mod(nz, 1) == 0).all():\n",
    "            return nums.astype(\"Int64\"), \"INT\"\n",
    "        return nums.astype(\"Float64\"), \"FLOAT\"\n",
    "\n",
    "    # 9) Texte\n",
    "    return ss.astype(\"string\"), \"STRING\"\n",
    "\n",
    "def sa_type(tag: str):\n",
    "    return {\n",
    "        \"DATE\": satypes.Date(),\n",
    "        \"DATETIME\": satypes.DateTime(),    # timestamp without time zone\n",
    "        \"INT\": satypes.Integer(),\n",
    "        \"FLOAT\": satypes.Float(precision=53),\n",
    "        \"BOOL\": satypes.Boolean(),\n",
    "        \"STRING\": satypes.Text()\n",
    "    }.get(tag, satypes.Text())\n",
    "\n",
    "def prepare_for_sql(df: pd.DataFrame, schema_tags: dict):\n",
    "    out = df.copy()\n",
    "    for c, tag in schema_tags.items():\n",
    "        if tag == \"DATE\":\n",
    "            out[c] = pd.to_datetime(out[c], errors=\"coerce\").dt.date\n",
    "        elif tag == \"DATETIME\":\n",
    "            out[c] = pd.to_datetime(out[c], errors=\"coerce\")\n",
    "    dtype_map = {c: sa_type(tag) for c, tag in schema_tags.items()}\n",
    "    return out, dtype_map\n",
    "\n",
    "def pg_ident(name: str, maxlen=63) -> str:\n",
    "    return name[:maxlen]\n",
    "\n",
    "# ============== MAIN ==============\n",
    "def main():\n",
    "    xlsx = Path(FILE_PATH)\n",
    "    log(f\"Fichier: {xlsx}\")\n",
    "    if not xlsx.exists():\n",
    "        log(\"[error] Fichier introuvable\"); return\n",
    "\n",
    "    # Connexion DB\n",
    "    try:\n",
    "        engine = get_engine()\n",
    "        with engine.connect() as conn:\n",
    "            ver = conn.execute(text(\"select version();\")).scalar()\n",
    "            log(\"[ok] Connecté PostgreSQL\")\n",
    "            log(ver)\n",
    "    except (OperationalError, RuntimeError) as e:\n",
    "        log(f\"[error] Connexion PostgreSQL échouée: {e}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        sheets = pd.read_excel(xlsx, sheet_name=None, engine=\"openpyxl\", header=None)\n",
    "    except Exception as e:\n",
    "        log(f\"[error] Lecture échouée: {e}\"); return\n",
    "\n",
    "    file_base = snake_id(xlsx.stem)\n",
    "    done = 0\n",
    "\n",
    "    for name, raw in sheets.items():\n",
    "        log(f\"\\n[feuille] {name}: shape initiale={raw.shape}\")\n",
    "\n",
    "        raw = raw.dropna(how=\"all\", axis=0).dropna(how=\"all\", axis=1)\n",
    "        log(f\"[feuille] {name}: après drop vides -> {raw.shape}\")\n",
    "        if raw.empty:\n",
    "            log(f\"[feuille] {name}: vide, on passe.\")\n",
    "            continue\n",
    "\n",
    "        h = choose_header_row(raw, scan=30)\n",
    "        log(f\"[feuille] {name}: header choisi à la ligne {h}\")\n",
    "\n",
    "        # Schéma STRICT du fichier\n",
    "        df_src = raw.iloc[h+1:].copy()\n",
    "        src_cols_original = raw.iloc[h].tolist()\n",
    "        df_src.columns = src_cols_original\n",
    "        df_src = df_src.dropna(how=\"all\").copy()\n",
    "        df_src = drop_empty_columns(df_src)\n",
    "        log(f\"[feuille] {name}: shape après affectation des en-têtes -> {df_src.shape}\")\n",
    "        if df_src.empty:\n",
    "            log(f\"[feuille] {name}: vide après normalisation, on passe.\")\n",
    "            continue\n",
    "\n",
    "        # noms de colonnes Postgres (snake_case + unicité) — aucune colonne ajoutée\n",
    "        pg_cols = make_unique_columns([snake_id(c) for c in df_src.columns])\n",
    "\n",
    "        # inférence sur colonnes d'origine -> vrais dtypes pandas\n",
    "        schema_src = {}\n",
    "        casted_df = df_src.copy()\n",
    "        for c in list(df_src.columns):\n",
    "            casted, tag = infer_col(df_src[c])\n",
    "            casted_df[c] = casted\n",
    "            schema_src[c] = tag\n",
    "\n",
    "        # Affichage\n",
    "        table_base = file_base if len(sheets) == 1 else f\"{file_base}__{snake_id(name)}\"\n",
    "        table_name = pg_ident(table_base)\n",
    "\n",
    "        print(f\"\\n--- Feuille: {name} -> {TARGET_SCHEMA}.{table_name} (SCHÉMA SOURCE STRICT / PostgreSQL) ---\")\n",
    "        print(f\"rows={len(casted_df)} | cols={casted_df.shape[1]}\")\n",
    "        print(\"\\nMapping colonnes (Excel → nom_pg) :\")\n",
    "        for src_name, pg_name in zip(df_src.columns, pg_cols):\n",
    "            print(f\"  - {src_name}  ->  {pg_name}\")\n",
    "        print(\"\\nSchema détecté (types PostgreSQL) :\")\n",
    "        for src_name, pg_name in zip(df_src.columns, pg_cols):\n",
    "            tag = schema_src.get(src_name, \"STRING\")\n",
    "            print(f\"  - {pg_name}: {sa_type(tag).__class__.__name__}  (source: {src_name}, tag: {tag})\")\n",
    "\n",
    "        if SHOW_SAMPLE:\n",
    "            with pd.option_context(\"display.max_columns\", 220, \"display.width\", 260):\n",
    "                print(\"\\nSample (top 10) :\")\n",
    "                print(casted_df.head(10))\n",
    "\n",
    "        # ===== INSERTION DB =====\n",
    "        try:\n",
    "            df_for_sql = casted_df.copy()\n",
    "            df_for_sql.columns = pg_cols\n",
    "            schema_sql = {pg: schema_src[src] for src, pg in zip(df_src.columns, pg_cols)}\n",
    "            df_sql, dtype_map = prepare_for_sql(df_for_sql, schema_sql)\n",
    "\n",
    "            df_sql.to_sql(\n",
    "                name=table_name,\n",
    "                con=engine,\n",
    "                schema=TARGET_SCHEMA,\n",
    "                if_exists=IF_EXISTS_MODE,\n",
    "                index=False,\n",
    "                dtype=dtype_map,\n",
    "                method=\"multi\",\n",
    "                chunksize=1000\n",
    "            )\n",
    "            log(f\"[ok] Inserted into {TARGET_SCHEMA}.{table_name}\")\n",
    "            done += 1\n",
    "        except Exception as e:\n",
    "            log(f\"[error] Échec insertion {TARGET_SCHEMA}.{table_name}: {e}\")\n",
    "\n",
    "    print(f\"\\nDone. Feuilles analysées & importées: {done}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532ffa8a-32de-4cfa-b21c-b99e422057ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
