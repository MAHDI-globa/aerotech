{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99c19ec5-9cef-4d67-8334-eadca07bc02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== data header: folder info ===\n",
      "path: C:\\globasoft\\aerotech\\fic\n",
      "files_found: 1\n",
      "\n",
      "=== data header: file info ===\n",
      "path: C:\\globasoft\\aerotech\\fic\\fichier qualité des trigrammes.xlsx\n",
      "\n",
      "=== data header: lecture ===\n",
      "file: fichier qualité des trigrammes.xlsx\n",
      "header_detected: no\n",
      "rows: 29 | cols: 9\n",
      "columns: col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9\n",
      "\n",
      "=== data sample (top 5) ===\n",
      "                          col_1 col_2 col_3                                              col_4  col_5  col_6  col_7  col_8 col_9\n",
      "0  Aérodrome - 81300 GRAULHET\\n   NaN  <NA>  DA-SQ-0027 LISTE DES TRIGRAMMES ET MARQUES DE ...   <NA>   <NA>   <NA>   <NA>  <NA>\n",
      "1                           NaN   NaN  <NA>                                               <NA>   <NA>   <NA>   <NA>   <NA>  <NA>\n",
      "2                           NaN   NaN  <NA>                                               <NA>   <NA>   <NA>   <NA>   <NA>  <NA>\n",
      "3                           NaN   NaN  <NA>                         EDITION : 21 du 16/05/2025   <NA>   <NA>   <NA>   <NA>  <NA>\n",
      "4                           NaN   NaN  <NA>                                               <NA>   <NA>   <NA>   <NA>   <NA>  <NA>\n",
      "\n",
      "=== data dtypes ===\n",
      "col_1            object\n",
      "col_2            object\n",
      "col_3    string[python]\n",
      "col_4    string[python]\n",
      "col_5             Int64\n",
      "col_6             Int64\n",
      "col_7             Int64\n",
      "col_8             Int64\n",
      "col_9    string[python]\n",
      "dtype: object\n",
      "\n",
      "=== data path ===\n",
      "C:\\globasoft\\aerotech\\fic\\fichier qualité des trigrammes.xlsx\n",
      "\n",
      "=== done ===\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Dépendances : pip install pandas openpyxl\n",
    "# (optionnel pour meilleure détection d'encodage CSV : pip install charset-normalizer)\n",
    "# Usage : placer vos fichiers dans le dossier \"fic\", puis lancer :\n",
    "#   python read_simple.py\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "ROOT_DIR = Path(\"fic\")  # dossier racine à parcourir\n",
    "\n",
    "# ---------------- Utils header ---------------- #\n",
    "\n",
    "def looks_like_header(first_row_values):\n",
    "    \"\"\"Vérifie si la 1ère ligne ressemble à une ligne d'en-tête.\"\"\"\n",
    "    vals = [(str(v).strip() if pd.notna(v) else \"\") for v in first_row_values]\n",
    "    if not any(vals):\n",
    "        return False\n",
    "    unnamed = sum(v.lower().startswith(\"unnamed\") for v in vals)\n",
    "    empties = sum(v in (\"\", \"none\", \"nan\") for v in vals)\n",
    "    return (unnamed + empties) < max(1, len(vals)//3)\n",
    "\n",
    "# ---------------- Excel ---------------- #\n",
    "\n",
    "def read_excel_simple(path: Path):\n",
    "    \"\"\"Lit le 1er onglet d'un Excel, tente d'utiliser la 1ère ligne comme header.\"\"\"\n",
    "    probe = pd.read_excel(path, nrows=1, header=None, engine=\"openpyxl\")\n",
    "    if probe.empty or not looks_like_header(probe.iloc[0].tolist()):\n",
    "        df = pd.read_excel(path, header=None, engine=\"openpyxl\")\n",
    "        df.columns = [f\"col_{i+1}\" for i in range(df.shape[1])]\n",
    "        used_header = False\n",
    "    else:\n",
    "        df = pd.read_excel(path, engine=\"openpyxl\")\n",
    "        used_header = True\n",
    "    return df.convert_dtypes(), used_header\n",
    "\n",
    "# ---------------- CSV (avec encodage robuste) ---------------- #\n",
    "\n",
    "def pick_encoding(path: Path):\n",
    "    \"\"\"\n",
    "    Essaie de détecter l'encodage avec charset-normalizer si installé.\n",
    "    Retourne l'encodage détecté (str) ou None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from charset_normalizer import from_path\n",
    "        res = from_path(str(path)).best()\n",
    "        return res.encoding if res else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def read_csv_simple(path: Path):\n",
    "    \"\"\"\n",
    "    Lit un CSV (auto-détection du séparateur) avec gestion d'encodage:\n",
    "    - devine l'encodage si possible (charset-normalizer),\n",
    "    - sinon essaie: utf-8-sig, utf-8, cp1252 (ANSI), latin-1, iso-8859-1,\n",
    "    - dernier recours: latin-1 avec encoding_errors='replace'.\n",
    "    Détecte aussi la 1ère ligne en-tête.\n",
    "    \"\"\"\n",
    "    enc_guess = pick_encoding(path)\n",
    "    candidates = [e for e in [enc_guess, \"utf-8-sig\", \"utf-8\", \"cp1252\", \"latin-1\", \"iso-8859-1\"] if e]\n",
    "\n",
    "    last_err = None\n",
    "    for enc in candidates:\n",
    "        try:\n",
    "            probe = pd.read_csv(path, nrows=1, header=None, sep=None, engine=\"python\", encoding=enc)\n",
    "            if probe.empty or not looks_like_header(probe.iloc[0].tolist()):\n",
    "                df = pd.read_csv(path, header=None, sep=None, engine=\"python\", encoding=enc)\n",
    "                df.columns = [f\"col_{i+1}\" for i in range(df.shape[1])]\n",
    "                used_header = False\n",
    "            else:\n",
    "                df = pd.read_csv(path, sep=None, engine=\"python\", encoding=enc)\n",
    "                used_header = True\n",
    "            return df.convert_dtypes(), used_header\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            continue\n",
    "\n",
    "    # Dernier recours: lecture permissive (ne plante pas, remplace caractères illisibles)\n",
    "    try:\n",
    "        df = pd.read_csv(path, sep=None, engine=\"python\", encoding=\"latin-1\", encoding_errors=\"replace\")\n",
    "        probe = pd.read_csv(path, nrows=1, header=None, sep=None, engine=\"python\", encoding=\"latin-1\", encoding_errors=\"replace\")\n",
    "        if probe.empty or not looks_like_header(probe.iloc[0].tolist()):\n",
    "            if list(df.columns) == list(range(df.shape[1])):  # colonnes 0..n (pas de header)\n",
    "                df.columns = [f\"col_{i+1}\" for i in range(df.shape[1])]\n",
    "            used_header = False\n",
    "        else:\n",
    "            used_header = True\n",
    "        return df.convert_dtypes(), used_header\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Echec lecture CSV (encodage). Dernière erreur: {last_err or e}\")\n",
    "\n",
    "# ---------------- Router ---------------- #\n",
    "\n",
    "def read_table(path: Path):\n",
    "    \"\"\"Route vers la bonne lecture selon l'extension.\"\"\"\n",
    "    ext = path.suffix.lower()\n",
    "    if ext in (\".xlsx\", \".xlsm\"):\n",
    "        return read_excel_simple(path)\n",
    "    elif ext == \".csv\":\n",
    "        return read_csv_simple(path)\n",
    "    else:\n",
    "        raise ValueError(f\"Extension non gérée: {ext}\")\n",
    "\n",
    "# ---------------- Main ---------------- #\n",
    "\n",
    "def main():\n",
    "    if not ROOT_DIR.exists():\n",
    "        print(f\"[error] Dossier introuvable : {ROOT_DIR.resolve()}\")\n",
    "        return\n",
    "\n",
    "    # recherche récursive des fichiers tabulaires\n",
    "    files = []\n",
    "    for pat in (\"*.xlsx\", \"*.xlsm\", \"*.csv\"):\n",
    "        files += [p for p in ROOT_DIR.rglob(pat) if p.is_file() and not p.name.startswith(\"~$\")]\n",
    "\n",
    "    print(\"=== data header: folder info ===\")\n",
    "    print(f\"path: {ROOT_DIR.resolve()}\")\n",
    "    print(f\"files_found: {len(files)}\")\n",
    "\n",
    "    if not files:\n",
    "        print(\"[warn] Aucun fichier .xlsx/.xlsm/.csv trouvé.\")\n",
    "        return\n",
    "\n",
    "    for f in sorted(files):\n",
    "        print(\"\\n=== data header: file info ===\")\n",
    "        print(f\"path: {f.resolve()}\")\n",
    "\n",
    "        try:\n",
    "            df, used = read_table(f)\n",
    "        except Exception as e:\n",
    "            print(f\"[error] Lecture échouée pour {f.name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # affichage simple\n",
    "        print(\"\\n=== data header: lecture ===\")\n",
    "        print(f\"file: {f.name}\")\n",
    "        print(f\"header_detected: {'yes' if used else 'no'}\")\n",
    "        print(f\"rows: {len(df)} | cols: {df.shape[1]}\")\n",
    "        print(\"columns:\", \", \".join(map(str, df.columns.tolist())))\n",
    "\n",
    "        print(\"\\n=== data sample (top 5) ===\")\n",
    "        with pd.option_context(\"display.max_columns\", 50, \"display.width\", 140):\n",
    "            print(df.head(5))\n",
    "\n",
    "        print(\"\\n=== data dtypes ===\")\n",
    "        print(df.dtypes)\n",
    "\n",
    "        print(\"\\n=== data path ===\")\n",
    "        print(f.resolve())\n",
    "\n",
    "    print(\"\\n=== done ===\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aedbf3e-5480-49ff-9106-38db1c92c11b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
