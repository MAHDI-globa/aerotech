{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99c19ec5-9cef-4d67-8334-eadca07bc02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== data header: folder info ===\n",
      "path: C:\\globasoft\\aerotech\\fic\n",
      "files_found: 3\n",
      "\n",
      "=== file ===\n",
      "fichier qualité des trigrammes.xlsx  (C:\\globasoft\\aerotech\\fic\\fichier qualité des trigrammes.xlsx)\n",
      "\n",
      "--- table detected ---\n",
      "name: fichier qualité des trigrammes__PDG__table_1\n",
      "rows: 20 | cols: 4\n",
      "columns: edition, date, motif, redacteur\n",
      "\n",
      "=== schema ===\n",
      "edition: INT\n",
      "date: DATE\n",
      "motif: STRING\n",
      "redacteur: STRING\n",
      "\n",
      "=== sample (top 8) ===\n",
      "   edition        date                                              motif    redacteur\n",
      "0        1  2024-06-10                                           Création  S. BELMONTE\n",
      "1        2  2024-09-16                           Ajout nouveaux arrivants    Y. RAGEOT\n",
      "2        3  2024-10-21                                    Ajout couturier    Y. RAGEOT\n",
      "3        4  2024-10-28  Mise à jour des dates d'entrée \n",
      "Ajout des habi...    Y. RAGEOT\n",
      "4        5  2024-12-16  Ajout nouvelle arrivante - 1 personne - Feriel...  F.BOULHABEL\n",
      "5        6  2024-12-18                              Départ de Yann RAGEOT  S. BELMONTE\n",
      "6        7  2024-12-19  Ajout de nouveaux arrivants - 4 personnes - Fr...  F.BOULHABEL\n",
      "7        8  2024-12-20  Ajout de nouvel arrivant - 1 personne - Loris ...  F.BOULHABEL\n",
      "[saved] out\\fichier qualité des trigrammes__PDG__table_1.csv\n",
      "\n",
      "--- table detected ---\n",
      "name: fichier qualité des trigrammes__Liste__table_1\n",
      "rows: 201 | cols: 6\n",
      "columns: nom_prenom, trig, personnel_intext, site, date_dattribution, date_de_retrait\n",
      "\n",
      "=== schema ===\n",
      "nom_prenom: STRING\n",
      "trig: STRING\n",
      "personnel_intext: STRING\n",
      "site: STRING\n",
      "date_dattribution: DATE\n",
      "date_de_retrait: DATE\n",
      "\n",
      "=== sample (top 8) ===\n",
      "                 nom_prenom trig personnel_intext site date_dattribution date_de_retrait\n",
      "0              ABAT Nicolas  ABT          Interne  AEC        2025-02-17             NaN\n",
      "1   ABDELLAOUI Schéhérazade  ADI          Interne  AEB        2025-05-05             NaN\n",
      "2          ADJEROUD Bastian  BAD          Interne  AEX        2024-05-21             NaN\n",
      "3              AGREBI Lilia  ARI          Interne  AEC        2025-02-24             NaN\n",
      "4         ALBERTON YANNICK   YAL          Interne  AEC        2018-11-05      2021-09-10\n",
      "5  ALIAS Séverine née HERAL  ALS          Interne  AEG        2024-05-21             NaN\n",
      "6      ALLARD Jean-François  ALD          Externe  AEC               NaN             NaN\n",
      "7               ALLARD Yann  YAD          Interne  AEC        2024-06-03             NaN\n",
      "[saved] out\\fichier qualité des trigrammes__Liste__table_1.csv\n",
      "\n",
      "=== file ===\n",
      "FNP AEC sous-traitance in Situ.xlsx  (C:\\globasoft\\aerotech\\fic\\FNP AEC sous-traitance in Situ.xlsx)\n",
      "\n",
      "--- table detected ---\n",
      "name: FNP AEC sous-traitance in Situ__tcd__table_1\n",
      "rows: 31 | cols: 5\n",
      "columns: etiquettes_de_lignes, somme_de_cout_st_du_mois_m, nb_jours, nb_hrs, col\n",
      "\n",
      "=== schema ===\n",
      "etiquettes_de_lignes: DATE\n",
      "somme_de_cout_st_du_mois_m: FLOAT\n",
      "nb_jours: FLOAT\n",
      "nb_hrs: FLOAT\n",
      "col: FLOAT\n",
      "\n",
      "=== sample (top 8) ===\n",
      "  etiquettes_de_lignes  somme_de_cout_st_du_mois_m  nb_jours  nb_hrs        col\n",
      "0           2021-10-01                     46695.0     121.0   931.7  50.118064\n",
      "1           2021-11-01                     36057.5      93.0   716.1  50.352604\n",
      "2           2021-12-01                     30700.0      79.0   608.3  50.468519\n",
      "3           2022-01-01                     27060.0      69.0   531.3  50.931677\n",
      "4           2022-02-01                     26480.0      68.0   523.6  50.572956\n",
      "5           2022-03-01                     33370.0      85.5  658.35  50.687324\n",
      "6           2022-04-01                     28840.0      74.0   569.8  50.614251\n",
      "7           2022-05-30                     26330.0      67.5  519.75  50.658971\n",
      "[saved] out\\FNP AEC sous-traitance in Situ__tcd__table_1.csv\n",
      "\n",
      "--- table detected ---\n",
      "name: FNP AEC sous-traitance in Situ__FNP ST__table_1\n",
      "rows: 255 | cols: 15\n",
      "columns: periode, fournisseurs, nom, factures_non_parvenues_m1, mois_m_nb_jrs_travailles, pu_journee, cout_st_du_mois_m, tx_h, facturation_mois_m, factures_non_parvenues_ht_mois_m, commentaires, type, compte_tiers, compte_charges, tva\n",
      "\n",
      "=== schema ===\n",
      "periode: DATE\n",
      "fournisseurs: STRING\n",
      "nom: STRING\n",
      "factures_non_parvenues_m1: FLOAT\n",
      "mois_m_nb_jrs_travailles: FLOAT\n",
      "pu_journee: FLOAT\n",
      "cout_st_du_mois_m: FLOAT\n",
      "tx_h: FLOAT\n",
      "facturation_mois_m: FLOAT\n",
      "factures_non_parvenues_ht_mois_m: FLOAT\n",
      "commentaires: STRING\n",
      "type: STRING\n",
      "compte_tiers: INT\n",
      "compte_charges: INT\n",
      "tva: FLOAT\n",
      "\n",
      "=== sample (top 8) ===\n",
      "      periode     fournisseurs               nom  factures_non_parvenues_m1  mois_m_nb_jrs_travailles  pu_journee  cout_st_du_mois_m       tx_h  \\\n",
      "0  2021-10-01  Expleo Assystem      David BUGEIA                        0.0                      21.0       380.0             7980.0  48.717949   \n",
      "1  2021-10-01  Expleo Assystem    Laurent JAPAUD                        0.0                      18.0       420.0             7560.0  53.846154   \n",
      "2  2021-10-01     PORTALLIANCE       Erwan FECIL                     7980.0                      21.0       380.0             7980.0  48.717949   \n",
      "3  2021-10-01  Expleo Assystem   Sandrine DURAND                        0.0                      20.0       380.0             7600.0  48.717949   \n",
      "4  2021-10-01  Expleo Assystem  Mikael PANNETIER                        0.0                      21.0       380.0             7980.0  48.717949   \n",
      "5  2021-10-01  Expleo Assystem     Nicolas DURAN                        0.0                      19.0       380.0             7220.0  48.717949   \n",
      "6  2021-10-01     PORTALLIANCE   Donatien PERRET                     5250.0                       1.0       375.0              375.0  48.076923   \n",
      "7  2021-11-01  Expleo Assystem      David BUGEIA                        0.0                      19.0       380.0             7220.0  48.717949   \n",
      "\n",
      "   facturation_mois_m  factures_non_parvenues_ht_mois_m commentaires        type  compte_tiers  compte_charges     tva  \n",
      "0              7980.0                               0.0       335565     S/T AFR    4081002000      6040000000     0.0  \n",
      "1              7560.0                               0.0       335564     S/T AFR    4081002000      6040000000     0.0  \n",
      "2              7980.0                            7980.0  20210900008  S/T France    4081010000      6040000000  1596.0  \n",
      "3              7600.0                               0.0       335562     S/T AFR    4081002000      6040000000     0.0  \n",
      "4              7980.0                               0.0       335563     S/T AFR    4081002000      6040000000     0.0  \n",
      "5              7220.0                               0.0       335566     S/T AFR    4081002000      6040000000     0.0  \n",
      "6              5250.0                             375.0  20210900009  S/T France    4081010000      6040000000    75.0  \n",
      "7              7220.0                               0.0       337261     S/T AFR    4081002000      6040000000     0.0  \n",
      "[saved] out\\FNP AEC sous-traitance in Situ__FNP ST__table_1.csv\n",
      "\n",
      "--- table detected ---\n",
      "name: FNP AEC sous-traitance in Situ__Data__table_1\n",
      "rows: 15 | cols: 6\n",
      "columns: fournisseur_interne_externe, type, compte_tiers, compte_charges, soumisnon_soumis, commentaires\n",
      "\n",
      "=== schema ===\n",
      "fournisseur_interne_externe: STRING\n",
      "type: STRING\n",
      "compte_tiers: INT\n",
      "compte_charges: INT\n",
      "soumisnon_soumis: STRING\n",
      "commentaires: STRING\n",
      "\n",
      "=== sample (top 8) ===\n",
      "  fournisseur_interne_externe             type  compte_tiers  compte_charges soumisnon_soumis commentaires\n",
      "0                     Externe             <NA>    4081010000            <NA>             <NA>         <NA>\n",
      "1                     Interne          S/T AFR    4081002000      6040000000           Soumis         <NA>\n",
      "2                     Externe  Matériel France    4081010000      6010000000           Soumis         <NA>\n",
      "3                     Externe     Matériel CEE    4081010000      6010000000       Non soumis         <NA>\n",
      "4                     Externe   Matériel Monde    4081010000      6010000000       Non soumis         <NA>\n",
      "5                     Interne  S/T Aerotec 21G    4081002000      6040000000           Soumis     kits 21G\n",
      "6                     Externe       S/T France    4081010000      6040000000           Soumis         <NA>\n",
      "7                     Externe          S/T CEE    4081010000      6040000000       Non soumis         <NA>\n",
      "[saved] out\\FNP AEC sous-traitance in Situ__Data__table_1.csv\n",
      "\n",
      "--- table detected ---\n",
      "name: FNP AEC sous-traitance in Situ__suivi pointages factu__table_1\n",
      "rows: 8 | cols: 5\n",
      "columns: colonne1, colonne2, colonne3, nom, prenom\n",
      "\n",
      "=== schema ===\n",
      "colonne1: INT\n",
      "colonne2: STRING\n",
      "colonne3: STRING\n",
      "nom: STRING\n",
      "prenom: STRING\n",
      "\n",
      "=== sample (top 8) ===\n",
      "   colonne1                  colonne2          colonne3        nom     prenom\n",
      "0         1  PORTALLIANCE ENGINEERING       Erwan FECIL      FECIL      Erwan\n",
      "1         2                 BERTRANDT     Michael JAMET      JAMET    Michael\n",
      "2         3           Expleo Assystem     Cédric COMBES     COMBES     Cédric\n",
      "3         4           Expleo Assystem    Gaëtan CHAUVEL    CHAUVEL     Gaëtan\n",
      "4         5           Expleo Assystem     Gilles BENOMY     BENOMY     Gilles\n",
      "5         6           Expleo Assystem  Mikael PANNETIER  PANNETIER     Mikael\n",
      "6         7           Expleo Assystem      André OPARIN     OPARIN      André\n",
      "7         8                     DO IT    Guillaume GASC       GASC  Guillaume\n",
      "[saved] out\\FNP AEC sous-traitance in Situ__suivi pointages factu__table_1.csv\n",
      "\n",
      "--- table detected ---\n",
      "name: FNP AEC sous-traitance in Situ__TAUX HORAIRE ST__table_1\n",
      "rows: 24 | cols: 4\n",
      "columns: etiquettes_de_lignes, cout_st_du_mois_m, nb_jrs_travailles, tx_horaire_st\n",
      "\n",
      "=== schema ===\n",
      "etiquettes_de_lignes: DATE\n",
      "cout_st_du_mois_m: FLOAT\n",
      "nb_jrs_travailles: FLOAT\n",
      "tx_horaire_st: FLOAT\n",
      "\n",
      "=== sample (top 8) ===\n",
      "  etiquettes_de_lignes  cout_st_du_mois_m  nb_jrs_travailles  tx_horaire_st\n",
      "0           2021-10-01            38340.0               99.0           <NA>\n",
      "1           2021-11-01            29410.0               75.5      51.254793\n",
      "2           2021-12-01            24620.0               63.0      51.420217\n",
      "3           2022-01-01            20980.0               53.0      52.085402\n",
      "4           2022-02-01            18880.0               48.0      51.754386\n",
      "5           2022-03-01            26150.0               66.5      51.741195\n",
      "6           2022-04-01            21620.0               55.0      51.722488\n",
      "7           2022-05-30            21010.0               53.5      51.672405\n",
      "[saved] out\\FNP AEC sous-traitance in Situ__TAUX HORAIRE ST__table_1.csv\n",
      "\n",
      "--- table detected ---\n",
      "name: FNP AEC sous-traitance in Situ__TAUX HORAIRE ST__table_2\n",
      "rows: 19 | cols: 4\n",
      "columns: mois, annee, st_expleo, st_externe\n",
      "\n",
      "=== schema ===\n",
      "mois: STRING\n",
      "annee: INT\n",
      "st_expleo: FLOAT\n",
      "st_externe: FLOAT\n",
      "\n",
      "=== sample (top 8) ===\n",
      "   mois  annee  st_expleo  st_externe\n",
      "0  juil     19  50.627472   46.130031\n",
      "1  août     19  49.721986   46.491228\n",
      "2  sept     19  49.639793   45.987921\n",
      "3   oct     19  51.757381   46.114958\n",
      "4   nov     19  51.272868   46.098246\n",
      "5   déc     19  51.711446   46.052632\n",
      "6  janv     20  51.625701   45.799916\n",
      "7  févr     20  51.294541   45.381837\n",
      "[saved] out\\FNP AEC sous-traitance in Situ__TAUX HORAIRE ST__table_2.csv\n",
      "\n",
      "--- table detected ---\n",
      "name: FNP AEC sous-traitance in Situ__TAUX HORAIRE ST__table_3\n",
      "rows: 8 | cols: 4\n",
      "columns: oct, 21, 5095693779904306, 4997009569377991\n",
      "\n",
      "=== schema ===\n",
      "oct: STRING\n",
      "21: INT\n",
      "5095693779904306: FLOAT\n",
      "4997009569377991: FLOAT\n",
      "\n",
      "=== sample (top 8) ===\n",
      "    oct  21  5095693779904306  4997009569377991\n",
      "0   nov  21         51.254793         49.981203\n",
      "1   déc  21         51.420217              50.0\n",
      "2  janv  22         52.085402              50.0\n",
      "3  févr  22         51.754386              50.0\n",
      "4  mars  22         51.741195              50.0\n",
      "5   avr  22         51.722488              50.0\n",
      "6   mai  22         51.672405              50.0\n",
      "7  juin  22         51.949318              50.0\n",
      "[saved] out\\FNP AEC sous-traitance in Situ__TAUX HORAIRE ST__table_3.csv\n",
      "\n",
      "=== file ===\n",
      "Tauxdechange.xlsx  (C:\\globasoft\\aerotech\\fic\\Tauxdechange.xlsx)\n",
      "\n",
      "--- table detected ---\n",
      "name: Tauxdechange__2024__table_1\n",
      "rows: 256 | cols: 12\n",
      "columns: date, eur, usd, gbp, jpy, chf, aud, cad, cny, sek, nzd, zar\n",
      "\n",
      "=== schema ===\n",
      "date: DATE\n",
      "eur: INT\n",
      "usd: FLOAT\n",
      "gbp: FLOAT\n",
      "jpy: FLOAT\n",
      "chf: FLOAT\n",
      "aud: FLOAT\n",
      "cad: FLOAT\n",
      "cny: FLOAT\n",
      "sek: FLOAT\n",
      "nzd: FLOAT\n",
      "zar: FLOAT\n",
      "\n",
      "=== sample (top 8) ===\n",
      "         date  eur      usd     gbp      jpy     chf      aud      cad      cny      sek      nzd      zar\n",
      "0  2024-01-02    1  0.91274  1.1541  0.00642  1.0747  0.61931  0.68658  0.12777  0.08965  0.57238   0.0491\n",
      "1  2024-01-03    1  0.91583  1.1565   0.0064  1.0727  0.61592  0.68615  0.12811  0.08935  0.57094   0.0487\n",
      "2  2024-01-04    1  0.91299   1.159  0.00633  1.0738  0.61425  0.68479  0.12767  0.08936  0.57052  0.04895\n",
      "3  2024-01-05    1  0.91567    1.16  0.00631   1.073  0.61211  0.68493  0.12799  0.08901  0.56935  0.04866\n",
      "4  2024-01-08    1  0.91358  1.1608  0.00632  1.0743  0.61058  0.68255  0.12756  0.08921  0.56796  0.04879\n",
      "5  2024-01-09    1  0.91408  1.1636  0.00634  1.0738  0.61203  0.68432  0.12758  0.08919  0.57058  0.04893\n",
      "6  2024-01-10    1  0.91358  1.1625  0.00629  1.0711  0.61222  0.68264  0.12743  0.08931  0.56925  0.04899\n",
      "7  2024-01-11    1  0.91017  1.1608  0.00626  1.0709  0.61091  0.68134  0.12715  0.08931  0.56893  0.04894\n",
      "[saved] out\\Tauxdechange__2024__table_1.csv\n",
      "\n",
      "--- table detected ---\n",
      "name: Tauxdechange__2025__table_1\n",
      "rows: 128 | cols: 12\n",
      "columns: date, eur, usd, gbp, jpy, chf, aud, cad, cny, sek, nzd, zar\n",
      "\n",
      "=== schema ===\n",
      "date: DATE\n",
      "eur: INT\n",
      "usd: FLOAT\n",
      "gbp: FLOAT\n",
      "jpy: FLOAT\n",
      "chf: FLOAT\n",
      "aud: FLOAT\n",
      "cad: FLOAT\n",
      "cny: FLOAT\n",
      "sek: FLOAT\n",
      "nzd: FLOAT\n",
      "zar: FLOAT\n",
      "\n",
      "=== sample (top 8) ===\n",
      "         date  eur      usd     gbp      jpy     chf      aud      cad      cny      sek      nzd      zar\n",
      "0  2025-01-02    1   0.9689  1.2031  0.00617  1.0671  0.60176  0.67182  0.13274  0.08755  0.54342  0.05189\n",
      "1  2025-01-03    1  0.97097  1.2049  0.00618  1.0681  0.60401  0.67376  0.13268  0.08742  0.54448  0.05183\n",
      "2  2025-01-06    1  0.95914  1.2034  0.00613  1.0643  0.60405  0.67051  0.13109  0.08723  0.54484  0.05189\n",
      "3  2025-01-07    1  0.96219  1.2061   0.0061  1.0609  0.60397  0.67213  0.13133  0.08715  0.54594  0.05176\n",
      "4  2025-01-08    1   0.9722   1.199  0.00614  1.0662  0.60241  0.67554   0.1326  0.08686  0.54398  0.05145\n",
      "5  2025-01-09    1   0.9704  1.1932  0.00615  1.0642  0.60132  0.67426  0.13235    0.087  0.54298   0.0514\n",
      "6  2025-01-10    1   0.9705  1.1948  0.00614   1.062  0.60042  0.67363  0.13238  0.08698  0.54189  0.05098\n",
      "7  2025-01-13    1  0.98058  1.1882  0.00624    1.07  0.60321  0.68032  0.13374  0.08691  0.54472  0.05122\n",
      "[saved] out\\Tauxdechange__2025__table_1.csv\n",
      "\n",
      "=== done ===\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "import warnings\n",
    "\n",
    "# ---- Désactive l'avertissement bruyant de pandas sur l'inférence de format de date ----\n",
    "warnings.filterwarnings(\"ignore\", message=\"Could not infer format.*\", category=UserWarning)\n",
    "\n",
    "# ================== PARAMS ================== #\n",
    "ROOT_DIR = Path(\"fic\")                # Dossier d'entrée (récursif)\n",
    "EXPORT_DIR = Path(\"out\")              # Dossier de sortie CSV (créé si export activé)\n",
    "EXPORT_TABLES = True                  # Mettre True pour exporter les tables détectées\n",
    "SHOW_SAMPLES = True                   # Afficher un aperçu (head) des tables détectées\n",
    "\n",
    "# Heuristiques génériques (adapter si besoin)\n",
    "MIN_COLS = 2               # nb min de colonnes non vides pour considérer une ligne \"tabulaire\"\n",
    "MIN_CONSEC_ROWS = 5        # nb min de lignes consécutives \"tabulaires\" pour former un bloc\n",
    "ROW_EMPTY_TOL = 1          # nb max de lignes vides autorisées à l'intérieur d'un bloc\n",
    "STOP_EMPTY_RUN = 5         # stop table si on rencontre STOP_EMPTY_RUN lignes vides consécutives après le header\n",
    "HEADER_SCAN_DEPTH = 6      # nb de premières lignes du bloc à tester pour choisir la meilleure ligne d'en-tête\n",
    "\n",
    "# Filtrage de colonnes après extraction (pour supprimer col/col_2… vides)\n",
    "MIN_NON_NULL_RATIO = 0.05  # garder une colonne si >= 5% de valeurs non nulles\n",
    "MIN_NON_NULL_ABS   = 2     # ... ou au moins 2 valeurs non nulles (filet de sécurité)\n",
    "\n",
    "# Inférence de types\n",
    "INFER_TYPES = True\n",
    "DATE_NAME_HINTS = (\"date\", \"dt_\", \"_dt\", \"attribution\", \"retrait\")\n",
    "# tokens typiques d'une date (séparateurs, mois FR/EN abrégés)\n",
    "DATE_TOKEN_RE = re.compile(\n",
    "    r\"[/\\-.]|(?:jan|feb|mar|apr|mai|may|jun|jul|aug|sep|oct|nov|dec|\"\n",
    "    r\"janv|févr|fevr|avr|juil|sept|oct|nov|déc|dec)\",\n",
    "    re.I\n",
    ")\n",
    "BOOL_TRUE  = {\"true\",\"vrai\",\"oui\",\"y\",\"1\"}\n",
    "BOOL_FALSE = {\"false\",\"faux\",\"non\",\"n\",\"0\"}\n",
    "\n",
    "# Garde-fous avant de tenter le parse date (évite les warnings inutiles)\n",
    "PRE_PARSE_TOKEN_RATIO_IF_NAME   = 0.10  # si le nom ressemble à une date\n",
    "PRE_PARSE_TOKEN_RATIO_NO_NAME   = 0.30  # sinon\n",
    "# ============================================ #\n",
    "\n",
    "def strip_accents_lower(s: str) -> str:\n",
    "    if s is None or pd.isna(s):\n",
    "        return \"\"\n",
    "    s = str(s)\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    s = \"\".join(c for c in s if not unicodedata.combining(c))\n",
    "    return s.lower().strip()\n",
    "\n",
    "def safe_read_excel_all_sheets(path: Path):\n",
    "    xls = pd.ExcelFile(path, engine=\"openpyxl\")\n",
    "    out = []\n",
    "    for sheet in xls.sheet_names:\n",
    "        df = pd.read_excel(xls, sheet_name=sheet, header=None)\n",
    "        out.append((sheet, df))\n",
    "    return out\n",
    "\n",
    "def pick_encoding(path: Path):\n",
    "    try:\n",
    "        from charset_normalizer import from_path\n",
    "        res = from_path(str(path)).best()\n",
    "        return res.encoding if res else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def read_csv_robust(path: Path):\n",
    "    enc_guess = pick_encoding(path)\n",
    "    candidates = [e for e in [enc_guess, \"utf-8-sig\", \"utf-8\", \"cp1252\", \"latin-1\", \"iso-8859-1\"] if e]\n",
    "    for enc in candidates:\n",
    "        try:\n",
    "            return pd.read_csv(path, sep=None, engine=\"python\", encoding=enc, header=None)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return pd.read_csv(path, sep=None, engine=\"python\", encoding=\"latin-1\", encoding_errors=\"replace\", header=None)\n",
    "\n",
    "def is_tabular_row(row, min_cols=MIN_COLS):\n",
    "    return row.notna().sum() >= min_cols\n",
    "\n",
    "def choose_header_row(block: pd.DataFrame):\n",
    "    best_idx = None\n",
    "    best_score = -1\n",
    "    limit = min(len(block), HEADER_SCAN_DEPTH)\n",
    "    for i in range(limit):\n",
    "        row = block.iloc[i]\n",
    "        vals = row.tolist()\n",
    "        non_empty = sum(pd.notna(v) and str(v).strip() != \"\" for v in vals)\n",
    "        texty = 0\n",
    "        for v in vals:\n",
    "            s = str(v).strip() if pd.notna(v) else \"\"\n",
    "            if s == \"\" or s.lower().startswith(\"unnamed\"):\n",
    "                continue\n",
    "            if re.search(r\"[A-Za-zÀ-ÿ]\", s):\n",
    "                texty += 1\n",
    "        score = non_empty * 2 + texty\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_idx = i\n",
    "    return best_idx if best_idx is not None else 0\n",
    "\n",
    "def clean_columns(vals):\n",
    "    cols = []\n",
    "    seen = {}\n",
    "    for v in vals:\n",
    "        s = strip_accents_lower(v)\n",
    "        s = s.replace(\"\\n\", \" \")\n",
    "        s = re.sub(r\"\\s+\", \" \", s).strip(\" -_\")\n",
    "        if s == \"\" or s.startswith(\"unnamed\"):\n",
    "            s = \"col\"\n",
    "        s = re.sub(r\"[^a-z0-9_ ]\", \"\", s)\n",
    "        s = re.sub(r\"\\s+\", \"_\", s).strip(\"_\")\n",
    "        if s == \"\":\n",
    "            s = \"col\"\n",
    "        if s in seen:\n",
    "            seen[s] += 1\n",
    "            s = f\"{s}_{seen[s]}\"\n",
    "        else:\n",
    "            seen[s] = 1\n",
    "        cols.append(s)\n",
    "    return cols\n",
    "\n",
    "def detect_blocks(df: pd.DataFrame):\n",
    "    if list(df.columns) != list(range(df.shape[1])):\n",
    "        df = df.copy()\n",
    "        df.columns = list(range(df.shape[1]))\n",
    "\n",
    "    blocks = []\n",
    "    consec = 0\n",
    "    empties_inside = 0\n",
    "    start = None\n",
    "\n",
    "    for i in df.index:\n",
    "        row = df.loc[i]\n",
    "        if is_tabular_row(row):\n",
    "            if start is None:\n",
    "                start = i\n",
    "                consec = 0\n",
    "                empties_inside = 0\n",
    "            consec += 1\n",
    "        else:\n",
    "            if start is not None:\n",
    "                empties_inside += 1\n",
    "                if empties_inside > ROW_EMPTY_TOL:\n",
    "                    end = i - (empties_inside)\n",
    "                    if end >= start and consec >= MIN_CONSEC_ROWS:\n",
    "                        blocks.append((start, end))\n",
    "                    start = None\n",
    "                    consec = 0\n",
    "                    empties_inside = 0\n",
    "\n",
    "    if start is not None and consec >= MIN_CONSEC_ROWS:\n",
    "        blocks.append((start, df.index[-1]))\n",
    "\n",
    "    return blocks\n",
    "\n",
    "def prune_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df.empty:\n",
    "        return df\n",
    "    df2 = df.dropna(axis=1, how=\"all\").copy()\n",
    "    if df2.empty:\n",
    "        return df2\n",
    "    n = len(df2)\n",
    "    keep = []\n",
    "    for c in df2.columns:\n",
    "        nnz = df2[c].notna().sum()\n",
    "        if nnz >= max(MIN_NON_NULL_ABS, int(n * MIN_NON_NULL_RATIO)):\n",
    "            keep.append(c)\n",
    "    return df2[keep].copy() if keep else pd.DataFrame()\n",
    "\n",
    "# ---------- Inférence de types & affichage schéma ---------- #\n",
    "\n",
    "def infer_and_cast_column(s: pd.Series, col_name: str) -> tuple[pd.Series, str]:\n",
    "    \"\"\"\n",
    "    Retourne (serie_convertie, type_inféré) parmi: date, int, float, bool, string.\n",
    "    On ne renvoie pas 'category' pour garder des types simples.\n",
    "    \"\"\"\n",
    "    name_norm = strip_accents_lower(col_name)\n",
    "    looks_like_date_name = any(h in name_norm for h in DATE_NAME_HINTS)\n",
    "\n",
    "    s_obj = s.astype(\"string\")\n",
    "    non_empty = s_obj.dropna()\n",
    "\n",
    "    # ratio valeurs \"numériques pures\" (ex: 1, 20240516)\n",
    "    numeric_only_ratio = 0.0\n",
    "    if len(non_empty) > 0:\n",
    "        numeric_only_ratio = sum(bool(re.fullmatch(r\"\\d+(?:[.,]\\d+)?\", str(x).strip()))\n",
    "                                 for x in non_empty) / len(non_empty)\n",
    "\n",
    "    # ratio valeurs contenant des \"tokens\" de date\n",
    "    date_token_ratio = 0.0\n",
    "    if len(non_empty) > 0:\n",
    "        date_token_ratio = sum(bool(DATE_TOKEN_RE.search(str(x)))\n",
    "                               for x in non_empty) / len(non_empty)\n",
    "\n",
    "    # ---- 1) Dates : on ne tente le parse que si les tokens le suggèrent ----\n",
    "    should_try_parse = (\n",
    "        (looks_like_date_name and date_token_ratio >= PRE_PARSE_TOKEN_RATIO_IF_NAME) or\n",
    "        ((not looks_like_date_name) and date_token_ratio >= PRE_PARSE_TOKEN_RATIO_NO_NAME and numeric_only_ratio < 0.80)\n",
    "    )\n",
    "\n",
    "    if should_try_parse:\n",
    "        parsed_dates = pd.to_datetime(s, errors=\"coerce\", dayfirst=True)  # pas d'infer_datetime_format\n",
    "        date_ratio = parsed_dates.notna().sum() / max(1, s.notna().sum())\n",
    "\n",
    "        accept_date = (date_ratio >= 0.30) if looks_like_date_name else (date_ratio >= 0.70)\n",
    "        if accept_date:\n",
    "            return parsed_dates.dt.normalize(), \"date\"\n",
    "\n",
    "    # ---- 2) Numériques ----\n",
    "    as_num = pd.to_numeric(s, errors=\"coerce\")\n",
    "    num_ratio = as_num.notna().sum() / max(1, s.notna().sum())\n",
    "    if num_ratio >= 0.85:\n",
    "        as_int = as_num.dropna()\n",
    "        if len(as_int) == 0:\n",
    "            return as_num.astype(\"Float64\"), \"float\"\n",
    "        if (as_int % 1 == 0).all():\n",
    "            return as_num.astype(\"Int64\"), \"int\"\n",
    "        else:\n",
    "            return as_num.astype(\"Float64\"), \"float\"\n",
    "\n",
    "    # ---- 3) Booléens ----\n",
    "    vals = non_empty.map(strip_accents_lower).unique().tolist()\n",
    "    small_set = set(vals)\n",
    "    if 1 <= len(small_set) <= 3:\n",
    "        mapped = s.astype(str).map(strip_accents_lower)\n",
    "        def map_bool(x):\n",
    "            if x in BOOL_TRUE: return True\n",
    "            if x in BOOL_FALSE: return False\n",
    "            return pd.NA\n",
    "        mb = mapped.map(map_bool)\n",
    "        if mb.notna().sum() / max(1, mapped.notna().sum()) >= 0.9:\n",
    "            return mb.astype(\"boolean\"), \"bool\"\n",
    "\n",
    "    # ---- 4) Texte ----\n",
    "    return s.astype(\"string\"), \"string\"\n",
    "\n",
    "def infer_types_df(df: pd.DataFrame) -> tuple[pd.DataFrame, dict]:\n",
    "    schema = {}\n",
    "    out = df.copy()\n",
    "    for c in out.columns:\n",
    "        out[c], t = infer_and_cast_column(out[c], c)\n",
    "        schema[c] = t\n",
    "    return out, schema\n",
    "\n",
    "def show_schema(df: pd.DataFrame, schema: dict):\n",
    "    print(\"\\n=== schema ===\")\n",
    "    # Affichage simplifié : \"Champ: TYPE\" (en MAJUSCULE)\n",
    "    for c in df.columns:\n",
    "        t = schema.get(c, str(df[c].dtype)).upper()\n",
    "        print(f\"{c}: {t}\")\n",
    "\n",
    "# ----------------------------------------------------------- #\n",
    "\n",
    "def carve_table_from_block(df_block: pd.DataFrame):\n",
    "    if df_block.empty:\n",
    "        return None\n",
    "    h_rel = choose_header_row(df_block)\n",
    "    header_vals = df_block.iloc[h_rel].tolist()\n",
    "    cols = clean_columns(header_vals)\n",
    "\n",
    "    data = df_block.iloc[h_rel+1:].copy()\n",
    "    data.columns = cols\n",
    "\n",
    "    # stop à N lignes vides consécutives après le header\n",
    "    empty_run = 0\n",
    "    cut_idx = data.index[-1]\n",
    "    for idx in data.index:\n",
    "        if data.loc[idx].isna().all():\n",
    "            empty_run += 1\n",
    "            if empty_run >= STOP_EMPTY_RUN:\n",
    "                cut_idx = idx - STOP_EMPTY_RUN\n",
    "                break\n",
    "        else:\n",
    "            empty_run = 0\n",
    "\n",
    "    data = data.loc[:cut_idx]\n",
    "    data = data[data.notna().sum(axis=1) >= MIN_COLS]\n",
    "\n",
    "    data = prune_columns(data)\n",
    "    if data.empty:\n",
    "        return None\n",
    "\n",
    "    # inférence & cast de types\n",
    "    if INFER_TYPES:\n",
    "        data, schema = infer_types_df(data)\n",
    "    else:\n",
    "        schema = {c: str(data[c].dtype) for c in data.columns}\n",
    "\n",
    "    data = data.reset_index(drop=True)\n",
    "\n",
    "    # Normalisation d’affichage des dates (visuel console + CSV)\n",
    "    for c, t in schema.items():\n",
    "        if t == \"date\":\n",
    "            try:\n",
    "                data[c] = pd.to_datetime(data[c], errors=\"coerce\").dt.strftime(\"%Y-%m-%d\")\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    return data, schema\n",
    "\n",
    "def find_tables_in_sheet(df_raw: pd.DataFrame):\n",
    "    # ⚠️ Correction du bug ici: utiliser df_raw.shape (pas df.shape)\n",
    "    if list(df_raw.columns) != list(range(df_raw.shape[1])):\n",
    "        df_raw = df_raw.copy()\n",
    "        df_raw.columns = list(range(df_raw.shape[1]))\n",
    "\n",
    "    blocks = detect_blocks(df_raw)\n",
    "\n",
    "    tables = []\n",
    "    for (start, end) in blocks:\n",
    "        block = df_raw.loc[start:end, :]\n",
    "        carved = carve_table_from_block(block)\n",
    "        if carved is None:\n",
    "            continue\n",
    "        table, schema = carved\n",
    "        if table is not None and table.shape[1] >= MIN_COLS and table.shape[0] >= 1:\n",
    "            tables.append((table, schema))\n",
    "    return tables\n",
    "\n",
    "def process_file(path: Path):\n",
    "    results = []  # [(sheet, idx, df_table, schema)]\n",
    "    if path.suffix.lower() in (\".xlsx\", \".xlsm\"):\n",
    "        sheets = safe_read_excel_all_sheets(path)\n",
    "        for sheet, df_raw in sheets:\n",
    "            tables = find_tables_in_sheet(df_raw)\n",
    "            for i, (t, sc) in enumerate(tables, start=1):\n",
    "                results.append((sheet, i, t, sc))\n",
    "    elif path.suffix.lower() == \".csv\":\n",
    "        df_raw = read_csv_robust(path)\n",
    "        tables = find_tables_in_sheet(df_raw)\n",
    "        for i, (t, sc) in enumerate(tables, start=1):\n",
    "            results.append((None, i, t, sc))\n",
    "    else:\n",
    "        raise ValueError(f\"Extension non gérée: {path.suffix}\")\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    if not ROOT_DIR.exists():\n",
    "        print(f\"[error] Dossier introuvable : {ROOT_DIR.resolve()}\")\n",
    "        return\n",
    "\n",
    "    files = []\n",
    "    for pat in (\"*.xlsx\", \"*.xlsm\", \"*.csv\"):\n",
    "        files += [p for p in ROOT_DIR.rglob(pat) if p.is_file() and not p.name.startswith(\"~$\")]\n",
    "\n",
    "    print(\"=== data header: folder info ===\")\n",
    "    print(f\"path: {ROOT_DIR.resolve()}\")\n",
    "    print(f\"files_found: {len(files)}\")\n",
    "\n",
    "    if not files:\n",
    "        print(\"[warn] Aucun fichier .xlsx/.xlsm/.csv trouvé.\")\n",
    "        return\n",
    "\n",
    "    if EXPORT_TABLES:\n",
    "        EXPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for f in sorted(files):\n",
    "        print(\"\\n=== file ===\")\n",
    "        print(f\"{f.name}  ({f.resolve()})\")\n",
    "\n",
    "        try:\n",
    "            tables = process_file(f)\n",
    "        except Exception as e:\n",
    "            print(f\"[error] Lecture échouée pour {f.name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        if not tables:\n",
    "            print(\"[info] Aucune table détectée\")\n",
    "            continue\n",
    "\n",
    "        for sheet, idx, df, schema in tables:\n",
    "            title = f\"{f.stem}__{sheet or 'sheet'}__table_{idx}\"\n",
    "            print(f\"\\n--- table detected ---\")\n",
    "            print(f\"name: {title}\")\n",
    "            print(f\"rows: {len(df)} | cols: {df.shape[1]}\")\n",
    "            print(\"columns:\", \", \".join(map(str, df.columns.tolist())))\n",
    "\n",
    "            # >>> affichage du schéma (simple)\n",
    "            show_schema(df, schema)\n",
    "\n",
    "            if SHOW_SAMPLES:\n",
    "                with pd.option_context(\"display.max_columns\", 60, \"display.width\", 160):\n",
    "                    print(\"\\n=== sample (top 8) ===\")\n",
    "                    print(df.head(8))\n",
    "\n",
    "            if EXPORT_TABLES:\n",
    "                out_path = EXPORT_DIR / f\"{title}.csv\"\n",
    "                df.to_csv(out_path, index=False)\n",
    "                print(f\"[saved] {out_path}\")\n",
    "\n",
    "    print(\"\\n=== done ===\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aedbf3e-5480-49ff-9106-38db1c92c11b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
