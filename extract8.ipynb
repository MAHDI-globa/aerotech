{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee57f4b-4e4a-42ae-9683-343774c348f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyxlsb\n",
    "pip install sqlalchemy psycopg2-binary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6486e77-fdd0-49e0-90c2-094615d930e2",
   "metadata": {},
   "source": [
    "# Connexion BDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fa857a7-7626-475a-8915-0f79ef1f611b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q \"sqlalchemy>=2\" psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae207269-9650-4173-81eb-b44a74f42e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK, connecté.\n",
      "PostgreSQL 17.6 (Debian 17.6-1.pgdg12+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14+deb12u1) 12.2.0, 64-bit\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "from urllib.parse import quote_plus\n",
    "import pandas as pd\n",
    "\n",
    "PG_HOST = \"dpg-d3jq6apr0fns738f81i0-a.frankfurt-postgres.render.com\"\n",
    "PG_PORT = 5432\n",
    "PG_DB   = \"aerotec_datawarehouse\"\n",
    "PG_USER = \"aerotec_datawarehouse_user\"\n",
    "PG_PASS = \"LHTYZJ3aUDI8IeylbA1SZs9M9TsKQ4To\"\n",
    "\n",
    "conn_str = (\n",
    "    f\"postgresql+psycopg2://{PG_USER}:{quote_plus(PG_PASS)}@{PG_HOST}:{PG_PORT}/{PG_DB}\"\n",
    ")\n",
    "engine = create_engine(conn_str, connect_args={\"sslmode\": \"require\"}, pool_pre_ping=True)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    print(\"OK, connecté.\")\n",
    "    print(conn.execute(text(\"SELECT version();\")).scalar())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2341020a-4972-418e-b2a9-9c904a1541a7",
   "metadata": {},
   "source": [
    " # fichier qualité des trigrammes.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0127f132-cfba-4b30-b958-7ad1c70d19a1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07e0087b-c5bc-40e3-9c01-cd4dfaee5ee7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Feuille: PDG -> trigrammes.pdg ---\n",
      "rows=20 | cols=4\n",
      "Colonnes: edition, date, motif, redacteur\n",
      "\n",
      "Schema détecté:\n",
      "  - edition: INT  ->  integer\n",
      "  - date: DATE  ->  date\n",
      "  - motif: STRING  ->  text\n",
      "  - redacteur: STRING  ->  text\n",
      "\n",
      "Sample (top 8):\n",
      "    edition        date                                              motif    redacteur\n",
      "9         1  2024-06-10                                           Création  S. BELMONTE\n",
      "10        2  2024-09-16                           Ajout nouveaux arrivants    Y. RAGEOT\n",
      "11        3  2024-10-21                                    Ajout couturier    Y. RAGEOT\n",
      "12        4  2024-10-28  Mise à jour des dates d'entrée \n",
      "Ajout des habi...    Y. RAGEOT\n",
      "13        5  2024-12-16  Ajout nouvelle arrivante - 1 personne - Feriel...  F.BOULHABEL\n",
      "14        6  2024-12-18                              Départ de Yann RAGEOT  S. BELMONTE\n",
      "15        7  2024-12-19  Ajout de nouveaux arrivants - 4 personnes - Fr...  F.BOULHABEL\n",
      "16        8  2024-12-20  Ajout de nouvel arrivant - 1 personne - Loris ...  F.BOULHABEL\n",
      "\n",
      "--- Feuille: Liste -> trigrammes.liste ---\n",
      "rows=201 | cols=6\n",
      "Colonnes: nom_prenom, trig, personnel_int_ext, site, date_d_attribution, date_de_retrait\n",
      "\n",
      "Schema détecté:\n",
      "  - nom_prenom: STRING  ->  text\n",
      "  - trig: STRING  ->  text\n",
      "  - personnel_int_ext: STRING  ->  text\n",
      "  - site: STRING  ->  text\n",
      "  - date_d_attribution: DATE  ->  date\n",
      "  - date_de_retrait: STRING  ->  text\n",
      "\n",
      "Sample (top 8):\n",
      "                  nom_prenom trig personnel_int_ext site date_d_attribution      date_de_retrait\n",
      "9               ABAT Nicolas  ABT           Interne  AEC         2025-02-17                 <NA>\n",
      "10   ABDELLAOUI Schéhérazade  ADI           Interne  AEB         2025-05-05                 <NA>\n",
      "11          ADJEROUD Bastian  BAD           Interne  AEX         2024-05-21                 <NA>\n",
      "12              AGREBI Lilia  ARI           Interne  AEC         2025-02-24                 <NA>\n",
      "13          ALBERTON YANNICK  YAL           Interne  AEC         2018-11-05  2021-09-10 00:00:00\n",
      "14  ALIAS Séverine née HERAL  ALS           Interne  AEG         2024-05-21                 <NA>\n",
      "15      ALLARD Jean-François  ALD           Externe  AEC                NaN                 <NA>\n",
      "16               ALLARD Yann  YAD           Interne  AEC         2024-06-03                 <NA>\n",
      "\n",
      "Done. Feuilles analysées: 2\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, unicodedata, warnings\n",
    "\n",
    "FILE_PATH = r\"C:\\globasoft\\aerotech\\fic\\fichier qualité des trigrammes.xlsx\"\n",
    "SHOW_SAMPLE = True\n",
    "\n",
    "# --- utils courts ---\n",
    "def strip_accents_lower(s):\n",
    "    if s is None or (isinstance(s, float) and pd.isna(s)): return \"\"\n",
    "    s = unicodedata.normalize(\"NFKD\", str(s))\n",
    "    s = \"\".join(c for c in s if not unicodedata.combining(c))\n",
    "    return s.lower().strip()\n",
    "\n",
    "def snake_id(s):\n",
    "    s = strip_accents_lower(s)\n",
    "    s = re.sub(r\"[\\s\\.\\-]+\", \"_\", s)\n",
    "    s = re.sub(r\"[^a-z0-9_]\", \"_\", s)\n",
    "    return re.sub(r\"_+\", \"_\", s).strip(\"_\") or \"col\"\n",
    "\n",
    "def parse_number_like(s: pd.Series) -> pd.Series:\n",
    "    x = s.astype(\"string\").str.replace(\"\\u00A0\",\" \", regex=False).str.replace(\" \",\"\", regex=False)\n",
    "    x = x.str.replace(r\"(?<=\\d)\\.(?=\\d{3}(?:\\D|$))\",\"\", regex=True).str.replace(\",\",\".\", regex=False)\n",
    "    return pd.to_numeric(x, errors=\"coerce\")\n",
    "\n",
    "# --- header smarter ---\n",
    "HEADER_KEYWORDS = (\n",
    "    \"date\", \"motif\", \"rédact\", \"redact\", \"trig\", \"nom\", \"prénom\", \"prenom\",\n",
    "    \"personnel\", \"site\", \"retrait\", \"édition\", \"edition\"\n",
    ")\n",
    "\n",
    "def choose_header_row(df: pd.DataFrame, scan=25) -> int:\n",
    "    limit = min(len(df), scan)\n",
    "    header_candidate_idx = None\n",
    "    header_candidate_hits = -1\n",
    "    for i in range(limit):\n",
    "        row = df.iloc[i].astype(str)\n",
    "        hits = 0\n",
    "        for v in row:\n",
    "            t = strip_accents_lower(v)\n",
    "            if t and any(k in t for k in HEADER_KEYWORDS):\n",
    "                hits += 1\n",
    "        if hits >= 2 and hits > header_candidate_hits:\n",
    "            header_candidate_hits = hits\n",
    "            header_candidate_idx = i\n",
    "    if header_candidate_idx is not None:\n",
    "        return header_candidate_idx\n",
    "    best, idx = -1, 0\n",
    "    for i in range(limit):\n",
    "        row = df.iloc[i].astype(str)\n",
    "        non_empty = row.map(lambda x: x.strip()!=\"\").sum()\n",
    "        texty = row.map(lambda x: bool(re.search(r\"[A-Za-zÀ-ÿ]\", x))).sum()\n",
    "        score = non_empty*2 + texty\n",
    "        if score>best: best, idx = score, i\n",
    "    return idx\n",
    "\n",
    "def normalize_columns(header_vals):\n",
    "    cols, seen = [], {}\n",
    "    for v in header_vals:\n",
    "        s = snake_id(v) if (v is not None and str(v).strip()!=\"\") else \"col\"\n",
    "        seen[s] = seen.get(s,0)+1\n",
    "        cols.append(s if seen[s]==1 else f\"{s}_{seen[s]}\")\n",
    "    return cols\n",
    "\n",
    "def drop_empty_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.dropna(axis=1, how=\"all\")\n",
    "    blank_cols = [c for c in df.columns if df[c].dropna().astype(str).str.strip().eq(\"\").all()]\n",
    "    if blank_cols:\n",
    "        df = df.drop(columns=blank_cols)\n",
    "    return df\n",
    "\n",
    "# --- inférence minimale robuste ---\n",
    "MAP_TRUE  = {\"true\",\"vrai\",\"oui\",\"yes\",\"1\",\"y\",\"o\"}\n",
    "MAP_FALSE = {\"false\",\"faux\",\"non\",\"no\",\"0\",\"n\"}\n",
    "\n",
    "# Regex SANS groupes capturants -> évite le warning pandas\n",
    "DATE_TOKEN_RE = re.compile(\n",
    "    r\"(?:\\d{4}[-/\\.]\\d{1,2}[-/\\.]\\d{1,2})|(?:\\d{1,2}[-/\\.]\\d{1,2}[-/\\.]\\d{2,4})|\"\n",
    "    r\"(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec|janv|févr|fevr|avr|mai|juin|juil|sept|oct|nov|d[ée]c)\",\n",
    "    re.I\n",
    ")\n",
    "ISO_DATE_RE = re.compile(r\"^\\d{4}-\\d{2}-\\d{2}(?:[ T]\\d{2}:\\d{2}:\\d{2})?$\")\n",
    "COLNAME_DATE_HINTS = (\"date\", \"dt\", \"heure\", \"time\")\n",
    "\n",
    "def infer_col(s: pd.Series):\n",
    "    s = s.copy()\n",
    "    ss = s.astype(\"string\").str.strip()\n",
    "    ss = ss.where(~ss.fillna(\"\").eq(\"0\"), pd.NA)  # éviter 0 -> 1970-01-01\n",
    "\n",
    "    # 0) ISO détecté -> on parse d'abord en ISO (dayfirst=False) pour éviter le warning\n",
    "    iso_mask = ss.fillna(\"\").str.match(ISO_DATE_RE)\n",
    "    if iso_mask.mean() >= 0.5:\n",
    "        dt_iso = pd.to_datetime(ss.where(iso_mask), errors=\"coerce\", dayfirst=False)\n",
    "        ok = dt_iso.notna().mean() if len(ss) else 0.0\n",
    "        if ok >= 0.5:\n",
    "            has_time = (dt_iso.dt.time.astype(str) != \"00:00:00\").mean() > 0.2\n",
    "            return (\n",
    "                dt_iso.dt.strftime(\"%Y-%m-%d %H:%M:%S\") if has_time else dt_iso.dt.strftime(\"%Y-%m-%d\"),\n",
    "                \"DATETIME\" if has_time else \"DATE\"\n",
    "            )\n",
    "\n",
    "    # 1) Excel serial dates plausibles\n",
    "    as_num = pd.to_numeric(ss, errors=\"coerce\")\n",
    "    frac_num = as_num.notna().mean() if len(ss) else 0.0\n",
    "    if frac_num >= 0.9:\n",
    "        mask = as_num.between(60, 2950000)  # >=60 = après 1900-03-01\n",
    "        parsed = pd.to_datetime(as_num.where(mask), unit=\"D\", origin=\"1899-12-30\", errors=\"coerce\")\n",
    "        ok = parsed.notna().mean() if len(ss) else 0.0\n",
    "        if ok >= 0.7:\n",
    "            has_time = (parsed.dt.time.astype(str) != \"00:00:00\").mean() > 0.2\n",
    "            return (\n",
    "                parsed.dt.strftime(\"%Y-%m-%d %H:%M:%S\") if has_time else parsed.dt.strftime(\"%Y-%m-%d\"),\n",
    "                \"DATETIME\" if has_time else \"DATE\"\n",
    "            )\n",
    "\n",
    "    # 2) tokens de date ou nom de colonne “datey”\n",
    "    colname_hint = any(h in strip_accents_lower(s.name or \"\") for h in COLNAME_DATE_HINTS)\n",
    "    date_token_ratio = ss.fillna(\"\").str.contains(DATE_TOKEN_RE, na=False).mean()\n",
    "    looks_datey = colname_hint or (date_token_ratio >= 0.30)\n",
    "    if looks_datey:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", message=\"Could not infer format.*\", category=UserWarning)\n",
    "            dt1 = pd.to_datetime(ss, errors=\"coerce\", dayfirst=True,  cache=True)\n",
    "            dt2 = pd.to_datetime(ss, errors=\"coerce\", dayfirst=False, cache=True)\n",
    "        dt = dt2 if dt2.notna().sum() > dt1.notna().sum() else dt1\n",
    "        ok = dt.notna().mean() if len(ss) else 0.0\n",
    "        # seuil plus bas si le NOM de colonne suggère une date (ex: 'date_de_retrait')\n",
    "        ok_thresh = 0.50 if colname_hint else 0.70\n",
    "        if ok >= ok_thresh:\n",
    "            has_time = (dt.dt.time.astype(str) != \"00:00:00\").mean() > 0.2\n",
    "            return (\n",
    "                pd.to_datetime(dt).dt.strftime(\"%Y-%m-%d %H:%M:%S\") if has_time else pd.to_datetime(dt).dt.strftime(\"%Y-%m-%d\"),\n",
    "                \"DATETIME\" if has_time else \"DATE\"\n",
    "            )\n",
    "\n",
    "    # 3) bool strict\n",
    "    mb = ss.str.lower().map(lambda x: True if x in MAP_TRUE else (False if x in MAP_FALSE else pd.NA))\n",
    "    if (mb.notna().mean() if len(ss) else 0) >= 0.98:\n",
    "        return mb.astype(\"boolean\"), \"BOOL\"\n",
    "\n",
    "    # 4) nombre\n",
    "    nums = parse_number_like(ss)\n",
    "    if (nums.notna().mean() if len(ss.dropna()) else 0) >= 0.85:\n",
    "        nz = nums.dropna()\n",
    "        if len(nz) and (np.mod(nz, 1) == 0).all():\n",
    "            return nums.astype(\"Int64\"), \"INT\"\n",
    "        return nums.astype(\"Float64\"), \"FLOAT\"\n",
    "\n",
    "    # 5) texte\n",
    "    return ss.astype(\"string\"), \"STRING\"\n",
    "\n",
    "def pg_type(tag: str) -> str:\n",
    "    return {\n",
    "        \"DATE\":\"date\", \"DATETIME\":\"timestamp without time zone\",\n",
    "        \"INT\":\"integer\", \"FLOAT\":\"double precision\", \"BOOL\":\"boolean\"\n",
    "    }.get(tag, \"text\")\n",
    "\n",
    "# --- main ---\n",
    "def main():\n",
    "    xlsx = Path(FILE_PATH)\n",
    "    if not xlsx.exists():\n",
    "        print(f\"[error] Fichier introuvable: {xlsx}\"); return\n",
    "\n",
    "    sheets = pd.read_excel(xlsx, sheet_name=None, engine=\"openpyxl\", header=None)\n",
    "\n",
    "    done = 0\n",
    "    for name, raw in sheets.items():\n",
    "        raw = raw.dropna(how=\"all\", axis=0).dropna(how=\"all\", axis=1)\n",
    "        if raw.empty: continue\n",
    "\n",
    "        h = choose_header_row(raw, scan=25)\n",
    "        cols = normalize_columns(raw.iloc[h].tolist())\n",
    "        df = raw.iloc[h+1:].copy()\n",
    "        df.columns = cols\n",
    "\n",
    "        df = df.dropna(how=\"all\")\n",
    "        df = drop_empty_columns(df)\n",
    "        if df.empty: \n",
    "            continue\n",
    "\n",
    "        schema = {}\n",
    "        for c in df.columns:\n",
    "            casted, tag = infer_col(df[c])\n",
    "            df[c] = casted\n",
    "            schema[c] = tag\n",
    "\n",
    "        base = f\"trigrammes.{snake_id(name)}\"\n",
    "        print(f\"\\n--- Feuille: {name} -> {base} ---\")\n",
    "        print(f\"rows={len(df)} | cols={df.shape[1]}\")\n",
    "        print(\"Colonnes:\", \", \".join(df.columns.astype(str)))\n",
    "        print(\"\\nSchema détecté:\")\n",
    "        for c in df.columns:\n",
    "            print(f\"  - {c}: {schema[c]}  ->  {pg_type(schema[c])}\")\n",
    "\n",
    "        if SHOW_SAMPLE:\n",
    "            with pd.option_context(\"display.max_columns\", 80, \"display.width\", 200):\n",
    "                print(\"\\nSample (top 8):\")\n",
    "                print(df.head(8))\n",
    "\n",
    "        done += 1\n",
    "\n",
    "    print(f\"\\nDone. Feuilles analysées: {done}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512156ef-83e5-48d0-9366-eb6acf766b53",
   "metadata": {},
   "source": [
    "# CatClients.xlsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00e463cb-e4b5-4166-8712-a60c764a7ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:39:47] Fichier: C:\\globasoft\\aerotech\\fic\\Conditionsdepaiement.xlsx\n",
      "[17:39:47] Feuille[0]: shape=(19, 3)\n",
      "[17:39:47] Après drop vides: (19, 3) -> (19, 3)\n",
      "[17:39:47] Colonnes détectées: code_condition, libelle, delai_source\n",
      "[17:39:47] Remplissage delai_jours depuis delai_source: +17 lignes\n",
      "\n",
      "--- Conditions de paiement (collecte) ---\n",
      "rows=19 | cols=3\n",
      "Colonnes: code_condition, libelle, delai_jours\n",
      "\n",
      "Schéma final:\n",
      "  - code_condition : INT (Int64 nullable)\n",
      "  - libelle        : STRING (string)\n",
      "  - delai_jours    : INT (Int64 nullable)\n",
      "\n",
      "Sample (top 15):\n",
      "    code_condition                        libelle  delai_jours\n",
      "0                1             Chèque à réception            0\n",
      "1                6   Virement bancaire à 30 jours           30\n",
      "2                7        Règlement à la commande            0\n",
      "3                9              Chèque à 30 jours           30\n",
      "4               15   Virement bancaire à 60 jours           60\n",
      "5               16   Virement bancaire à 45 jours           45\n",
      "6               18           Virement à réception            0\n",
      "7               25         Règlement 30 jours FDM           30\n",
      "8               23         Virement le 10 du Mois         <NA>\n",
      "9               13  Virement 45 jours fin de mois         <NA>\n",
      "10              24   Virement bancaire à 15 jours           15\n",
      "11               8           chéque sous 10 jours           10\n",
      "12              22              Chéque à 45 jours           45\n",
      "13              11          Chèque à la livraison            0\n",
      "14              19      Paiement par anticipation            0\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re, unicodedata\n",
    "from datetime import datetime\n",
    "\n",
    "# ========= CONFIG =========\n",
    "FILE_PATH = r\"C:\\globasoft\\aerotech\\fic\\Conditionsdepaiement.xlsx\"\n",
    "SHOW_SAMPLE = True\n",
    "\n",
    "# ========= LOG =========\n",
    "def now(): return datetime.now().strftime(\"%H:%M:%S\")\n",
    "def log(msg): print(f\"[{now()}] {msg}\", flush=True)\n",
    "\n",
    "# ========= UTILS =========\n",
    "def parse_number_like(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Normalise nombres FR/US et convertit en nombre (ou NaN).\"\"\"\n",
    "    x = series.astype(\"string\").str.replace(\"\\u00A0\", \" \", regex=False).str.replace(\" \", \"\", regex=False)\n",
    "    x = x.str.replace(r\"(?<=\\d)\\.(?=\\d{3}(?:\\D|$))\", \"\", regex=True)  # retire séparateurs de milliers type 1.234\n",
    "    x = x.str.replace(\",\", \".\", regex=False)                          # virgule -> point\n",
    "    return pd.to_numeric(x, errors=\"coerce\")\n",
    "\n",
    "# ========= MAIN =========\n",
    "def main():\n",
    "    xlsx = Path(FILE_PATH)\n",
    "    log(f\"Fichier: {xlsx}\")\n",
    "    if not xlsx.exists():\n",
    "        log(\"[error] Fichier introuvable\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        df0 = pd.read_excel(xlsx, sheet_name=0, header=None, engine=\"openpyxl\")\n",
    "    except Exception as e:\n",
    "        log(f\"[error] Lecture échouée: {e}\")\n",
    "        return\n",
    "\n",
    "    log(f\"Feuille[0]: shape={df0.shape}\")\n",
    "\n",
    "    # Purge lignes/colonnes totalement vides\n",
    "    df = df0.dropna(how=\"all\", axis=0).dropna(how=\"all\", axis=1)\n",
    "    log(f\"Après drop vides: {df0.shape} -> {df.shape}\")\n",
    "    if df.empty:\n",
    "        log(\"Feuille vide après nettoyage.\")\n",
    "        return\n",
    "\n",
    "    # On s'attend à 2 ou 3 colonnes: code, libellé, (option) délai\n",
    "    if df.shape[1] >= 3:\n",
    "        df = df.iloc[:, :3].copy()\n",
    "        df.columns = [\"code_condition\", \"libelle\", \"delai_source\"]\n",
    "        log(\"Colonnes détectées: code_condition, libelle, delai_source\")\n",
    "    elif df.shape[1] == 2:\n",
    "        df = df.iloc[:, :2].copy()\n",
    "        df.columns = [\"code_condition\", \"libelle\"]\n",
    "        log(\"Colonnes détectées: code_condition, libelle (pas de colonne delai_source)\")\n",
    "    else:\n",
    "        log(\"[warn] Moins de 2 colonnes non vides trouvées. Abandon.\")\n",
    "        return\n",
    "\n",
    "    # Types de base + trims\n",
    "    df[\"code_condition\"] = parse_number_like(df[\"code_condition\"]).astype(\"Int64\")\n",
    "    df[\"libelle\"] = df[\"libelle\"].astype(\"string\").str.strip()\n",
    "\n",
    "    # Colonne finale: delai_jours (Int64, nullable)\n",
    "    df[\"delai_jours\"] = pd.Series(pd.NA, index=df.index, dtype=\"Int64\")\n",
    "\n",
    "    # Si delai_source existe, l'utiliser (aucune déduction depuis libellé)\n",
    "    if \"delai_source\" in df.columns:\n",
    "        d0 = parse_number_like(df[\"delai_source\"]).astype(\"Int64\")\n",
    "        n_before = df[\"delai_jours\"].notna().sum()\n",
    "        df.loc[d0.notna(), \"delai_jours\"] = d0\n",
    "        n_after = df[\"delai_jours\"].notna().sum()\n",
    "        log(f\"Remplissage delai_jours depuis delai_source: +{int(n_after - n_before)} lignes\")\n",
    "\n",
    "    # Conserver UNIQUEMENT (code_condition, libelle, delai_jours)\n",
    "    keep_cols = [\"code_condition\", \"libelle\", \"delai_jours\"]\n",
    "    df = df[keep_cols]\n",
    "\n",
    "    # Affichage\n",
    "    print(\"\\n--- Conditions de paiement (collecte) ---\")\n",
    "    print(f\"rows={len(df)} | cols={df.shape[1]}\")\n",
    "    print(\"Colonnes:\", \", \".join(df.columns.astype(str)))\n",
    "\n",
    "    print(\"\\nSchéma final:\")\n",
    "    print(\"  - code_condition : INT (Int64 nullable)\")\n",
    "    print(\"  - libelle        : STRING (string)\")\n",
    "    print(\"  - delai_jours    : INT (Int64 nullable)\")\n",
    "\n",
    "    if SHOW_SAMPLE:\n",
    "        with pd.option_context(\"display.max_columns\", 100, \"display.width\", 200):\n",
    "            print(\"\\nSample (top 15):\")\n",
    "            print(df.head(15))\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_conditions = main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904113a8-3a66-4165-81c9-b213fcff63db",
   "metadata": {},
   "source": [
    "# FNP AEC projets - source.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6eb37216-3eab-4cc2-8ed7-61212191ea33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:47:50] Fichier: C:\\globasoft\\aerotech\\fic\\FNP AEC projets - source.xlsx\n",
      "[17:47:51] \n",
      "[feuille] FNP achats: shape initiale=(1417, 23)\n",
      "[17:47:51] [feuille] FNP achats: après drop vides -> (1417, 23)\n",
      "[17:47:51] [feuille] FNP achats: header choisi à la ligne 0\n",
      "[17:47:51] [feuille] FNP achats: colonnes normalisées -> periode, fournisseur_interne_externe, fournisseurs, code_projets, libelle_commande, type, n_cmd_aec, cdp, n_cmd_frs_date_cmd, montant_commande_ht, factures_recues, fact_recues, factures_non_recues, avancement_sur_factu_non_recues, montant_fnp, commentaires, compte_tiers, compte_charges, soumis_non_soumis, tva, reste, client_interne, section_analytique\n",
      "[17:47:51] [feuille] FNP achats: shape après nettoyage colonnes -> (1416, 23)\n",
      "[17:47:51] [excel_serial_to_datetime] valeurs hors fenêtre [60, 106750] remplacées par NaN: 149\n",
      "\n",
      "--- Feuille: FNP achats -> fnp_aec_projets_source.fnp_achats ---\n",
      "rows=1416 | cols=23\n",
      "Colonnes: periode, fournisseur_interne_externe, fournisseurs, code_projets, libelle_commande, type, n_cmd_aec, cdp, n_cmd_frs_date_cmd, montant_commande_ht, factures_recues, fact_recues, factures_non_recues, avancement_sur_factu_non_recues, montant_fnp, commentaires, compte_tiers, compte_charges, soumis_non_soumis, tva, reste, client_interne, section_analytique\n",
      "\n",
      "Schema détecté:\n",
      "  - periode: DATE  ->  date\n",
      "  - fournisseur_interne_externe: STRING  ->  text\n",
      "  - fournisseurs: STRING  ->  text\n",
      "  - code_projets: STRING  ->  text\n",
      "  - libelle_commande: STRING  ->  text\n",
      "  - type: STRING  ->  text\n",
      "  - n_cmd_aec: DATE  ->  date\n",
      "  - cdp: STRING  ->  text\n",
      "  - n_cmd_frs_date_cmd: DATE  ->  date\n",
      "  - montant_commande_ht: DATETIME  ->  timestamp without time zone\n",
      "  - factures_recues: STRING  ->  text\n",
      "  - fact_recues: STRING  ->  text\n",
      "  - factures_non_recues: STRING  ->  text\n",
      "  - avancement_sur_factu_non_recues: FLOAT  ->  double precision\n",
      "  - montant_fnp: STRING  ->  text\n",
      "  - commentaires: STRING  ->  text\n",
      "  - compte_tiers: STRING  ->  text\n",
      "  - compte_charges: STRING  ->  text\n",
      "  - soumis_non_soumis: STRING  ->  text\n",
      "  - tva: STRING  ->  text\n",
      "  - reste: STRING  ->  text\n",
      "  - client_interne: DATE  ->  date\n",
      "  - section_analytique: STRING  ->  text\n",
      "\n",
      "Sample (top 10):\n",
      "       periode fournisseur_interne_externe                            fournisseurs code_projets              libelle_commande             type   n_cmd_aec      cdp n_cmd_frs_date_cmd  montant_commande_ht  \\\n",
      "1   2024-01-30                     Externe                           L3 WESCAM USA      C191893                   camera MX15       S/T France  1900-08-01      BAZ                NaN                  NaN   \n",
      "2   2024-01-30                     Externe                AEROPORT CASTRES MAZAMET      C192026      REDEVANCES AERONAUTIQUES       S/T France  1905-05-10      PRO         2023-08-30  1900-07-10 02:52:48   \n",
      "3   2024-01-30                     Externe                      MOUSER ELECTRONICS      C192195       Connecteurs d’éclairage  Matériel France  1903-12-03      JFA         2022-09-06                  NaN   \n",
      "4   2024-01-30                     Externe  PROFESSIONAL & BROADCAST SERVICE - PBS      C192195                       KIL1/E1  Matériel France  1904-04-16      TBI         2022-11-17                  NaN   \n",
      "5   2024-01-30                     Externe                                   CIPEM      C192195  CLAVIER IK-TR-911-RED USB-US       S/T France  1905-07-20      JFA         2023-10-30  1901-08-15 00:00:00   \n",
      "6   2024-01-30                     Externe                                   NEHIA      C202695       PREDECOUPES HD MASK 115       S/T France  1904-11-30      MSU         2023-04-27  1900-08-19 00:00:00   \n",
      "7   2024-01-30                     Externe                                 TENCATE      C202695     FABRICATION PANNEAU PORTE       S/T France  1904-12-06      MSU         2023-05-04  1907-04-13 00:00:00   \n",
      "8   2024-01-30                     Externe                                LOGO SKY      C202695              MATERIAL 3M 6900  Matériel France  1905-11-01  SRE/MSU         2023-12-20                  NaN   \n",
      "9   2024-01-30                     Externe                                   ZELIN      C212808                multiples lots       S/T France  1902-12-16      TBI         2022-02-21  1933-12-27 00:00:00   \n",
      "10  2024-01-30                     Externe                           BDEX AVIATION      C212809                         DOCHD   Matériel Monde  1903-05-13      TBI         2022-05-17  1901-02-28 00:00:00   \n",
      "\n",
      "       factures_recues         fact_recues factures_non_recues  avancement_sur_factu_non_recues        montant_fnp                       commentaires compte_tiers compte_charges soumis_non_soumis                 tva  \\\n",
      "1   2035920.4000000001  0.9654671614945716   72820.82000000007                              1.0  72820.82000000007                               <NA>   4081010000     6040000000            Soumis  14564.164000000013   \n",
      "2                 <NA>                <NA>              192.12                              1.0             192.12                               <NA>   4081010000     6040000000            Soumis   38.42400000000001   \n",
      "3                29.86                   1                <NA>                              1.0               <NA>  s48.23 : mail pour maj statut JFA   4081010000     6010000000            Soumis                <NA>   \n",
      "4                 <NA>                   1                <NA>                              1.0               <NA>  s48.23 : mail pour maj statut JFA   4081010000     6010000000            Soumis                <NA>   \n",
      "5                 <NA>                <NA>                 593                              1.0                593                               <NA>   4081010000     6040000000            Soumis  118.60000000000001   \n",
      "6                 <NA>                <NA>                 232                              1.0                232                               <NA>   4081010000     6040000000            Soumis  46.400000000000006   \n",
      "7                 <NA>                <NA>                2660                              1.0               2660                               <NA>   4081010000     6040000000            Soumis                 532   \n",
      "8                 <NA>                <NA>                  44                              1.0                 44                               <NA>   4081010000     6010000000            Soumis                 8.8   \n",
      "9                 9915  0.7986306886830447                2500                              1.0               2500                     mail TBI 31/05   4081010000     6040000000            Soumis                 500   \n",
      "10                <NA>                <NA>                 425                              1.0                425                               <NA>   4081010000     6010000000        Non soumis                <NA>   \n",
      "\n",
      "   reste client_interne       section_analytique  \n",
      "1   <NA>     1902-09-25  AEC-999-DCS-C191893-21J  \n",
      "2   <NA>     1902-09-25  AEC-999-DCS-C192026-21J  \n",
      "3   <NA>     1902-09-25  AEC-999-DCS-C192195-21J  \n",
      "4   <NA>     1902-09-25  AEC-999-DCS-C192195-21J  \n",
      "5   <NA>     1902-09-25  AEC-999-DCS-C192195-21J  \n",
      "6   <NA>     1902-09-25  AEC-999-DCS-C202695-21J  \n",
      "7   <NA>     1902-09-25  AEC-999-DCS-C202695-21J  \n",
      "8   <NA>     1902-09-25  AEC-999-DCS-C202695-21J  \n",
      "9   <NA>     1902-09-25  AEC-999-DCS-C212808-21J  \n",
      "10  <NA>     1902-09-25  AEC-999-DCS-C212809-21J  \n",
      "[17:47:51] \n",
      "[feuille] Feuil3: shape initiale=(128, 24)\n",
      "[17:47:51] [feuille] Feuil3: après drop vides -> (128, 24)\n",
      "[17:47:51] [feuille] Feuil3: header choisi à la ligne 0\n",
      "[17:47:51] [feuille] Feuil3: colonnes normalisées -> code_projet, fournisseur, ffcleunik, nofact, cofou, typebc, naf, lbcleunik, prix, prixmon, comon, qtefa, cofa, desa1, cobc, daterec, tva, compt, analytiq, datesaisie, unite, coefunite, codeemp, i1cleunik\n",
      "[17:47:51] [feuille] Feuil3: shape après nettoyage colonnes -> (127, 23)\n",
      "[17:47:51] [excel_serial_to_datetime] valeurs hors fenêtre [60, 106750] remplacées par NaN: 35\n",
      "[17:47:51] [excel_serial_to_datetime] valeurs hors fenêtre [60, 106750] remplacées par NaN: 35\n",
      "\n",
      "--- Feuille: Feuil3 -> fnp_aec_projets_source.feuil3 ---\n",
      "rows=127 | cols=23\n",
      "Colonnes: code_projet, fournisseur, ffcleunik, nofact, cofou, typebc, naf, lbcleunik, prix, prixmon, comon, qtefa, cofa, desa1, cobc, daterec, tva, compt, datesaisie, unite, coefunite, codeemp, i1cleunik\n",
      "\n",
      "Schema détecté:\n",
      "  - code_projet: STRING  ->  text\n",
      "  - fournisseur: STRING  ->  text\n",
      "  - ffcleunik: DATE  ->  date\n",
      "  - nofact: STRING  ->  text\n",
      "  - cofou: STRING  ->  text\n",
      "  - typebc: INT  ->  integer\n",
      "  - naf: INT  ->  integer\n",
      "  - lbcleunik: STRING  ->  text\n",
      "  - prix: DATETIME  ->  timestamp without time zone\n",
      "  - prixmon: DATETIME  ->  timestamp without time zone\n",
      "  - comon: INT  ->  integer\n",
      "  - qtefa: INT  ->  integer\n",
      "  - cofa: STRING  ->  text\n",
      "  - desa1: STRING  ->  text\n",
      "  - cobc: STRING  ->  text\n",
      "  - daterec: DATE  ->  date\n",
      "  - tva: INT  ->  integer\n",
      "  - compt: INT  ->  integer\n",
      "  - datesaisie: DATE  ->  date\n",
      "  - unite: STRING  ->  text\n",
      "  - coefunite: BOOL  ->  boolean\n",
      "  - codeemp: STRING  ->  text\n",
      "  - i1cleunik: STRING  ->  text\n",
      "\n",
      "Sample (top 10):\n",
      "   code_projet      fournisseur   ffcleunik     nofact  cofou  typebc    naf lbcleunik                 prix              prixmon  comon  qtefa     cofa                      desa1  cobc     daterec  tva       compt  \\\n",
      "1      C213178  AEROTEC BLAGNAC  1905-10-08    2262023  00017       3   1945      1518                  NaN                  NaN      9      1  EQUIPMT                C213178-089  1580  2023-01-02    2  6011000000   \n",
      "2      C202695  SURUGUE MICKAEL  1905-10-09  NDF23-006    MSU       3   1216      <NA>  1900-04-13 20:24:00  1900-04-13 20:24:00      9      1  MISSION  A/R GRAULHET 15/12/22 PC6  <NA>  2023-01-04    2  6256000000   \n",
      "3      C202695  SURUGUE MICKAEL  1905-10-10  NDF23-007    MSU       3   1216      <NA>  1900-04-13 20:24:00  1900-04-13 20:24:00      9      1  MISSION  A/R GRAULHET 05/01/23 PC6  <NA>  2023-01-06    2  6256000000   \n",
      "4      C212810           AVALEX  1905-10-11      46504  00194       3    697        44  1920-04-17 23:16:48  1921-10-06 00:00:00      6      1  EQUIPMT    \"17.3\"\" HD WIDESCREEN,\"   229  2022-12-22    2  6011000000   \n",
      "5      C213178  AEROTEC BLAGNAC  1905-10-12     226759  00017       3   1150       322                  NaN                  NaN      9     -1  SSTRAIT  38-2 FLIGHT TEST CAMPAIGN  1067  2023-01-03    2  6040000000   \n",
      "6      C213178  AEROTEC BLAGNAC  1905-10-13     226760  00017       3   1150      1496  1944-06-15 00:00:00  1944-06-15 00:00:00      9      1  SSTRAIT  38-2 FLIGHT TEST CAMPAIGN  1067  2023-01-03    2  6040000000   \n",
      "7      C223301  AEROTEC BLAGNAC  1905-10-14     226765  00017       3  20042      1672  1902-05-29 00:00:00  1902-05-29 00:00:00      9      1  EQUIPMT      PEINTURE OIL DEFECTOR  1634  2023-01-04    2  6011000000   \n",
      "8      C223521            NEHIA  1905-10-15   22002895  00315       3   1791      1374  1944-06-26 00:00:00  1944-06-26 00:00:00      9      1  EQUIPMT         STENCILS HDMASK115  1534  2022-12-20    2  6011000000   \n",
      "9      C223521            NEHIA  1905-10-16   22002895  00315       3   1791      1375  1944-06-26 00:00:00  1944-06-26 00:00:00      9      1  EQUIPMT         STENCILS HDMASK115  1534  2022-12-20    2  6011000000   \n",
      "10     C223521            NEHIA  1905-10-17   22002895  00315       3   1791      1379  1901-08-02 00:00:00  1901-08-02 00:00:00      9      1  EQUIPMT         STENCILS HDMASK115  1534  2022-12-20    2  6011000000   \n",
      "\n",
      "    datesaisie unite  coefunite codeemp i1cleunik  \n",
      "1   2023-01-02     u       True     IVI      <NA>  \n",
      "2   2023-01-12     u       True     AOD      <NA>  \n",
      "3   2023-01-12     u       True     AOD      <NA>  \n",
      "4   2023-01-12     u       True     AOD      <NA>  \n",
      "5   2023-01-12     u       True     AOD      <NA>  \n",
      "6   2023-01-12     u       True     AOD      <NA>  \n",
      "7   2023-01-12     u       True     AOD      <NA>  \n",
      "8   2023-01-12     u       True     AOD      <NA>  \n",
      "9   2023-01-12     u       True     AOD      <NA>  \n",
      "10  2023-01-12     u       True     AOD      <NA>  \n",
      "\n",
      "Done. Feuilles analysées: 2\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, unicodedata, warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# ============== CONFIG ==============\n",
    "FILE_PATH = r\"C:\\globasoft\\aerotech\\fic\\FNP AEC projets - source.xlsx\"\n",
    "SHOW_SAMPLE = True\n",
    "\n",
    "# ============== LOG ==============\n",
    "def now(): return datetime.now().strftime(\"%H:%M:%S\")\n",
    "def log(msg): print(f\"[{now()}] {msg}\", flush=True)\n",
    "\n",
    "# ============== UTILS ==============\n",
    "def strip_accents_lower(s):\n",
    "    if s is None or (isinstance(s, float) and pd.isna(s)): return \"\"\n",
    "    s = unicodedata.normalize(\"NFKD\", str(s))\n",
    "    s = \"\".join(c for c in s if not unicodedata.combining(c))\n",
    "    return s.lower().strip()\n",
    "\n",
    "def snake_id(s):\n",
    "    s = strip_accents_lower(s)\n",
    "    s = re.sub(r\"[\\s\\.\\-]+\", \"_\", s)\n",
    "    s = re.sub(r\"[^a-z0-9_]\", \"_\", s)\n",
    "    return re.sub(r\"_+\", \"_\", s).strip(\"_\") or \"col\"\n",
    "\n",
    "def parse_number_like(series: pd.Series) -> pd.Series:\n",
    "    x = series.astype(\"string\").str.replace(\"\\u00A0\",\" \", regex=False).str.replace(\" \",\"\", regex=False)\n",
    "    x = x.str.replace(r\"(?<=\\d)\\.(?=\\d{3}(?:\\D|$))\",\"\", regex=True)  # retire séparateurs de milliers\n",
    "    x = x.str.replace(\",\",\".\", regex=False)                          # virgule -> point\n",
    "    return pd.to_numeric(x, errors=\"coerce\")\n",
    "\n",
    "# ============== HEADER PICK + NORMALIZE ==============\n",
    "HEADER_HINTS = (\n",
    "    \"projet\",\"projets\",\"code\",\"id\",\"date\",\"mois\",\"année\",\"client\",\"fournisseur\",\"libelle\",\"libellé\",\n",
    "    \"montant\",\"quantite\",\"qté\",\"qte\",\"prix\",\"ttc\",\"ht\",\"statut\",\"status\",\"site\",\"type\",\"categorie\",\n",
    "    \"echeance\",\"échéance\",\"délai\",\"delai\",\"commentaire\",\"ref\",\"réf\"\n",
    ")\n",
    "\n",
    "def choose_header_row(df: pd.DataFrame, scan=25) -> int:\n",
    "    \"\"\"1) ligne contenant plusieurs mots-clés; 2) densité + présence de texte.\"\"\"\n",
    "    limit = min(len(df), scan)\n",
    "    cand_idx, cand_hits = None, -1\n",
    "    for i in range(limit):\n",
    "        row = df.iloc[i].astype(str)\n",
    "        hits = 0\n",
    "        for v in row:\n",
    "            t = strip_accents_lower(v)\n",
    "            if t and any(k in t for k in HEADER_HINTS):\n",
    "                hits += 1\n",
    "        if hits >= 2 and hits > cand_hits:\n",
    "            cand_idx, cand_hits = i, hits\n",
    "    if cand_idx is not None:\n",
    "        return cand_idx\n",
    "\n",
    "    best, idx = -1, 0\n",
    "    for i in range(limit):\n",
    "        row = df.iloc[i].astype(str)\n",
    "        non_empty = row.map(lambda x: x.strip()!=\"\").sum()\n",
    "        texty = row.map(lambda x: bool(re.search(r\"[A-Za-zÀ-ÿ]\", x))).sum()\n",
    "        score = non_empty*2 + texty\n",
    "        if score > best: best, idx = score, i\n",
    "    return idx\n",
    "\n",
    "def normalize_columns(header_vals):\n",
    "    cols, seen = [], {}\n",
    "    for v in header_vals:\n",
    "        s = snake_id(v) if (v is not None and str(v).strip()!=\"\") else \"col\"\n",
    "        seen[s] = seen.get(s,0)+1\n",
    "        cols.append(s if seen[s]==1 else f\"{s}_{seen[s]}\")\n",
    "    return cols\n",
    "\n",
    "def drop_empty_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.dropna(axis=1, how=\"all\")\n",
    "    blank_cols = [c for c in df.columns if df[c].dropna().astype(str).str.strip().eq(\"\").all()]\n",
    "    if blank_cols:\n",
    "        df = df.drop(columns=blank_cols)\n",
    "    return df\n",
    "\n",
    "# ============== INFÉRENCE TYPES (simple et robuste) ==============\n",
    "MAP_TRUE  = {\"true\",\"vrai\",\"oui\",\"yes\",\"1\",\"y\",\"o\"}\n",
    "MAP_FALSE = {\"false\",\"faux\",\"non\",\"no\",\"0\",\"n\"}\n",
    "\n",
    "DATE_TOKEN_RE = re.compile(\n",
    "    r\"(?:\\d{4}[-/\\.]\\d{1,2}[-/\\.]\\d{1,2})|(?:\\d{1,2}[-/\\.]\\d{1,2}[-/\\.]\\d{2,4})|\"\n",
    "    r\"(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec|janv|févr|fevr|avr|mai|juin|juil|sept|oct|nov|d[ée]c)\",\n",
    "    re.I\n",
    ")\n",
    "ISO_DATE_RE = re.compile(r\"^\\d{4}-\\d{2}-\\d{2}(?:[ T]\\d{2}:\\d{2}:\\d{2})?$\")\n",
    "COLNAME_DATE_HINTS = (\"date\",\"dt\",\"heure\",\"time\",\"echeance\",\"échéance\")\n",
    "\n",
    "def excel_serial_to_datetime(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Conversion sûre des numéros de date Excel -> datetime.\n",
    "    Fenêtre 'safe' contrainte à [60 .. 106750] jours:\n",
    "    - 60  ~ 1900-03-01\n",
    "    - 106750 ~ limite Timedelta pandas (~2173)\n",
    "    Tout ce qui est hors-fenêtre -> NaN AVANT conversion.\n",
    "    \"\"\"\n",
    "    vals = pd.to_numeric(series, errors=\"coerce\").astype(\"float64\")\n",
    "    vals[~np.isfinite(vals)] = np.nan\n",
    "\n",
    "    lower, upper = 60.0, 106750.0\n",
    "    mask = (vals >= lower) & (vals <= upper)\n",
    "    n_out = int((~mask & ~pd.isna(vals)).sum())\n",
    "    if n_out:\n",
    "        log(f\"[excel_serial_to_datetime] valeurs hors fenêtre [{int(lower)}, {int(upper)}] remplacées par NaN: {n_out}\")\n",
    "    vals = vals.where(mask, np.nan)\n",
    "\n",
    "    base = pd.Timestamp(\"1899-12-30\")\n",
    "    # conversion sûre (les NaN restent NaT)\n",
    "    td = pd.to_timedelta(vals, unit=\"D\", errors=\"coerce\")\n",
    "    dt = base + td\n",
    "    return pd.to_datetime(dt, errors=\"coerce\")\n",
    "\n",
    "def infer_col(col: pd.Series):\n",
    "    s = col.copy()\n",
    "    ss = s.astype(\"string\").str.strip()\n",
    "    ss = ss.where(~ss.fillna(\"\").eq(\"0\"), pd.NA)  # éviter 0 -> 1970-01-01\n",
    "\n",
    "    # 0) ISO direct\n",
    "    iso_mask = ss.fillna(\"\").str.match(ISO_DATE_RE)\n",
    "    if iso_mask.mean() >= 0.5:\n",
    "        dt_iso = pd.to_datetime(ss.where(iso_mask), errors=\"coerce\", dayfirst=False)\n",
    "        ok = dt_iso.notna().mean() if len(ss) else 0.0\n",
    "        if ok >= 0.5:\n",
    "            has_time = (dt_iso.dt.time.astype(str) != \"00:00:00\").mean() > 0.2\n",
    "            return (\n",
    "                dt_iso.dt.strftime(\"%Y-%m-%d %H:%M:%S\") if has_time else dt_iso.dt.strftime(\"%Y-%m-%d\"),\n",
    "                \"DATETIME\" if has_time else \"DATE\"\n",
    "            )\n",
    "\n",
    "    # 1) Excel serial plausibles (et majoritairement dans la fenêtre sûre)\n",
    "    as_num = pd.to_numeric(ss, errors=\"coerce\")\n",
    "    if len(ss):\n",
    "        safe_mask = (as_num >= 60) & (as_num <= 106750)\n",
    "        safe_ratio = safe_mask.mean()\n",
    "    else:\n",
    "        safe_ratio = 0.0\n",
    "\n",
    "    if (as_num.notna().mean() if len(ss) else 0.0) >= 0.9 and safe_ratio >= 0.7:\n",
    "        parsed = excel_serial_to_datetime(as_num)\n",
    "        ok = parsed.notna().mean() if len(ss) else 0.0\n",
    "        if ok >= 0.7:\n",
    "            has_time = (parsed.dt.time.astype(str) != \"00:00:00\").mean() > 0.2\n",
    "            return (\n",
    "                parsed.dt.strftime(\"%Y-%m-%d %H:%M:%S\") if has_time else parsed.dt.strftime(\"%Y-%m-%d\"),\n",
    "                \"DATETIME\" if has_time else \"DATE\"\n",
    "            )\n",
    "\n",
    "    # 2) tokens de date / nom “datey”\n",
    "    colname_hint = any(h in strip_accents_lower(s.name or \"\") for h in COLNAME_DATE_HINTS)\n",
    "    date_token_ratio = ss.fillna(\"\").str.contains(DATE_TOKEN_RE, na=False).mean()\n",
    "    looks_datey = colname_hint or (date_token_ratio >= 0.30)\n",
    "    if looks_datey:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", message=\"Could not infer format.*\", category=UserWarning)\n",
    "            dt1 = pd.to_datetime(ss, errors=\"coerce\", dayfirst=True,  cache=True)\n",
    "            dt2 = pd.to_datetime(ss, errors=\"coerce\", dayfirst=False, cache=True)\n",
    "        dt = dt2 if dt2.notna().sum() > dt1.notna().sum() else dt1\n",
    "        ok = dt.notna().mean() if len(ss) else 0.0\n",
    "        ok_thresh = 0.50 if colname_hint else 0.70\n",
    "        if ok >= ok_thresh:\n",
    "            has_time = (dt.dt.time.astype(str) != \"00:00:00\").mean() > 0.2\n",
    "            return (\n",
    "                pd.to_datetime(dt).dt.strftime(\"%Y-%m-%d %H:%M:%S\") if has_time else pd.to_datetime(dt).dt.strftime(\"%Y-%m-%d\"),\n",
    "                \"DATETIME\" if has_time else \"DATE\"\n",
    "            )\n",
    "\n",
    "    # 3) bool strict\n",
    "    mb = ss.str.lower().map(lambda x: True if x in MAP_TRUE else (False if x in MAP_FALSE else pd.NA))\n",
    "    if (mb.notna().mean() if len(ss) else 0) >= 0.98:\n",
    "        return mb.astype(\"boolean\"), \"BOOL\"\n",
    "\n",
    "    # 4) nombre\n",
    "    nums = parse_number_like(ss)\n",
    "    if (nums.notna().mean() if len(ss.dropna()) else 0) >= 0.85:\n",
    "        nz = nums.dropna()\n",
    "        if len(nz) and (np.mod(nz, 1) == 0).all():\n",
    "            return nums.astype(\"Int64\"), \"INT\"\n",
    "        return nums.astype(\"Float64\"), \"FLOAT\"\n",
    "\n",
    "    # 5) texte\n",
    "    return ss.astype(\"string\"), \"STRING\"\n",
    "\n",
    "def pg_type(tag: str) -> str:\n",
    "    return {\n",
    "        \"DATE\":\"date\",\"DATETIME\":\"timestamp without time zone\",\n",
    "        \"INT\":\"integer\",\"FLOAT\":\"double precision\",\"BOOL\":\"boolean\"\n",
    "    }.get(tag, \"text\")\n",
    "\n",
    "# ============== MAIN ==============\n",
    "def main():\n",
    "    xlsx = Path(FILE_PATH)\n",
    "    log(f\"Fichier: {xlsx}\")\n",
    "    if not xlsx.exists():\n",
    "        log(\"[error] Fichier introuvable\"); return\n",
    "\n",
    "    try:\n",
    "        sheets = pd.read_excel(xlsx, sheet_name=None, engine=\"openpyxl\", header=None)\n",
    "    except Exception as e:\n",
    "        log(f\"[error] Lecture échouée: {e}\"); return\n",
    "\n",
    "    done = 0\n",
    "    for name, raw in sheets.items():\n",
    "        log(f\"\\n[feuille] {name}: shape initiale={raw.shape}\")\n",
    "\n",
    "        # nettoyage vide\n",
    "        raw = raw.dropna(how=\"all\", axis=0).dropna(how=\"all\", axis=1)\n",
    "        log(f\"[feuille] {name}: après drop vides -> {raw.shape}\")\n",
    "        if raw.empty: \n",
    "            log(f\"[feuille] {name}: vide, on passe.\")\n",
    "            continue\n",
    "\n",
    "        # header + normalisation\n",
    "        h = choose_header_row(raw, scan=25)\n",
    "        log(f\"[feuille] {name}: header choisi à la ligne {h}\")\n",
    "        cols = normalize_columns(raw.iloc[h].tolist())\n",
    "        log(f\"[feuille] {name}: colonnes normalisées -> {', '.join(cols)}\")\n",
    "        df = raw.iloc[h+1:].copy()\n",
    "        df.columns = cols\n",
    "        df = df.dropna(how=\"all\")\n",
    "        df = drop_empty_columns(df)\n",
    "        log(f\"[feuille] {name}: shape après nettoyage colonnes -> {df.shape}\")\n",
    "        if df.empty:\n",
    "            log(f\"[feuille] {name}: vide après normalisation, on passe.\")\n",
    "            continue\n",
    "\n",
    "        # inférence types\n",
    "        schema = {}\n",
    "        for c in df.columns:\n",
    "            casted, tag = infer_col(df[c])\n",
    "            df[c] = casted\n",
    "            schema[c] = tag\n",
    "\n",
    "        base = f\"{snake_id(xlsx.stem)}.{snake_id(name)}\"\n",
    "        print(f\"\\n--- Feuille: {name} -> {base} ---\")\n",
    "        print(f\"rows={len(df)} | cols={df.shape[1]}\")\n",
    "        print(\"Colonnes:\", \", \".join(df.columns.astype(str)))\n",
    "        print(\"\\nSchema détecté:\")\n",
    "        for c in df.columns:\n",
    "            print(f\"  - {c}: {schema[c]}  ->  {pg_type(schema[c])}\")\n",
    "\n",
    "        if SHOW_SAMPLE:\n",
    "            with pd.option_context(\"display.max_columns\", 120, \"display.width\", 220):\n",
    "                print(\"\\nSample (top 10):\")\n",
    "                print(df.head(10))\n",
    "\n",
    "        done += 1\n",
    "\n",
    "    print(f\"\\nDone. Feuilles analysées: {done}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b778bf4-a237-4cae-be16-be2ab9c4947d",
   "metadata": {},
   "source": [
    "# Projets AEC AE 2025 - source.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3747a9f-d754-44af-ab95-2abb51be1267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:03:36] Fichier: C:\\globasoft\\aerotech\\fic\\Projets AEC AE 2025 - source.xlsx\n",
      "[10:03:43] \n",
      "[feuille] Sheet1: shape initiale=(34790, 13)\n",
      "[10:03:43] [feuille] Sheet1: après drop vides -> (34790, 13)\n",
      "[10:03:43] [feuille] Sheet1: header choisi à la ligne 0\n",
      "[10:03:43] [feuille] Sheet1: shape après affectation des en-têtes -> (34789, 13)\n",
      "\n",
      "--- Feuille: Sheet1 -> projets_aec_ae_2025_source.sheet1 (SCHÉMA SOURCE STRICT / PostgreSQL) ---\n",
      "rows=34789 | cols=13\n",
      "\n",
      "Mapping colonnes (Excel → nom_pg) :\n",
      "  - SOP  ->  sop\n",
      "  - AnnéeMois  ->  anneemois\n",
      "  - Nature  ->  nature\n",
      "  - Section analytique  ->  section_analytique\n",
      "  - Période  ->  periode\n",
      "  - Plan 1 Niveau 1  ->  plan_1_niveau_1\n",
      "  - Plan 2 Niveau 1  ->  plan_2_niveau_1\n",
      "  - Plan 3 Niveau 1  ->  plan_3_niveau_1\n",
      "  - Plan4  ->  plan4\n",
      "  - Plan5  ->  plan5\n",
      "  - Montant débit  ->  montant_debit\n",
      "  - Montant crédit  ->  montant_credit\n",
      "  - Solde montant  ->  solde_montant\n",
      "\n",
      "Schema détecté (types PostgreSQL) :\n",
      "  - sop: text  (source: SOP, type détecté: STRING)\n",
      "  - anneemois: integer  (source: AnnéeMois, type détecté: INT)\n",
      "  - nature: text  (source: Nature, type détecté: STRING)\n",
      "  - section_analytique: text  (source: Section analytique, type détecté: STRING)\n",
      "  - periode: date  (source: Période, type détecté: DATE)\n",
      "  - plan_1_niveau_1: text  (source: Plan 1 Niveau 1, type détecté: STRING)\n",
      "  - plan_2_niveau_1: text  (source: Plan 2 Niveau 1, type détecté: STRING)\n",
      "  - plan_3_niveau_1: text  (source: Plan 3 Niveau 1, type détecté: STRING)\n",
      "  - plan4: text  (source: Plan4, type détecté: STRING)\n",
      "  - plan5: text  (source: Plan5, type détecté: STRING)\n",
      "  - montant_debit: double precision  (source: Montant débit, type détecté: FLOAT)\n",
      "  - montant_credit: double precision  (source: Montant crédit, type détecté: FLOAT)\n",
      "  - solde_montant: double precision  (source: Solde montant, type détecté: FLOAT)\n",
      "\n",
      "Sample (top 10) :\n",
      "                      SOP  AnnéeMois      Nature       Section analytique     Période Plan 1 Niveau 1 Plan 2 Niveau 1 Plan 3 Niveau 1    Plan4 Plan5  Montant débit  Montant crédit  Solde montant\n",
      "1   3-ACHATS SUR AFFAIRES     202001  6011000000      AEB-000-DCS-CRD-145  2020-01-31             AEB               0             DCS      CRD   145            0.0             0.0            0.0\n",
      "2   3-ACHATS SUR AFFAIRES     202001  6011000000  AEB-999-DCS-B180074-145  2020-01-31             AEB             999             DCS  B180074   145        3589.95             0.0        3589.95\n",
      "3   3-ACHATS SUR AFFAIRES     202001  6011000000  AEB-999-DCS-B190094-145  2020-01-31             AEB             999             DCS  B190094   145          39.28             0.0          39.28\n",
      "4   3-ACHATS SUR AFFAIRES     202001  6011000000  AEB-999-DCS-B190232-145  2020-01-31             AEB             999             DCS  B190232   145       261011.0             0.0       261011.0\n",
      "5   3-ACHATS SUR AFFAIRES     202001  6011000000  AEB-999-DCS-B190296-145  2020-01-31             AEB             999             DCS  B190296   145          52.88             0.0          52.88\n",
      "6   3-ACHATS SUR AFFAIRES     202001  6011000000  AEB-999-DCS-B190322-145  2020-01-31             AEB             999             DCS  B190322   145        4227.56             0.0        4227.56\n",
      "7   3-ACHATS SUR AFFAIRES     202001  6011000000  AEB-999-DCS-B190325-145  2020-01-31             AEB             999             DCS  B190325   145         105.57             0.0         105.57\n",
      "8   3-ACHATS SUR AFFAIRES     202001  6011000000  AEB-999-DCS-B190326-145  2020-01-31             AEB             999             DCS  B190326   145          79.39             0.0          79.39\n",
      "9   3-ACHATS SUR AFFAIRES     202001  6011000000  AEB-999-DCS-B190330-145  2020-01-31             AEB             999             DCS  B190330   145        2210.47             0.0        2210.47\n",
      "10  3-ACHATS SUR AFFAIRES     202001  6011000000  AEB-999-DCS-B190349-145  2020-01-31             AEB             999             DCS  B190349   145          987.1             0.0          987.1\n",
      "\n",
      "Done. Feuilles analysées: 1\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, unicodedata, warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# ============== CONFIG ==============\n",
    "FILE_PATH = r\"C:\\globasoft\\aerotech\\fic\\Projets AEC AE 2025 - source.xlsx\"\n",
    "SHOW_SAMPLE = True\n",
    "STRICT_SOURCE_SCHEMA = True  # Afficher uniquement le schéma strict du fichier\n",
    "\n",
    "# ============== LOG ==============\n",
    "def now(): return datetime.now().strftime(\"%H:%M:%S\")\n",
    "def log(msg): print(f\"[{now()}] {msg}\", flush=True)\n",
    "\n",
    "# ============== UTILS ==============\n",
    "def strip_accents_lower(s):\n",
    "    if s is None or (isinstance(s, float) and pd.isna(s)): return \"\"\n",
    "    s = unicodedata.normalize(\"NFKD\", str(s))\n",
    "    s = \"\".join(c for c in s if not unicodedata.combining(c))\n",
    "    return s.lower().strip()\n",
    "\n",
    "def snake_id(s):\n",
    "    s = strip_accents_lower(s)\n",
    "    s = re.sub(r\"[\\s\\.\\-]+\", \"_\", s)\n",
    "    s = re.sub(r\"[^a-z0-9_]\", \"_\", s)\n",
    "    return re.sub(r\"_+\", \"_\", s).strip(\"_\") or \"col\"\n",
    "\n",
    "def make_unique_columns(cols):\n",
    "    \"\"\"Rend les noms uniques en suffixant _2, _3... en cas de doublons.\"\"\"\n",
    "    out, seen = [], {}\n",
    "    for c in cols:\n",
    "        if c not in seen:\n",
    "            seen[c] = 1\n",
    "            out.append(c)\n",
    "        else:\n",
    "            seen[c] += 1\n",
    "            out.append(f\"{c}_{seen[c]}\")\n",
    "    return out\n",
    "\n",
    "def parse_number_like(series: pd.Series) -> pd.Series:\n",
    "    x = series.astype(\"string\").str.replace(\"\\u00A0\",\" \", regex=False).str.replace(\" \",\"\", regex=False)\n",
    "    # retire séparateurs de milliers type \".\" entre chiffres\n",
    "    x = x.str.replace(r\"(?<=\\d)\\.(?=\\d{3}(?:\\D|$))\",\"\", regex=True)\n",
    "    # virgule décimale -> point\n",
    "    x = x.str.replace(\",\",\".\", regex=False)\n",
    "    return pd.to_numeric(x, errors=\"coerce\")\n",
    "\n",
    "def drop_empty_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.dropna(axis=1, how=\"all\")\n",
    "    blank_idx = []\n",
    "    for j in range(df.shape[1]):\n",
    "        s = df.iloc[:, j]\n",
    "        if s.dropna().astype(str).str.strip().eq(\"\").all():\n",
    "            blank_idx.append(j)\n",
    "    if blank_idx:\n",
    "        log(f\"[drop_empty_columns] suppression colonnes blanches (pos): {blank_idx}\")\n",
    "        df = df.drop(df.columns[blank_idx], axis=1)\n",
    "    return df\n",
    "\n",
    "# ============== HEADER PICK ==============\n",
    "HEADER_HINTS = (\n",
    "    \"projet\",\"projets\",\"code\",\"id\",\"réf\",\"ref\",\"libelle\",\"libellé\",\"intitulé\",\n",
    "    \"client\",\"fournisseur\",\"chef de projet\",\"cp\",\"cdp\",\"manager\",\n",
    "    \"statut\",\"status\",\"phase\",\"categorie\",\"catégorie\",\"type\",\n",
    "    \"date debut\",\"date début\",\"debut\",\"début\",\"date fin\",\"fin\",\"echeance\",\"échéance\",\n",
    "    \"budget\",\"montant\",\"cout\",\"coût\",\"prix\",\"ht\",\"ttc\",\n",
    "    \"avancement\",\"progress\",\"%\",\"taux\",\n",
    "    \"site\",\"section analytique\",\"analytique\",\"commentaire\",\"période\",\"periode\",\n",
    "    \"plan\",\"niveau\",\"sop\",\"année\",\"mois\",\"anneemois\",\"nature\",\"compte\",\"crédit\",\"debit\",\"solde\"\n",
    ")\n",
    "\n",
    "def choose_header_row(df: pd.DataFrame, scan=25) -> int:\n",
    "    limit = min(len(df), scan)\n",
    "    cand_idx, cand_hits = None, -1\n",
    "    for i in range(limit):\n",
    "        row = df.iloc[i].astype(str)\n",
    "        hits = 0\n",
    "        for v in row:\n",
    "            t = strip_accents_lower(v)\n",
    "            if t and any(k in t for k in HEADER_HINTS):\n",
    "                hits += 1\n",
    "        if hits >= 2 and hits > cand_hits:\n",
    "            cand_idx, cand_hits = i, hits\n",
    "    if cand_idx is not None:\n",
    "        return cand_idx\n",
    "\n",
    "    best, idx = -1, 0\n",
    "    for i in range(limit):\n",
    "        row = df.iloc[i].astype(str)\n",
    "        non_empty = row.map(lambda x: x.strip()!=\"\").sum()\n",
    "        texty = row.map(lambda x: bool(re.search(r\"[A-Za-zÀ-ÿ]\", x))).sum()\n",
    "        score = non_empty*2 + texty\n",
    "        if score > best: best, idx = score, i\n",
    "    return idx\n",
    "\n",
    "# ============== INFÉRENCE TYPES (→ PostgreSQL) ==============\n",
    "MAP_TRUE  = {\"true\",\"vrai\",\"oui\",\"yes\",\"1\",\"y\",\"o\"}\n",
    "MAP_FALSE = {\"false\",\"faux\",\"non\",\"no\",\"0\",\"n\"}\n",
    "\n",
    "DATE_TOKEN_RE = re.compile(\n",
    "    r\"(?:\\d{4}[-/\\.]\\d{1,2}[-/\\.]\\d{1,2})|(?:\\d{1,2}[-/\\.]\\d{1,2}[-/\\.]\\d{2,4})|\"\n",
    "    r\"(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec|janv|févr|fevr|avr|mai|juin|juil|sept|oct|nov|d[ée]c)\",\n",
    "    re.I\n",
    ")\n",
    "ISO_DATE_RE = re.compile(r\"^\\d{4}-\\d{2}-\\d{2}(?:[ T]\\d{2}:\\d{2}:\\d{2})?$\")\n",
    "COLNAME_DATE_HINTS = (\"date\",\"dt\",\"heure\",\"time\",\"echeance\",\"échéance\",\"debut\",\"début\",\"fin\",\"période\",\"periode\")\n",
    "\n",
    "AMOUNT_NAME_HINTS = (\n",
    "    \"montant\",\"debit\",\"débit\",\"credit\",\"crédit\",\"solde\",\"budget\",\"ht\",\"ttc\",\n",
    "    \"amount\",\"total\",\"prix\",\"coût\",\"cout\"\n",
    ")\n",
    "CODE_LIKE_HINTS = (\"code\",\"nature\",\"plan\",\"compte\",\"sop\",\"section\",\"niveau\")\n",
    "\n",
    "def colname_has(hints, name):\n",
    "    n = strip_accents_lower(name or \"\")\n",
    "    return any(h in n for h in hints)\n",
    "\n",
    "def excel_serial_to_datetime(series: pd.Series) -> pd.Series:\n",
    "    vals = pd.to_numeric(series, errors=\"coerce\").astype(\"float64\")\n",
    "    vals[~np.isfinite(vals)] = np.nan\n",
    "    # fenêtre sûre Excel (≈ 1899-12-30 + jours)\n",
    "    lower, upper = 60.0, 60000.0  # upper ~ 2064\n",
    "    mask = (vals >= lower) & (vals <= upper)\n",
    "    n_out = int((~mask & ~pd.isna(vals)).sum())\n",
    "    if n_out:\n",
    "        log(f\"[excel_serial_to_datetime] valeurs hors fenêtre [{int(lower)}, {int(upper)}] -> NaN: {n_out}\")\n",
    "    vals = vals.where(mask, np.nan)\n",
    "    base = pd.Timestamp(\"1899-12-30\")\n",
    "    td = pd.to_timedelta(vals, unit=\"D\", errors=\"coerce\")\n",
    "    dt = base + td\n",
    "    return pd.to_datetime(dt, errors=\"coerce\")\n",
    "\n",
    "def infer_col(col: pd.Series):\n",
    "    \"\"\"\n",
    "    Retourne (serie_casted, tag) avec tag ∈ {\"DATE\",\"DATETIME\",\"INT\",\"FLOAT\",\"BOOL\",\"STRING\"}.\n",
    "    \"\"\"\n",
    "    s = col.copy()\n",
    "    ss = s.astype(\"string\").str.strip()\n",
    "\n",
    "    # 0) ISO direct\n",
    "    iso_mask = ss.fillna(\"\").str.match(ISO_DATE_RE)\n",
    "    if len(ss) and iso_mask.mean() >= 0.5:\n",
    "        dt_iso = pd.to_datetime(ss.where(iso_mask), errors=\"coerce\", dayfirst=False)\n",
    "        ok = dt_iso.notna().mean()\n",
    "        if ok >= 0.5:\n",
    "            has_time = (dt_iso.dt.time.astype(str) != \"00:00:00\").mean() > 0.2\n",
    "            return (\n",
    "                dt_iso.dt.strftime(\"%Y-%m-%d %H:%M:%S\") if has_time else dt_iso.dt.strftime(\"%Y-%m-%d\"),\n",
    "                \"DATETIME\" if has_time else \"DATE\"\n",
    "            )\n",
    "\n",
    "    # 1) Excel serial dates (restreint)\n",
    "    as_num = pd.to_numeric(ss, errors=\"coerce\")\n",
    "    if len(ss):\n",
    "        safe_mask = (as_num >= 60) & (as_num <= 60000)\n",
    "        safe_ratio = safe_mask.mean()\n",
    "    else:\n",
    "        safe_ratio = 0.0\n",
    "\n",
    "    colname_hint = colname_has(COLNAME_DATE_HINTS, s.name)\n",
    "    high_vals_ratio = (as_num >= 20000).mean() if len(ss) else 0.0  # 20000 ~ 1954\n",
    "\n",
    "    if (as_num.notna().mean() if len(ss) else 0.0) >= 0.9 and safe_ratio >= 0.7 and (colname_hint or high_vals_ratio >= 0.2):\n",
    "        parsed = excel_serial_to_datetime(as_num)\n",
    "        ok = parsed.notna().mean() if len(ss) else 0.0\n",
    "        if ok >= 0.7:\n",
    "            has_time = (parsed.dt.time.astype(str) != \"00:00:00\").mean() > 0.2\n",
    "            return (\n",
    "                parsed.dt.strftime(\"%Y-%m-%d %H:%M:%S\") if has_time else parsed.dt.strftime(\"%Y-%m-%d\"),\n",
    "                \"DATETIME\" if has_time else \"DATE\"\n",
    "            )\n",
    "\n",
    "    # 2) tokens de date / nom “datey”\n",
    "    date_token_ratio = ss.fillna(\"\").str.contains(DATE_TOKEN_RE, na=False).mean()\n",
    "    looks_datey = colname_hint or (date_token_ratio >= 0.30)\n",
    "    if looks_datey:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", message=\"Could not infer format.*\", category=UserWarning)\n",
    "            dt1 = pd.to_datetime(ss, errors=\"coerce\", dayfirst=True,  cache=True)\n",
    "            dt2 = pd.to_datetime(ss, errors=\"coerce\", dayfirst=False, cache=True)\n",
    "        dt = dt2 if dt2.notna().sum() > dt1.notna().sum() else dt1\n",
    "        ok = dt.notna().mean() if len(ss) else 0.0\n",
    "        ok_thresh = 0.50 if colname_hint else 0.70\n",
    "        if ok >= ok_thresh:\n",
    "            has_time = (dt.dt.time.astype(str) != \"00:00:00\").mean() > 0.2\n",
    "            return (\n",
    "                pd.to_datetime(dt).dt.strftime(\"%Y-%m-%d %H:%M:%S\") if has_time else pd.to_datetime(dt).dt.strftime(\"%Y-%m-%d\"),\n",
    "                \"DATETIME\" if has_time else \"DATE\"\n",
    "            )\n",
    "\n",
    "    # 3) bool strict\n",
    "    mb = ss.str.lower().map(lambda x: True if x in MAP_TRUE else (False if x in MAP_FALSE else pd.NA))\n",
    "    if len(ss) and mb.notna().mean() >= 0.98:\n",
    "        return mb.astype(\"boolean\"), \"BOOL\"\n",
    "\n",
    "    # 3bis) colonnes monétaires : forcer numéric si le nom l'indique\n",
    "    if colname_has(AMOUNT_NAME_HINTS, s.name):\n",
    "        nums_hint = parse_number_like(ss)\n",
    "        if nums_hint.notna().any():\n",
    "            nz = nums_hint.dropna()\n",
    "            if len(nz) and (np.mod(nz, 1) == 0).all():\n",
    "                return nums_hint.astype(\"Int64\"), \"INT\"\n",
    "            return nums_hint.astype(\"Float64\"), \"FLOAT\"\n",
    "\n",
    "    # 3ter) colonnes \"code-like\" : garder du texte\n",
    "    if colname_has(CODE_LIKE_HINTS, s.name):\n",
    "        return ss.astype(\"string\"), \"STRING\"\n",
    "\n",
    "    # 4) nombre générique\n",
    "    nums = parse_number_like(ss)\n",
    "    if (nums.notna().mean() if len(ss) else 0) >= 0.85:\n",
    "        nz = nums.dropna()\n",
    "        if len(nz) and (np.mod(nz, 1) == 0).all():\n",
    "            return nums.astype(\"Int64\"), \"INT\"\n",
    "        return nums.astype(\"Float64\"), \"FLOAT\"\n",
    "\n",
    "    # 5) texte\n",
    "    return ss.astype(\"string\"), \"STRING\"\n",
    "\n",
    "def pg_type(tag: str) -> str:\n",
    "    return {\n",
    "        \"DATE\":\"date\",\n",
    "        \"DATETIME\":\"timestamp without time zone\",\n",
    "        \"INT\":\"integer\",\n",
    "        \"FLOAT\":\"double precision\",\n",
    "        \"BOOL\":\"boolean\",\n",
    "        \"STRING\":\"text\"\n",
    "    }.get(tag, \"text\")\n",
    "\n",
    "# ============== MAIN ==============\n",
    "def main():\n",
    "    xlsx = Path(FILE_PATH)\n",
    "    log(f\"Fichier: {xlsx}\")\n",
    "    if not xlsx.exists():\n",
    "        log(\"[error] Fichier introuvable\"); return\n",
    "\n",
    "    try:\n",
    "        sheets = pd.read_excel(xlsx, sheet_name=None, engine=\"openpyxl\", header=None)\n",
    "    except Exception as e:\n",
    "        log(f\"[error] Lecture échouée: {e}\"); return\n",
    "\n",
    "    done = 0\n",
    "    for name, raw in sheets.items():\n",
    "        log(f\"\\n[feuille] {name}: shape initiale={raw.shape}\")\n",
    "\n",
    "        # nettoyage vide\n",
    "        raw = raw.dropna(how=\"all\", axis=0).dropna(how=\"all\", axis=1)\n",
    "        log(f\"[feuille] {name}: après drop vides -> {raw.shape}\")\n",
    "        if raw.empty:\n",
    "            log(f\"[feuille] {name}: vide, on passe.\")\n",
    "            continue\n",
    "\n",
    "        # repère l'entête dans le brut (sans remap)\n",
    "        h = choose_header_row(raw, scan=25)\n",
    "        log(f\"[feuille] {name}: header choisi à la ligne {h}\")\n",
    "\n",
    "        # ====== VUE SOURCE STRICTE (schéma du fichier) ======\n",
    "        df_src = raw.iloc[h+1:].copy()\n",
    "        src_cols_original = raw.iloc[h].tolist()  # libellés EXACTS du fichier\n",
    "        df_src.columns = src_cols_original\n",
    "        df_src = df_src.dropna(how=\"all\").copy()\n",
    "        df_src = drop_empty_columns(df_src)\n",
    "        log(f\"[feuille] {name}: shape après affectation des en-têtes -> {df_src.shape}\")\n",
    "        if df_src.empty:\n",
    "            log(f\"[feuille] {name}: vide après normalisation, on passe.\")\n",
    "            continue\n",
    "\n",
    "        # noms PostgreSQL (snake_case) correspondants aux libellés Excel\n",
    "        pg_cols = make_unique_columns([snake_id(c) for c in df_src.columns])\n",
    "\n",
    "        # inférence STRICTE sur colonnes d'origine (sans ajout ni remap)\n",
    "        schema_src = {}\n",
    "        casted_df = df_src.copy()\n",
    "        for c in list(df_src.columns):\n",
    "            casted, tag = infer_col(df_src[c])\n",
    "            casted_df[c] = casted\n",
    "            schema_src[c] = tag\n",
    "\n",
    "        # affichage STRICT : schéma = fichier, avec mapping vers noms pg + types pg\n",
    "        base = f\"{snake_id(xlsx.stem)}.{snake_id(name)}\"\n",
    "        print(f\"\\n--- Feuille: {name} -> {base} (SCHÉMA SOURCE STRICT / PostgreSQL) ---\")\n",
    "        print(f\"rows={len(casted_df)} | cols={casted_df.shape[1]}\")\n",
    "\n",
    "        print(\"\\nMapping colonnes (Excel → nom_pg) :\")\n",
    "        for src_name, pg_name in zip(df_src.columns, pg_cols):\n",
    "            print(f\"  - {src_name}  ->  {pg_name}\")\n",
    "\n",
    "        print(\"\\nSchema détecté (types PostgreSQL) :\")\n",
    "        for src_name, pg_name in zip(df_src.columns, pg_cols):\n",
    "            tag = schema_src.get(src_name, \"STRING\")\n",
    "            print(f\"  - {pg_name}: {pg_type(tag)}  (source: {src_name}, type détecté: {tag})\")\n",
    "\n",
    "        if SHOW_SAMPLE:\n",
    "            with pd.option_context(\"display.max_columns\", 140, \"display.width\", 240):\n",
    "                print(\"\\nSample (top 10) :\")\n",
    "                print(casted_df.head(10))\n",
    "\n",
    "        done += 1\n",
    "\n",
    "        # ====== (OPTIONNEL) VUE CIBLE : si tu veux une table prête IFS, remets à False STRICT_SOURCE_SCHEMA et ajoute ta logique ======\n",
    "        if not STRICT_SOURCE_SCHEMA:\n",
    "            pass  # tu peux réinsérer ici ta vue cible/mapping si besoin\n",
    "\n",
    "    print(f\"\\nDone. Feuilles analysées: {done}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb1a388-6d54-45d3-9317-41e9bc0826c9",
   "metadata": {},
   "source": [
    "# Relevé pointages AEB.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b77832e-161e-444c-9c0f-26345bd8376b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:43:19] Fichier: C:\\globasoft\\aerotech\\fic\\Relevé pointages AEB.xlsx\n",
      "[10:43:24] \n",
      "[feuille] Sheet1: shape initiale=(8980, 28)\n",
      "[10:43:24] [feuille] Sheet1: après drop vides -> (8980, 28)\n",
      "[10:43:24] [feuille] Sheet1: header choisi à la ligne 0\n",
      "[10:43:24] [feuille] Sheet1: shape après affectation des en-têtes -> (8979, 27)\n",
      "\n",
      "--- Feuille: Sheet1 -> releve_pointages_aeb.sheet1 (SCHÉMA SOURCE STRICT / PostgreSQL) ---\n",
      "rows=8979 | cols=27\n",
      "\n",
      "Mapping colonnes (Excel → nom_pg) :\n",
      "  - Trigramme  ->  trigramme\n",
      "  - NOM  ->  nom\n",
      "  - DATE  ->  date\n",
      "  - Cat Pointage  ->  cat_pointage\n",
      "  - N° DOSSIER  ->  n_dossier\n",
      "  - CATEGORIE  ->  categorie\n",
      "  - OT  ->  ot\n",
      "  - ATA  ->  ata\n",
      "  - Type de tâche  ->  type_de_tache\n",
      "  - Commentaires  ->  commentaires\n",
      "  - Hrs  ->  hrs\n",
      "  - Hrs supp  ->  hrs_supp\n",
      "  - Heures Totals  ->  heures_totals\n",
      "  - Société  ->  societe\n",
      "  - SERVICE  ->  service\n",
      "  - Code Projet  ->  code_projet\n",
      "  - TYPE APPAREIL  ->  type_appareil\n",
      "  - Client  ->  client\n",
      "  - BU  ->  bu\n",
      "  - IMMAT  ->  immat\n",
      "  - WP  ->  wp\n",
      "  - SEMAINE  ->  semaine\n",
      "  - MOIS  ->  mois\n",
      "  - ANNEE  ->  annee\n",
      "  - Cat point  ->  cat_point\n",
      "  - ANNEE - SEMAINE  ->  annee_semaine\n",
      "  - Mois.  ->  mois_2\n",
      "\n",
      "Schema détecté (types PostgreSQL) :\n",
      "  - trigramme: text  (source: Trigramme, type détecté: STRING)\n",
      "  - nom: text  (source: NOM, type détecté: STRING)\n",
      "  - date: date  (source: DATE, type détecté: DATE)\n",
      "  - cat_pointage: text  (source: Cat Pointage, type détecté: STRING)\n",
      "  - n_dossier: text  (source: N° DOSSIER, type détecté: STRING)\n",
      "  - categorie: text  (source: CATEGORIE, type détecté: STRING)\n",
      "  - ot: text  (source: OT, type détecté: STRING)\n",
      "  - ata: text  (source: ATA, type détecté: STRING)\n",
      "  - type_de_tache: text  (source: Type de tâche, type détecté: STRING)\n",
      "  - commentaires: text  (source: Commentaires, type détecté: STRING)\n",
      "  - hrs: double precision  (source: Hrs, type détecté: FLOAT)\n",
      "  - hrs_supp: double precision  (source: Hrs supp, type détecté: FLOAT)\n",
      "  - heures_totals: double precision  (source: Heures Totals, type détecté: FLOAT)\n",
      "  - societe: text  (source: Société, type détecté: STRING)\n",
      "  - service: text  (source: SERVICE, type détecté: STRING)\n",
      "  - code_projet: text  (source: Code Projet, type détecté: STRING)\n",
      "  - type_appareil: text  (source: TYPE APPAREIL, type détecté: STRING)\n",
      "  - client: text  (source: Client, type détecté: STRING)\n",
      "  - bu: text  (source: BU, type détecté: STRING)\n",
      "  - immat: text  (source: IMMAT, type détecté: STRING)\n",
      "  - wp: text  (source: WP, type détecté: STRING)\n",
      "  - semaine: integer  (source: SEMAINE, type détecté: INT)\n",
      "  - mois: integer  (source: MOIS, type détecté: INT)\n",
      "  - annee: date  (source: ANNEE, type détecté: DATE)\n",
      "  - cat_point: text  (source: Cat point, type détecté: STRING)\n",
      "  - annee_semaine: text  (source: ANNEE - SEMAINE, type détecté: STRING)\n",
      "  - mois_2: text  (source: Mois., type détecté: STRING)\n",
      "\n",
      "Sample (top 10) :\n",
      "   Trigramme                    NOM        DATE Cat Pointage      N° DOSSIER CATEGORIE      OT   ATA Type de tâche      Commentaires  Hrs  Hrs supp  Heures Totals Société            SERVICE Code Projet TYPE APPAREIL                 Client    BU    IMMAT  \\\n",
      "1        GLE          GALTIE Franck  2025-01-18      Dossier  B0200AEB240326      <NA>  OE-INT  <NA>          <NA>  GESTION CHANTIER  1.5      <NA>            1.5     AEB        MAINTENANCE     B240199        B200GT  GIE AIRNET\n",
      "(NICOLLIN)     0   F-HDLN   \n",
      "2        BAD       ADJEROUD Bastian  2025-01-01      Absence            <NA>      <NA>    <NA>  <NA>          <NA>             FERIE  8.0      <NA>            8.0     AEB               CAMO        <NA>          <NA>                   <NA>  <NA>  Absence   \n",
      "3        BLY          BAILLY Célian  2025-01-01      Absence            <NA>      <NA>    <NA>  <NA>          <NA>        Jour férié  8.0      <NA>            8.0     AEB        MAINTENANCE        <NA>          <NA>                   <NA>  <NA>  Absence   \n",
      "4        MBJ  BEN JOMAA Mohamed Ali  2025-01-01      Absence            <NA>      <NA>    <NA>  <NA>          <NA>             Férié  8.0      <NA>            8.0     AEB               CAMO        <NA>          <NA>                   <NA>  <NA>  Absence   \n",
      "5        CCE         CEZERAC Cédric  2025-01-01      Absence            <NA>      <NA>    <NA>  <NA>          <NA>             FERIE  8.0      <NA>            8.0     AEY        MAINTENANCE        <NA>          <NA>                   <NA>  <NA>  Absence   \n",
      "6        CTR         COUTURIER Yves  2025-01-01      Absence            <NA>      <NA>    <NA>  <NA>          <NA>     ARRET MALADIE  8.0      <NA>            8.0     AEB        MAINTENANCE        <NA>          <NA>                   <NA>  <NA>  Absence   \n",
      "7        NDO      DONNADIEU Nicolas  2025-01-01      Absence            <NA>      <NA>    <NA>  <NA>          <NA>             FERIE  8.0      <NA>            8.0     AEY  ACHATS/LOGISTIQUE        <NA>          <NA>                   <NA>  <NA>  Absence   \n",
      "8        DQE     DUQUESNE Guillaume  2025-01-01      Absence            <NA>      <NA>    <NA>  <NA>          <NA>             FERIE  8.0      <NA>            8.0     AEB        MAINTENANCE        <NA>          <NA>                   <NA>  <NA>  Absence   \n",
      "9        FCX     FAUCHEUX Guillaume  2025-01-01      Absence      JOUR FERIE      <NA>    <NA>  <NA>          <NA>             FERIE  8.0      <NA>            8.0     AEB   BUREAU TECHNIQUE        <NA>          <NA>                   <NA>  <NA>  Absence   \n",
      "10       GLE          GALTIE Franck  2025-01-01      Absence            <NA>      <NA>    <NA>  <NA>          <NA>             FERIE  8.0      <NA>            8.0     AEB        MAINTENANCE        <NA>          <NA>                   <NA>  <NA>  Absence   \n",
      "\n",
      "         WP  SEMAINE  MOIS       ANNEE   Cat point ANNEE - SEMAINE    Mois.  \n",
      "1      2372        3     1  1905-07-17  FACTURABLE          2025-3  Janvier  \n",
      "2   Absence        1     1  1905-07-17     ABSENCE          2025-1  Janvier  \n",
      "3   Absence        1     1  1905-07-17     ABSENCE          2025-1  Janvier  \n",
      "4   Absence        1     1  1905-07-17     ABSENCE          2025-1  Janvier  \n",
      "5   Absence        1     1  1905-07-17     ABSENCE          2025-1  Janvier  \n",
      "6   Absence        1     1  1905-07-17     ABSENCE          2025-1  Janvier  \n",
      "7   Absence        1     1  1905-07-17     ABSENCE          2025-1  Janvier  \n",
      "8   Absence        1     1  1905-07-17     ABSENCE          2025-1  Janvier  \n",
      "9   Absence        1     1  1905-07-17     ABSENCE          2025-1  Janvier  \n",
      "10  Absence        1     1  1905-07-17     ABSENCE          2025-1  Janvier  \n",
      "\n",
      "Done. Feuilles analysées: 1\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, unicodedata, warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# ============== CONFIG ==============\n",
    "FILE_PATH = r\"C:\\globasoft\\aerotech\\fic\\Relevé pointages AEB.xlsx\"  # <== adapte si besoin\n",
    "SHOW_SAMPLE = True\n",
    "STRICT_SOURCE_SCHEMA = True  # schéma = EXACT du fichier (pas d'ajout/remap)\n",
    "\n",
    "# ============== LOG ==============\n",
    "def now(): return datetime.now().strftime(\"%H:%M:%S\")\n",
    "def log(msg): print(f\"[{now()}] {msg}\", flush=True)\n",
    "\n",
    "# ============== UTILS ==============\n",
    "def strip_accents_lower(s):\n",
    "    if s is None or (isinstance(s, float) and pd.isna(s)): return \"\"\n",
    "    s = unicodedata.normalize(\"NFKD\", str(s))\n",
    "    s = \"\".join(c for c in s if not unicodedata.combining(c))\n",
    "    return s.lower().strip()\n",
    "\n",
    "def snake_id(s):\n",
    "    s = strip_accents_lower(s)\n",
    "    s = re.sub(r\"[\\s\\.\\-]+\", \"_\", s)\n",
    "    s = re.sub(r\"[^a-z0-9_]\", \"_\", s)\n",
    "    return re.sub(r\"_+\", \"_\", s).strip(\"_\") or \"col\"\n",
    "\n",
    "def make_unique_columns(cols):\n",
    "    out, seen = [], {}\n",
    "    for c in cols:\n",
    "        if c not in seen:\n",
    "            seen[c] = 1\n",
    "            out.append(c)\n",
    "        else:\n",
    "            seen[c] += 1\n",
    "            out.append(f\"{c}_{seen[c]}\")\n",
    "    return out\n",
    "\n",
    "def parse_number_like(series: pd.Series) -> pd.Series:\n",
    "    x = series.astype(\"string\").str.replace(\"\\u00A0\",\" \", regex=False).str.replace(\" \",\"\", regex=False)\n",
    "    x = x.str.replace(r\"(?<=\\d)\\.(?=\\d{3}(?:\\D|$))\",\"\", regex=True)  # 1.234 -> 1234 (milliers)\n",
    "    x = x.str.replace(\",\",\".\", regex=False)  # virgule décimale -> point\n",
    "    return pd.to_numeric(x, errors=\"coerce\")\n",
    "\n",
    "def drop_empty_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.dropna(axis=1, how=\"all\")\n",
    "    blank_idx = []\n",
    "    for j in range(df.shape[1]):\n",
    "        s = df.iloc[:, j]\n",
    "        if s.dropna().astype(str).str.strip().eq(\"\").all():\n",
    "            blank_idx.append(j)\n",
    "    if blank_idx:\n",
    "        log(f\"[drop_empty_columns] suppression colonnes blanches (pos): {blank_idx}\")\n",
    "        df = df.drop(df.columns[blank_idx], axis=1)\n",
    "    return df\n",
    "\n",
    "# ============== HEADER PICK ==============\n",
    "HEADER_HINTS = (\n",
    "    # génériques\n",
    "    \"projet\",\"projets\",\"code\",\"id\",\"réf\",\"ref\",\"libelle\",\"libellé\",\"intitulé\",\n",
    "    \"client\",\"fournisseur\",\"chef de projet\",\"cp\",\"cdp\",\"manager\",\n",
    "    \"statut\",\"status\",\"phase\",\"categorie\",\"catégorie\",\"type\",\n",
    "    \"date\",\"heure\",\"time\",\"période\",\"periode\",\"echeance\",\"échéance\",\n",
    "    \"budget\",\"montant\",\"cout\",\"coût\",\"prix\",\"ht\",\"ttc\",\"avancement\",\"progress\",\"%\",\"taux\",\n",
    "    \"site\",\"section analytique\",\"analytique\",\"commentaire\",\"observations\",\"notes\",\"remarques\",\n",
    "    # spécifiques vus dans le fichier de pointage\n",
    "    \"trigramme\",\"nom\",\"cat pointage\",\"n° dossier\",\"categorie\",\"ot\",\"ata\",\"type de tâche\",\"commentaires\",\n",
    "    \"bu\",\"immat\",\"wp\",\"semaine\",\"mois\",\"annee\",\"année\",\"cat point\",\"annee - semaine\",\"mois.\"\n",
    ")\n",
    "\n",
    "def choose_header_row(df: pd.DataFrame, scan=25) -> int:\n",
    "    limit = min(len(df), scan)\n",
    "    cand_idx, cand_hits = None, -1\n",
    "    for i in range(limit):\n",
    "        row = df.iloc[i].astype(str)\n",
    "        hits = 0\n",
    "        for v in row:\n",
    "            t = strip_accents_lower(v)\n",
    "            if t and any(k in t for k in HEADER_HINTS):\n",
    "                hits += 1\n",
    "        if hits >= 2 and hits > cand_hits:\n",
    "            cand_idx, cand_hits = i, hits\n",
    "    if cand_idx is not None:\n",
    "        return cand_idx\n",
    "\n",
    "    best, idx = -1, 0\n",
    "    for i in range(limit):\n",
    "        row = df.iloc[i].astype(str)\n",
    "        non_empty = row.map(lambda x: x.strip()!=\"\").sum()\n",
    "        texty = row.map(lambda x: bool(re.search(r\"[A-Za-zÀ-ÿ]\", x))).sum()\n",
    "        score = non_empty*2 + texty\n",
    "        if score > best: best, idx = score, i\n",
    "    return idx\n",
    "\n",
    "# ============== INFÉRENCE TYPES (→ PostgreSQL) ==============\n",
    "MAP_TRUE  = {\"true\",\"vrai\",\"oui\",\"yes\",\"1\",\"y\",\"o\"}\n",
    "MAP_FALSE = {\"false\",\"faux\",\"non\",\"no\",\"0\",\"n\"}\n",
    "\n",
    "DATE_TOKEN_RE = re.compile(\n",
    "    r\"(?:\\d{4}[-/\\.]\\d{1,2}[-/\\.]\\d{1,2})|(?:\\d{1,2}[-/\\.]\\d{1,2}[-/\\.]\\d{2,4})|\"\n",
    "    r\"(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec|janv|févr|fevr|avr|mai|juin|juil|sept|oct|nov|d[ée]c)\",\n",
    "    re.I\n",
    ")\n",
    "ISO_DATE_RE = re.compile(r\"^\\d{4}-\\d{2}-\\d{2}(?:[ T]\\d{2}:\\d{2}:\\d{2})?$\")\n",
    "COLNAME_DATE_HINTS = (\"date\",\"dt\",\"heure\",\"time\",\"echeance\",\"échéance\",\"debut\",\"début\",\"fin\",\"période\",\"periode\",\"semaine\",\"mois\",\"année\",\"annee\")\n",
    "\n",
    "AMOUNT_NAME_HINTS = (\n",
    "    \"montant\",\"debit\",\"débit\",\"credit\",\"crédit\",\"solde\",\"budget\",\"ht\",\"ttc\",\n",
    "    \"amount\",\"total\",\"prix\",\"coût\",\"cout\",\"heures\",\"h\"\n",
    ")\n",
    "CODE_LIKE_HINTS = (\"code\",\"nature\",\"plan\",\"compte\",\"sop\",\"section\",\"niveau\",\"trigramme\",\"immat\",\"ot\",\"ata\",\"wp\",\"n° dossier\",\"n_dossier\",\"dossier\",\"cat point\",\"cat pointage\")\n",
    "\n",
    "def colname_has(hints, name):\n",
    "    n = strip_accents_lower(name or \"\")\n",
    "    return any(h in n for h in hints)\n",
    "\n",
    "def excel_serial_to_datetime(series: pd.Series) -> pd.Series:\n",
    "    vals = pd.to_numeric(series, errors=\"coerce\").astype(\"float64\")\n",
    "    vals[~np.isfinite(vals)] = np.nan\n",
    "    lower, upper = 60.0, 60000.0  # ~ 1900..2064\n",
    "    mask = (vals >= lower) & (vals <= upper)\n",
    "    n_out = int((~mask & ~pd.isna(vals)).sum())\n",
    "    if n_out:\n",
    "        log(f\"[excel_serial_to_datetime] valeurs hors fenêtre [{int(lower)}, {int(upper)}] -> NaN: {n_out}\")\n",
    "    base = pd.Timestamp(\"1899-12-30\")\n",
    "    td = pd.to_timedelta(vals.where(mask, np.nan), unit=\"D\", errors=\"coerce\")\n",
    "    dt = base + td\n",
    "    return pd.to_datetime(dt, errors=\"coerce\")\n",
    "\n",
    "def infer_col(col: pd.Series):\n",
    "    \"\"\"\n",
    "    Retourne (serie_casted, tag) avec tag ∈ {\"DATE\",\"DATETIME\",\"INT\",\"FLOAT\",\"BOOL\",\"STRING\"}.\n",
    "    \"\"\"\n",
    "    s = col.copy()\n",
    "    ss = s.astype(\"string\").str.strip()\n",
    "\n",
    "    # 0) ISO direct\n",
    "    iso_mask = ss.fillna(\"\").str.match(ISO_DATE_RE)\n",
    "    if len(ss) and iso_mask.mean() >= 0.5:\n",
    "        dt_iso = pd.to_datetime(ss.where(iso_mask), errors=\"coerce\", dayfirst=False)\n",
    "        ok = dt_iso.notna().mean()\n",
    "        if ok >= 0.5:\n",
    "            has_time = (dt_iso.dt.time.astype(str) != \"00:00:00\").mean() > 0.2\n",
    "            return (\n",
    "                dt_iso.dt.strftime(\"%Y-%m-%d %H:%M:%S\") if has_time else dt_iso.dt.strftime(\"%Y-%m-%d\"),\n",
    "                \"DATETIME\" if has_time else \"DATE\"\n",
    "            )\n",
    "\n",
    "    # 1) Excel serial dates (restreint)\n",
    "    as_num = pd.to_numeric(ss, errors=\"coerce\")\n",
    "    safe_mask = (as_num >= 60) & (as_num <= 60000)\n",
    "    safe_ratio = safe_mask.mean() if len(ss) else 0.0\n",
    "\n",
    "    colname_hint = colname_has(COLNAME_DATE_HINTS, s.name)\n",
    "    high_vals_ratio = (as_num >= 20000).mean() if len(ss) else 0.0  # 20000 ~ 1954\n",
    "\n",
    "    if (as_num.notna().mean() if len(ss) else 0.0) >= 0.9 and safe_ratio >= 0.7 and (colname_hint or high_vals_ratio >= 0.2):\n",
    "        parsed = excel_serial_to_datetime(as_num)\n",
    "        ok = parsed.notna().mean() if len(ss) else 0.0\n",
    "        if ok >= 0.7:\n",
    "            has_time = (parsed.dt.time.astype(str) != \"00:00:00\").mean() > 0.2\n",
    "            return (\n",
    "                parsed.dt.strftime(\"%Y-%m-%d %H:%M:%S\") if has_time else parsed.dt.strftime(\"%Y-%m-%d\"),\n",
    "                \"DATETIME\" if has_time else \"DATE\"\n",
    "            )\n",
    "\n",
    "    # 2) tokens de date / nom “datey”\n",
    "    date_token_ratio = ss.fillna(\"\").str.contains(DATE_TOKEN_RE, na=False).mean()\n",
    "    looks_datey = colname_hint or (date_token_ratio >= 0.30)\n",
    "    if looks_datey:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", message=\"Could not infer format.*\", category=UserWarning)\n",
    "            dt1 = pd.to_datetime(ss, errors=\"coerce\", dayfirst=True,  cache=True)\n",
    "            dt2 = pd.to_datetime(ss, errors=\"coerce\", dayfirst=False, cache=True)\n",
    "        dt = dt2 if dt2.notna().sum() > dt1.notna().sum() else dt1\n",
    "        ok = dt.notna().mean() if len(ss) else 0.0\n",
    "        ok_thresh = 0.50 if colname_hint else 0.70\n",
    "        if ok >= ok_thresh:\n",
    "            has_time = (dt.dt.time.astype(str) != \"00:00:00\").mean() > 0.2\n",
    "            return (\n",
    "                pd.to_datetime(dt).dt.strftime(\"%Y-%m-%d %H:%M:%S\") if has_time else pd.to_datetime(dt).dt.strftime(\"%Y-%m-%d\"),\n",
    "                \"DATETIME\" if has_time else \"DATE\"\n",
    "            )\n",
    "\n",
    "    # 3) bool strict\n",
    "    mb = ss.str.lower().map(lambda x: True if x in MAP_TRUE else (False if x in MAP_FALSE else pd.NA))\n",
    "    if len(ss) and mb.notna().mean() >= 0.98:\n",
    "        return mb.astype(\"boolean\"), \"BOOL\"\n",
    "\n",
    "    # 3bis) colonnes monétaires / heures : forcer numérique si le nom l'indique\n",
    "    if colname_has(AMOUNT_NAME_HINTS, s.name):\n",
    "        nums_hint = parse_number_like(ss)\n",
    "        if nums_hint.notna().any():\n",
    "            nz = nums_hint.dropna()\n",
    "            if len(nz) and (np.mod(nz, 1) == 0).all():\n",
    "                return nums_hint.astype(\"Int64\"), \"INT\"\n",
    "            return nums_hint.astype(\"Float64\"), \"FLOAT\"\n",
    "\n",
    "    # 3ter) colonnes \"code-like\" : garder du texte\n",
    "    if colname_has(CODE_LIKE_HINTS, s.name):\n",
    "        return ss.astype(\"string\"), \"STRING\"\n",
    "\n",
    "    # 4) nombre générique\n",
    "    nums = parse_number_like(ss)\n",
    "    if (nums.notna().mean() if len(ss) else 0) >= 0.85:\n",
    "        nz = nums.dropna()\n",
    "        if len(nz) and (np.mod(nz, 1) == 0).all():\n",
    "            return nums.astype(\"Int64\"), \"INT\"\n",
    "        return nums.astype(\"Float64\"), \"FLOAT\"\n",
    "\n",
    "    # 5) texte\n",
    "    return ss.astype(\"string\"), \"STRING\"\n",
    "\n",
    "def pg_type(tag: str) -> str:\n",
    "    return {\n",
    "        \"DATE\":\"date\",\n",
    "        \"DATETIME\":\"timestamp without time zone\",\n",
    "        \"INT\":\"integer\",\n",
    "        \"FLOAT\":\"double precision\",\n",
    "        \"BOOL\":\"boolean\",\n",
    "        \"STRING\":\"text\"\n",
    "    }.get(tag, \"text\")\n",
    "\n",
    "# ============== MAIN ==============\n",
    "def main():\n",
    "    xlsx = Path(FILE_PATH)\n",
    "    log(f\"Fichier: {xlsx}\")\n",
    "    if not xlsx.exists():\n",
    "        log(\"[error] Fichier introuvable\"); return\n",
    "\n",
    "    try:\n",
    "        sheets = pd.read_excel(xlsx, sheet_name=None, engine=\"openpyxl\", header=None)\n",
    "    except Exception as e:\n",
    "        log(f\"[error] Lecture échouée: {e}\"); return\n",
    "\n",
    "    done = 0\n",
    "    for name, raw in sheets.items():\n",
    "        log(f\"\\n[feuille] {name}: shape initiale={raw.shape}\")\n",
    "\n",
    "        # nettoyage vide\n",
    "        raw = raw.dropna(how=\"all\", axis=0).dropna(how=\"all\", axis=1)\n",
    "        log(f\"[feuille] {name}: après drop vides -> {raw.shape}\")\n",
    "        if raw.empty:\n",
    "            log(f\"[feuille] {name}: vide, on passe.\")\n",
    "            continue\n",
    "\n",
    "        # repère l'entête dans le brut (sans remap)\n",
    "        h = choose_header_row(raw, scan=25)\n",
    "        log(f\"[feuille] {name}: header choisi à la ligne {h}\")\n",
    "\n",
    "        # ====== VUE SOURCE STRICTE (schéma du fichier) ======\n",
    "        df_src = raw.iloc[h+1:].copy()\n",
    "        src_cols_original = raw.iloc[h].tolist()  # libellés EXACTS du fichier\n",
    "        df_src.columns = src_cols_original\n",
    "        df_src = df_src.dropna(how=\"all\").copy()\n",
    "        df_src = drop_empty_columns(df_src)\n",
    "        log(f\"[feuille] {name}: shape après affectation des en-têtes -> {df_src.shape}\")\n",
    "        if df_src.empty:\n",
    "            log(f\"[feuille] {name}: vide après normalisation, on passe.\")\n",
    "            continue\n",
    "\n",
    "        # noms PostgreSQL (snake_case) correspondants aux libellés Excel\n",
    "        pg_cols = make_unique_columns([snake_id(c) for c in df_src.columns])\n",
    "\n",
    "        # inférence STRICTE sur colonnes d'origine (sans ajout ni remap)\n",
    "        schema_src = {}\n",
    "        casted_df = df_src.copy()\n",
    "        for c in list(df_src.columns):\n",
    "            casted, tag = infer_col(df_src[c])\n",
    "            casted_df[c] = casted\n",
    "            schema_src[c] = tag\n",
    "\n",
    "        # affichage STRICT : schéma = fichier, avec mapping vers noms pg + types pg\n",
    "        base = f\"{snake_id(xlsx.stem)}.{snake_id(name)}\"\n",
    "        print(f\"\\n--- Feuille: {name} -> {base} (SCHÉMA SOURCE STRICT / PostgreSQL) ---\")\n",
    "        print(f\"rows={len(casted_df)} | cols={casted_df.shape[1]}\")\n",
    "\n",
    "        print(\"\\nMapping colonnes (Excel → nom_pg) :\")\n",
    "        for src_name, pg_name in zip(df_src.columns, pg_cols):\n",
    "            print(f\"  - {src_name}  ->  {pg_name}\")\n",
    "\n",
    "        print(\"\\nSchema détecté (types PostgreSQL) :\")\n",
    "        for src_name, pg_name in zip(df_src.columns, pg_cols):\n",
    "            tag = schema_src.get(src_name, \"STRING\")\n",
    "            print(f\"  - {pg_name}: {pg_type(tag)}  (source: {src_name}, type détecté: {tag})\")\n",
    "\n",
    "        if SHOW_SAMPLE:\n",
    "            with pd.option_context(\"display.max_columns\", 180, \"display.width\", 260):\n",
    "                print(\"\\nSample (top 10) :\")\n",
    "                print(casted_df.head(10))\n",
    "\n",
    "        done += 1\n",
    "\n",
    "        # ====== (OPTIONNEL) VUE CIBLE : si tu veux une table cible, remets STRICT_SOURCE_SCHEMA=False et implémente ici ======\n",
    "        if not STRICT_SOURCE_SCHEMA:\n",
    "            pass\n",
    "\n",
    "    print(f\"\\nDone. Feuilles analysées: {done}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03eef39-a59e-42e3-89de-29289b1d2da5",
   "metadata": {},
   "source": [
    "# Suivi Projets AEC - source.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebafa3aa-24bf-410f-8d3d-02507da60b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:16:11] Fichier: C:\\globasoft\\aerotech\\fic\\Suivi Projets AEC - source.xlsx\n",
      "[11:16:11] \n",
      "[feuille] 2025mai: shape initiale=(226, 82)\n",
      "[11:16:11] [feuille] 2025mai: après drop vides -> (226, 82)\n",
      "[11:16:11] [feuille] 2025mai: header choisi à la ligne 3\n",
      "[11:16:11] [feuille] 2025mai: shape après affectation des en-têtes -> (222, 75)\n",
      "\n",
      "--- Feuille: 2025mai -> suivi_projets_aec_source.2025mai (SCHÉMA SOURCE STRICT / PostgreSQL) ---\n",
      "rows=222 | cols=75\n",
      "\n",
      "Mapping colonnes (Excel → nom_pg) :\n",
      "  - Comments  ->  comments\n",
      "  - REVUE RAF  ->  revue_raf\n",
      "  - GTM  ->  gtm\n",
      "  - Statut suivi de projets  ->  statut_suivi_de_projets\n",
      "  - Top custo  ->  top_custo\n",
      "  - Num Projets  ->  num_projets\n",
      "  - Réunion RAF  ->  reunion_raf\n",
      "  - CdP  ->  cdp\n",
      "  - Date fin  ->  date_fin\n",
      "  - Total Budget\n",
      "€  ->  total_budget\n",
      "  - Ecart Budget M-1\n",
      "€  ->  ecart_budget_m_1\n",
      "  - Total Dépensé Engagé\n",
      "€  ->  total_depense_engage\n",
      "  - Total Dépensé Enregistré\n",
      "€  ->  total_depense_enregistre\n",
      "  - Total Marge Projeté\n",
      "%  ->  total_marge_projete\n",
      "  - Ecart Marge Projeté M-1\n",
      "%  ->  ecart_marge_projete_m_1\n",
      "  - Objectif de marge %  ->  objectif_de_marge\n",
      "  - Budget Heures\n",
      "Hrs  ->  budget_heures_hrs\n",
      "  - Réel Heures Internes\n",
      "Hrs  ->  reel_heures_internes_hrs\n",
      "  - Réel Heures ST\n",
      "Hrs  ->  reel_heures_st_hrs\n",
      "  - RAF Heures\n",
      "Hrs  ->  raf_heures_hrs\n",
      "  - RAF Heures M-1\n",
      "Hrs  ->  raf_heures_m_1_hrs\n",
      "  - Ecart Heures vs M-1\n",
      "Hrs  ->  ecart_heures_vs_m_1_hrs\n",
      "  - Budget Heures Valorisées\n",
      "€  ->  budget_heures_valorisees\n",
      "  - Réel Heures Valorisées\n",
      "€  ->  reel_heures_valorisees\n",
      "  - RAF Heures Valorisées\n",
      "€  ->  raf_heures_valorisees\n",
      "  - Marge prévisionnelle Heures\n",
      "%  ->  marge_previsionnelle_heures\n",
      "  - Budget Achat HT\n",
      "€  ->  budget_achat_ht\n",
      "  - Prévi HA coûts = nomenaf  ->  previ_ha_couts_nomenaf\n",
      "  - Achats commandés HT\n",
      "€  ->  achats_commandes_ht\n",
      "  - Achats enregistrés HT\n",
      "€  ->  achats_enregistres_ht\n",
      "  - Commandé-Enregistré yc FNP  ->  commande_enregistre_yc_fnp\n",
      "  - dont FNP à date (€ HT)  ->  dont_fnp_a_date_ht\n",
      "  - RAF Achats\n",
      "€  ->  raf_achats\n",
      "  - RAF Achats M-1\n",
      "€  ->  raf_achats_m_1\n",
      "  - Ecart Achats vs M-1\n",
      "€  ->  ecart_achats_vs_m_1\n",
      "  - Int Commandé OT\n",
      "€  ->  int_commande_ot\n",
      "  - Int Réalisé OT\n",
      "€  ->  int_realise_ot\n",
      "  - RAF Int OT\n",
      "€  ->  raf_int_ot\n",
      "  - RAF OT M-1\n",
      "€  ->  raf_ot_m_1\n",
      "  - Ecart Int OT vs M-1\n",
      "€  ->  ecart_int_ot_vs_m_1\n",
      "  - Marge prévisionnelle Achats\n",
      "%  ->  marge_previsionnelle_achats\n",
      "  - Budget Mission\n",
      " €  ->  budget_mission\n",
      "  - Prévisionnel Missions\n",
      "€  ->  previsionnel_missions\n",
      "  - Réel Mission\n",
      "€  ->  reel_mission\n",
      "  - RAF Mission\n",
      "€  ->  raf_mission\n",
      "  - RAF Mission M-1\n",
      "€  ->  raf_mission_m_1\n",
      "  - Ecart Mission vs M-1\n",
      "€  ->  ecart_mission_vs_m_1\n",
      "  - Marge prévisionnelle Mission\n",
      "%  ->  marge_previsionnelle_mission\n",
      "  - Provisions pour risques  ->  provisions_pour_risques\n",
      "  - Facturation globale projet à date (€ HT)   ->  facturation_globale_projet_a_date_ht\n",
      "  - CA fin N-1  ->  ca_fin_n_1\n",
      "  - CA N à date (€ HT)   ->  ca_n_a_date_ht\n",
      "  - Consommé global Enregistré à date (€ HT)  ->  consomme_global_enregistre_a_date_ht\n",
      "  - RaF Global à terminaison à date (€ HT)  ->  raf_global_a_terminaison_a_date_ht\n",
      "  - Avancement Global Financier basé sur Enregistré à date (%)  ->  avancement_global_financier_base_sur_enregistre_a_date\n",
      "  - Avancement Global Facturation à date (%)  ->  avancement_global_facturation_a_date\n",
      "  - PCA basé sur Enregistré à date (€)  ->  pca_base_sur_enregistre_a_date\n",
      "  - FAE basé sur Enregistré à date (€)  ->  fae_base_sur_enregistre_a_date\n",
      "  - Valeur vente Ingenieur (€ HT)  ->  valeur_vente_ingenieur_ht\n",
      "  - Objectif fin d'année  ->  objectif_fin_d_annee\n",
      "  - Cohérence Budget  ->  coherence_budget\n",
      "  - ecart couts à terminaison vs M-1  ->  ecart_couts_a_terminaison_vs_m_1\n",
      "  - écart avancement  ->  ecart_avancement\n",
      "  - CA Y  ->  ca_y\n",
      "  - Charges Y  ->  charges_y\n",
      "  - Marge Y  ->  marge_y\n",
      "  - Facturation Y  ->  facturation_y\n",
      "  - CA mois  ->  ca_mois\n",
      "  - Charges mois  ->  charges_mois\n",
      "  - Marge mois  ->  marge_mois\n",
      "  - Facturation mois  ->  facturation_mois\n",
      "  - Remaining Forecast  ->  remaining_forecast\n",
      "  - hrs à fin s21  ->  hrs_a_fin_s21\n",
      "  - RaF (h) MO à fin s21  ->  raf_h_mo_a_fin_s21\n",
      "  - RaF (h) MO à fin s22  ->  raf_h_mo_a_fin_s22\n",
      "\n",
      "Schema détecté (types PostgreSQL) :\n",
      "  - comments: text  (source: Comments, type détecté: STRING)\n",
      "  - revue_raf: text  (source: REVUE RAF, type détecté: STRING)\n",
      "  - gtm: text  (source: GTM, type détecté: STRING)\n",
      "  - statut_suivi_de_projets: text  (source: Statut suivi de projets, type détecté: STRING)\n",
      "  - top_custo: text  (source: Top custo, type détecté: STRING)\n",
      "  - num_projets: text  (source: Num Projets, type détecté: STRING)\n",
      "  - reunion_raf: text  (source: Réunion RAF, type détecté: STRING)\n",
      "  - cdp: text  (source: CdP, type détecté: STRING)\n",
      "  - date_fin: text  (source: Date fin, type détecté: STRING)\n",
      "  - total_budget: double precision  (source: Total Budget\n",
      "€, type détecté: FLOAT)\n",
      "  - ecart_budget_m_1: double precision  (source: Ecart Budget M-1\n",
      "€, type détecté: FLOAT)\n",
      "  - total_depense_engage: double precision  (source: Total Dépensé Engagé\n",
      "€, type détecté: FLOAT)\n",
      "  - total_depense_enregistre: double precision  (source: Total Dépensé Enregistré\n",
      "€, type détecté: FLOAT)\n",
      "  - total_marge_projete: double precision  (source: Total Marge Projeté\n",
      "%, type détecté: FLOAT)\n",
      "  - ecart_marge_projete_m_1: double precision  (source: Ecart Marge Projeté M-1\n",
      "%, type détecté: FLOAT)\n",
      "  - objectif_de_marge: double precision  (source: Objectif de marge %, type détecté: FLOAT)\n",
      "  - budget_heures_hrs: double precision  (source: Budget Heures\n",
      "Hrs, type détecté: FLOAT)\n",
      "  - reel_heures_internes_hrs: double precision  (source: Réel Heures Internes\n",
      "Hrs, type détecté: FLOAT)\n",
      "  - reel_heures_st_hrs: double precision  (source: Réel Heures ST\n",
      "Hrs, type détecté: FLOAT)\n",
      "  - raf_heures_hrs: double precision  (source: RAF Heures\n",
      "Hrs, type détecté: FLOAT)\n",
      "  - raf_heures_m_1_hrs: double precision  (source: RAF Heures M-1\n",
      "Hrs, type détecté: FLOAT)\n",
      "  - ecart_heures_vs_m_1_hrs: double precision  (source: Ecart Heures vs M-1\n",
      "Hrs, type détecté: FLOAT)\n",
      "  - budget_heures_valorisees: double precision  (source: Budget Heures Valorisées\n",
      "€, type détecté: FLOAT)\n",
      "  - reel_heures_valorisees: double precision  (source: Réel Heures Valorisées\n",
      "€, type détecté: FLOAT)\n",
      "  - raf_heures_valorisees: double precision  (source: RAF Heures Valorisées\n",
      "€, type détecté: FLOAT)\n",
      "  - marge_previsionnelle_heures: double precision  (source: Marge prévisionnelle Heures\n",
      "%, type détecté: FLOAT)\n",
      "  - budget_achat_ht: double precision  (source: Budget Achat HT\n",
      "€, type détecté: FLOAT)\n",
      "  - previ_ha_couts_nomenaf: double precision  (source: Prévi HA coûts = nomenaf, type détecté: FLOAT)\n",
      "  - achats_commandes_ht: double precision  (source: Achats commandés HT\n",
      "€, type détecté: FLOAT)\n",
      "  - achats_enregistres_ht: double precision  (source: Achats enregistrés HT\n",
      "€, type détecté: FLOAT)\n",
      "  - commande_enregistre_yc_fnp: double precision  (source: Commandé-Enregistré yc FNP, type détecté: FLOAT)\n",
      "  - dont_fnp_a_date_ht: double precision  (source: dont FNP à date (€ HT), type détecté: FLOAT)\n",
      "  - raf_achats: double precision  (source: RAF Achats\n",
      "€, type détecté: FLOAT)\n",
      "  - raf_achats_m_1: double precision  (source: RAF Achats M-1\n",
      "€, type détecté: FLOAT)\n",
      "  - ecart_achats_vs_m_1: double precision  (source: Ecart Achats vs M-1\n",
      "€, type détecté: FLOAT)\n",
      "  - int_commande_ot: double precision  (source: Int Commandé OT\n",
      "€, type détecté: FLOAT)\n",
      "  - int_realise_ot: double precision  (source: Int Réalisé OT\n",
      "€, type détecté: FLOAT)\n",
      "  - raf_int_ot: double precision  (source: RAF Int OT\n",
      "€, type détecté: FLOAT)\n",
      "  - raf_ot_m_1: double precision  (source: RAF OT M-1\n",
      "€, type détecté: FLOAT)\n",
      "  - ecart_int_ot_vs_m_1: double precision  (source: Ecart Int OT vs M-1\n",
      "€, type détecté: FLOAT)\n",
      "  - marge_previsionnelle_achats: double precision  (source: Marge prévisionnelle Achats\n",
      "%, type détecté: FLOAT)\n",
      "  - budget_mission: double precision  (source: Budget Mission\n",
      " €, type détecté: FLOAT)\n",
      "  - previsionnel_missions: double precision  (source: Prévisionnel Missions\n",
      "€, type détecté: FLOAT)\n",
      "  - reel_mission: double precision  (source: Réel Mission\n",
      "€, type détecté: FLOAT)\n",
      "  - raf_mission: double precision  (source: RAF Mission\n",
      "€, type détecté: FLOAT)\n",
      "  - raf_mission_m_1: double precision  (source: RAF Mission M-1\n",
      "€, type détecté: FLOAT)\n",
      "  - ecart_mission_vs_m_1: double precision  (source: Ecart Mission vs M-1\n",
      "€, type détecté: FLOAT)\n",
      "  - marge_previsionnelle_mission: double precision  (source: Marge prévisionnelle Mission\n",
      "%, type détecté: FLOAT)\n",
      "  - provisions_pour_risques: integer  (source: Provisions pour risques, type détecté: INT)\n",
      "  - facturation_globale_projet_a_date_ht: double precision  (source: Facturation globale projet à date (€ HT) , type détecté: FLOAT)\n",
      "  - ca_fin_n_1: double precision  (source: CA fin N-1, type détecté: FLOAT)\n",
      "  - ca_n_a_date_ht: double precision  (source: CA N à date (€ HT) , type détecté: FLOAT)\n",
      "  - consomme_global_enregistre_a_date_ht: double precision  (source: Consommé global Enregistré à date (€ HT), type détecté: FLOAT)\n",
      "  - raf_global_a_terminaison_a_date_ht: double precision  (source: RaF Global à terminaison à date (€ HT), type détecté: FLOAT)\n",
      "  - avancement_global_financier_base_sur_enregistre_a_date: double precision  (source: Avancement Global Financier basé sur Enregistré à date (%), type détecté: FLOAT)\n",
      "  - avancement_global_facturation_a_date: double precision  (source: Avancement Global Facturation à date (%), type détecté: FLOAT)\n",
      "  - pca_base_sur_enregistre_a_date: double precision  (source: PCA basé sur Enregistré à date (€), type détecté: FLOAT)\n",
      "  - fae_base_sur_enregistre_a_date: double precision  (source: FAE basé sur Enregistré à date (€), type détecté: FLOAT)\n",
      "  - valeur_vente_ingenieur_ht: double precision  (source: Valeur vente Ingenieur (€ HT), type détecté: FLOAT)\n",
      "  - objectif_fin_d_annee: double precision  (source: Objectif fin d'année, type détecté: FLOAT)\n",
      "  - coherence_budget: double precision  (source: Cohérence Budget, type détecté: FLOAT)\n",
      "  - ecart_couts_a_terminaison_vs_m_1: double precision  (source: ecart couts à terminaison vs M-1, type détecté: FLOAT)\n",
      "  - ecart_avancement: double precision  (source: écart avancement, type détecté: FLOAT)\n",
      "  - ca_y: double precision  (source: CA Y, type détecté: FLOAT)\n",
      "  - charges_y: double precision  (source: Charges Y, type détecté: FLOAT)\n",
      "  - marge_y: double precision  (source: Marge Y, type détecté: FLOAT)\n",
      "  - facturation_y: double precision  (source: Facturation Y, type détecté: FLOAT)\n",
      "  - ca_mois: double precision  (source: CA mois, type détecté: FLOAT)\n",
      "  - charges_mois: double precision  (source: Charges mois, type détecté: FLOAT)\n",
      "  - marge_mois: double precision  (source: Marge mois, type détecté: FLOAT)\n",
      "  - facturation_mois: double precision  (source: Facturation mois, type détecté: FLOAT)\n",
      "  - remaining_forecast: double precision  (source: Remaining Forecast, type détecté: FLOAT)\n",
      "  - hrs_a_fin_s21: double precision  (source: hrs à fin s21, type détecté: FLOAT)\n",
      "  - raf_h_mo_a_fin_s21: double precision  (source: RaF (h) MO à fin s21, type détecté: FLOAT)\n",
      "  - raf_h_mo_a_fin_s22: double precision  (source: RaF (h) MO à fin s22, type détecté: FLOAT)\n",
      "\n",
      "Sample (top 10) :\n",
      "                                             Comments REVUE RAF        GTM Statut suivi de projets Top custo Num Projets         Réunion RAF   CdP Date fin  Total Budget\\n€  Ecart Budget M-1\\n€  Total Dépensé Engagé\\n€  Total Dépensé Enregistré\\n€  \\\n",
      "4   s35 : à annuler - s22/s52 : spéléo zombie à po...      <NA>      ROTOR                    <NA>    autres     C181320              Rotors  <NA>     <NA>             <NA>                 <NA>                     <NA>                         <NA>   \n",
      "5   s22 : annulé à indexer sur facturé (2024)- dis...      <NA>  A/L & STC                  Annulé    autres     C181556  Cabines & Systèmes  <NA>     <NA>             <NA>                 <NA>                     <NA>                         <NA>   \n",
      "6   s15 : ramené au facturé (0) - s09/s48 : invest...      <NA>        MRO                    <NA>      DGAC     C181592                   ?  <NA>     <NA>             <NA>                 <NA>                     <NA>                         <NA>   \n",
      "7   s22 : annulé à indexer sur facturé - discussio...      <NA>  A/L & STC                  Annulé    autres     C181688  Cabines & Systèmes  <NA>     <NA>             <NA>                 <NA>                     <NA>                         <NA>   \n",
      "8   s48 : annulé - s40: standby chez client final....      <NA>  A/L & STC                  Annulé    autres     C191860  Cabines & Systèmes  <NA>     <NA>             <NA>                 <NA>                     <NA>                         <NA>   \n",
      "9   s22 : facturation supérieure au budget -s05 : ...      <NA>      ROTOR                    <NA>    autres     C192026          Programmes  <NA>     <NA>              0.0                  0.0                     <NA>                         <NA>   \n",
      "10  s22 : négo client pour facturer le consommé ( ...      <NA>  A/L & STC                  Annulé    autres     C202607  Cabines & Systèmes  <NA>     <NA>             <NA>                 <NA>                     <NA>                         <NA>   \n",
      "11  s48 : annulé s44/40/35/26/22/13/09/05/48 : sta...      <NA>  A/L & STC                  Annulé    autres     C202681  Cabines & Systèmes  <NA>     <NA>             <NA>                 <NA>                     <NA>                         <NA>   \n",
      "12  s22 : à annuler commandé à indexer sur facturé...      <NA>  A/L & STC       Terminé à annuler    autres     C212935  Cabines & Systèmes  <NA>     <NA>             <NA>                 <NA>                     <NA>                         <NA>   \n",
      "13                                                            Y      ROTOR                    <NA>   Babcock     C202747              Rotors  <NA>     <NA>             <NA>                 <NA>                     <NA>                         <NA>   \n",
      "\n",
      "    Total Marge Projeté\\n%  Ecart Marge Projeté M-1\\n%  Objectif de marge %  Budget Heures\\nHrs  Réel Heures Internes\\nHrs  Réel Heures ST\\nHrs  RAF Heures\\nHrs  RAF Heures M-1\\nHrs  Ecart Heures vs M-1\\nHrs  Budget Heures Valorisées\\n€  \\\n",
      "4                     <NA>                        <NA>                 <NA>                 0.0                        0.0                  0.0              3.0                  0.0                       0.0                          0.0   \n",
      "5                     <NA>                        <NA>                 <NA>                 0.0                        0.0                  0.0             29.5                  0.0                       0.0                          0.0   \n",
      "6                     <NA>                        <NA>                 <NA>                 0.0                        0.0                  0.0              5.0                  0.0                       0.0                          0.0   \n",
      "7                     <NA>                        <NA>                 <NA>                 0.0                        0.0                  0.0            172.5                  0.0                       0.0                          0.0   \n",
      "8                     <NA>                        <NA>                 <NA>                 0.0                        0.0                  0.0             32.5                  0.0                       0.0                          0.0   \n",
      "9                      0.0                         0.0                  0.0                 0.0                        0.0                  0.0           1970.5                  0.0                       0.0                          0.0   \n",
      "10                    <NA>                        <NA>                 <NA>                 0.0                        0.0                  0.0            418.5                  0.0                       0.0                          0.0   \n",
      "11                    <NA>                        <NA>                 <NA>                 0.0                        0.0                  0.0             18.5                  0.0                       0.0                          0.0   \n",
      "12                    <NA>                        <NA>                 <NA>                 0.0                        0.0                  0.0            361.0                  0.0                       0.0                         <NA>   \n",
      "13                    <NA>                        <NA>                 <NA>                <NA>                        0.0                  0.0        144.01875                  0.0                       0.0                         <NA>   \n",
      "\n",
      "    Réel Heures Valorisées\\n€  RAF Heures Valorisées\\n€  Marge prévisionnelle Heures\\n%  Budget Achat HT\\n€  Prévi HA coûts = nomenaf  Achats commandés HT\\n€  Achats enregistrés HT\\n€  Commandé-Enregistré yc FNP  dont FNP à date (€ HT)  RAF Achats\\n€  \\\n",
      "4                        <NA>                     143.4                             0.0                 0.0                       0.0                     0.0                       0.0                         0.0                     0.0            0.0   \n",
      "5                        <NA>                    1410.1                             0.0                <NA>                       0.0                     0.0                       0.0                         0.0                     0.0            0.0   \n",
      "6                        <NA>                     239.0                             0.0                 0.0                       0.0                     0.0                       0.0                         0.0                     0.0            0.0   \n",
      "7                        <NA>                    8245.5                             0.0                <NA>                       0.0                     0.0                       0.0                         0.0                     0.0            0.0   \n",
      "8                        <NA>                    1553.5                             0.0                 0.0                       0.0                     0.0                       0.0                         0.0                     0.0            0.0   \n",
      "9                        <NA>                   94189.9                             0.0                 0.0                       0.0               -10590.32                    192.12                   -10782.44                  192.12            0.0   \n",
      "10                       <NA>                   20004.3                             0.0                <NA>                       0.0                     0.0                       0.0                         0.0                     0.0            0.0   \n",
      "11                       <NA>                     884.3                             0.0                 0.0                       0.0                     0.0                       0.0                         0.0                     0.0            0.0   \n",
      "12                       <NA>                   17255.8                            <NA>                 0.0                       0.0                     0.0                       0.0                         0.0                     0.0            0.0   \n",
      "13                       <NA>                6884.09625                            <NA>                 0.0                       0.0                     0.0                       0.0                         0.0                     0.0            0.0   \n",
      "\n",
      "    RAF Achats M-1\\n€  Ecart Achats vs M-1\\n€  Int Commandé OT\\n€  Int Réalisé OT\\n€  RAF Int OT\\n€  RAF OT M-1\\n€  Ecart Int OT vs M-1\\n€  Marge prévisionnelle Achats\\n%  Budget Mission\\n €  Prévisionnel Missions\\n€  Réel Mission\\n€  RAF Mission\\n€  \\\n",
      "4                 0.0                     0.0                 0.0                0.0            0.0            0.0                     0.0                             0.0                 0.0                       0.0              0.0             0.0   \n",
      "5                 0.0                     0.0                 0.0                0.0            0.0            0.0                     0.0                            <NA>                 0.0                       0.0              0.0             0.0   \n",
      "6                 0.0                     0.0                 0.0                0.0            0.0            0.0                     0.0                             0.0                 0.0                       0.0              0.0             0.0   \n",
      "7                 0.0                     0.0                 0.0                0.0            0.0            0.0                     0.0                            <NA>                 0.0                       0.0              0.0             0.0   \n",
      "8                 0.0                     0.0                 0.0                0.0            0.0            0.0                     0.0                             0.0                 0.0                       0.0              0.0             0.0   \n",
      "9                 0.0               -10590.32                 0.0             195.25            0.0            0.0                     0.0                             0.0                 0.0                       0.0              0.0             0.0   \n",
      "10                0.0                     0.0                 0.0                0.0            0.0            0.0                     0.0                            <NA>                 0.0                       0.0              0.0             0.0   \n",
      "11                0.0                     0.0                 0.0                0.0            0.0            0.0                     0.0                             0.0                 0.0                       0.0              0.0             0.0   \n",
      "12                0.0                     0.0                 0.0                0.0            0.0            0.0                     0.0                             0.0                 0.0                       0.0              0.0             0.0   \n",
      "13                0.0                     0.0                 0.0                0.0            0.0            0.0                     0.0                             0.0                 0.0                       0.0              0.0             0.0   \n",
      "\n",
      "    RAF Mission M-1\\n€  Ecart Mission vs M-1\\n€  Marge prévisionnelle Mission\\n%  Provisions pour risques  Facturation globale projet à date (€ HT)   CA fin N-1  CA N à date (€ HT)   Consommé global Enregistré à date (€ HT)  \\\n",
      "4                  0.0                      0.0                              0.0                        0                                        0.0         0.0                 <NA>                                      <NA>   \n",
      "5                  0.0                      0.0                              0.0                        0                                        0.0         0.0                 <NA>                                      <NA>   \n",
      "6                  0.0                      0.0                              0.0                        0                                        0.0         0.0                 <NA>                                      <NA>   \n",
      "7                  0.0                      0.0                              0.0                        0                                        0.0         0.0                 <NA>                                      <NA>   \n",
      "8                  0.0                      0.0                              0.0                        0                                        0.0         0.0                 <NA>                                      <NA>   \n",
      "9                  0.0                      0.0                              0.0                        0                                        0.0         0.0                 <NA>                                      <NA>   \n",
      "10                 0.0                      0.0                              0.0                        0                                        0.0         0.0                 <NA>                                      <NA>   \n",
      "11                 0.0                      0.0                              0.0                        0                                        0.0         0.0                 <NA>                                      <NA>   \n",
      "12                 0.0                      0.0                              0.0                        0                                        0.0         0.0                 <NA>                                      <NA>   \n",
      "13                 0.0                      0.0                              0.0                        0                                        0.0         0.0                 <NA>                                      <NA>   \n",
      "\n",
      "    RaF Global à terminaison à date (€ HT)  Avancement Global Financier basé sur Enregistré à date (%)  Avancement Global Facturation à date (%)  PCA basé sur Enregistré à date (€)  FAE basé sur Enregistré à date (€)  Valeur vente Ingenieur (€ HT)  \\\n",
      "4                                    143.4                                               <NA>                                               <NA>                                <NA>                                <NA>                      93.052109   \n",
      "5                                   1410.1                                               <NA>                                               <NA>                                <NA>                                <NA>                      96.010408   \n",
      "6                                    239.0                                               <NA>                                               <NA>                                <NA>                                <NA>                      93.023256   \n",
      "7                                   8245.5                                               <NA>                                               <NA>                                <NA>                                <NA>                       96.35122   \n",
      "8                                   1553.5                                               <NA>                                               <NA>                                <NA>                                <NA>                      96.006144   \n",
      "9                                 83212.21                                               <NA>                                                0.0                                <NA>                                <NA>                          95.04   \n",
      "10                                 20004.3                                               <NA>                                               <NA>                                <NA>                                <NA>                      96.069869   \n",
      "11                                   884.3                                               <NA>                                               <NA>                                <NA>                                <NA>                           95.0   \n",
      "12                                 17255.8                                               <NA>                                               <NA>                                <NA>                                <NA>                       96.02649   \n",
      "13                              6884.09625                                               <NA>                                               <NA>                                <NA>                                <NA>                           96.0   \n",
      "\n",
      "    Objectif fin d'année  Cohérence Budget  ecart couts à terminaison vs M-1  écart avancement  CA Y  Charges Y  Marge Y  Facturation Y  CA mois  Charges mois  Marge mois  Facturation mois  Remaining Forecast  hrs à fin s21  RaF (h) MO à fin s21  \\\n",
      "4                    0.5              <NA>                              <NA>              <NA>  <NA>       <NA>     <NA>            0.0     <NA>          <NA>        <NA>               0.0                <NA>            3.0                   0.0   \n",
      "5                   <NA>              <NA>                              <NA>              <NA>  <NA>       <NA>     <NA>            0.0     <NA>          <NA>        <NA>               0.0                <NA>           29.5                   0.0   \n",
      "6                    1.0              <NA>                              <NA>              <NA>  <NA>       <NA>     <NA>            0.0     <NA>          <NA>        <NA>               0.0                <NA>            5.0                   0.0   \n",
      "7                    1.0              <NA>                              <NA>              <NA>  <NA>       <NA>     <NA>            0.0     <NA>          <NA>        <NA>               0.0                <NA>          172.5                   0.0   \n",
      "8                   <NA>              <NA>                              <NA>              <NA>  <NA>       <NA>     <NA>            0.0     <NA>          <NA>        <NA>               0.0                <NA>           32.5                   0.0   \n",
      "9                    1.0               0.0                              <NA>              <NA>  <NA>       <NA>     <NA>            0.0     <NA>          <NA>        <NA>               0.0                <NA>         1970.5                   0.0   \n",
      "10                  <NA>              <NA>                              <NA>              <NA>  <NA>       <NA>     <NA>            0.0     <NA>          <NA>        <NA>               0.0                <NA>          418.5                   0.0   \n",
      "11                  <NA>              <NA>                              <NA>              <NA>  <NA>       <NA>     <NA>            0.0     <NA>          <NA>        <NA>               0.0                <NA>           18.5                   0.0   \n",
      "12                  <NA>              <NA>                              <NA>              <NA>  <NA>       <NA>     <NA>            0.0     <NA>          <NA>        <NA>               0.0                <NA>          361.0                   0.0   \n",
      "13                   1.0              <NA>                              <NA>              <NA>  <NA>       <NA>     <NA>            0.0     <NA>          <NA>        <NA>               0.0                <NA>          144.0               0.01875   \n",
      "\n",
      "    RaF (h) MO à fin s22  \n",
      "4                   -3.0  \n",
      "5                  -29.5  \n",
      "6                   -5.0  \n",
      "7                 -172.5  \n",
      "8                  -32.5  \n",
      "9                -1970.5  \n",
      "10                -418.5  \n",
      "11                 -18.5  \n",
      "12                -361.0  \n",
      "13                -144.0  \n",
      "\n",
      "Done. Feuilles analysées: 1\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, unicodedata, warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# ============== CONFIG ==============\n",
    "FILE_PATH = r\"C:\\globasoft\\aerotech\\fic\\Suivi Projets AEC - source.xlsx\"\n",
    "SHOW_SAMPLE = True\n",
    "\n",
    "# (optionnel) masquer un warning bruyant de pandas\n",
    "warnings.filterwarnings(\"ignore\", message=r\"Parsing dates in %Y-%m-%d %H:%M:%S format.*\", category=UserWarning)\n",
    "\n",
    "# ============== LOG ==============\n",
    "def now(): return datetime.now().strftime(\"%H:%M:%S\")\n",
    "def log(msg): print(f\"[{now()}] {msg}\", flush=True)\n",
    "\n",
    "# ============== UTILS ==============\n",
    "def strip_accents_lower(s):\n",
    "    if s is None or (isinstance(s, float) and pd.isna(s)): return \"\"\n",
    "    s = unicodedata.normalize(\"NFKD\", str(s))\n",
    "    s = \"\".join(c for c in s if not unicodedata.combining(c))\n",
    "    return s.lower().strip()\n",
    "\n",
    "def snake_id(s):\n",
    "    s = strip_accents_lower(s)\n",
    "    s = re.sub(r\"[\\s\\.\\-]+\", \"_\", s)\n",
    "    s = re.sub(r\"[^a-z0-9_]\", \"_\", s)\n",
    "    return re.sub(r\"_+\", \"_\", s).strip(\"_\") or \"col\"\n",
    "\n",
    "def make_unique_columns(cols):\n",
    "    out, seen = [], {}\n",
    "    for c in cols:\n",
    "        if c not in seen:\n",
    "            seen[c] = 1\n",
    "            out.append(c)\n",
    "        else:\n",
    "            seen[c] += 1\n",
    "            out.append(f\"{c}_{seen[c]}\")\n",
    "    return out\n",
    "\n",
    "def _preclean_numeric_strings(x: pd.Series) -> pd.Series:\n",
    "    \"\"\"Nettoyage avant parse : retire True/False, espaces insécables, milliers, virgule décimale.\"\"\"\n",
    "    s = x.astype(\"string\")\n",
    "    # True/False/Yes/No -> vide (on les considère comme 'pas de valeur' dans colonnes numériques)\n",
    "    s = s.str.replace(r\"^(true|false|yes|no|vrai|faux)$\", \"\", flags=re.I, regex=True)\n",
    "    s = s.str.replace(\"\\u00A0\",\" \", regex=False).str.replace(\" \",\"\", regex=False)\n",
    "    s = s.str.replace(r\"(?<=\\d)\\.(?=\\d{3}(?:\\D|$))\",\"\", regex=True)  # mille: 1.234 -> 1234\n",
    "    s = s.str.replace(\",\",\".\", regex=False)  # décimale: 1,23 -> 1.23\n",
    "    return s\n",
    "\n",
    "def parse_number_like(series: pd.Series) -> pd.Series:\n",
    "    s = _preclean_numeric_strings(series)\n",
    "    return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "def drop_empty_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.dropna(axis=1, how=\"all\")\n",
    "    blank_idx = []\n",
    "    for j in range(df.shape[1]):\n",
    "        s = df.iloc[:, j]\n",
    "        if s.dropna().astype(str).str.strip().eq(\"\").all():\n",
    "            blank_idx.append(j)\n",
    "    if blank_idx:\n",
    "        log(f\"[drop_empty_columns] suppression colonnes blanches (pos): {blank_idx}\")\n",
    "        df = df.drop(df.columns[blank_idx], axis=1)\n",
    "    return df\n",
    "\n",
    "# ============== HEADER PICK ==============\n",
    "HEADER_HINTS = (\n",
    "    # génériques\n",
    "    \"projet\",\"projets\",\"code\",\"id\",\"réf\",\"ref\",\"libelle\",\"libellé\",\"intitulé\",\n",
    "    \"client\",\"fournisseur\",\"chef de projet\",\"cp\",\"cdp\",\"manager\",\n",
    "    \"statut\",\"status\",\"phase\",\"categorie\",\"catégorie\",\"type\",\n",
    "    \"date\",\"heure\",\"time\",\"période\",\"periode\",\"echeance\",\"échéance\",\"fin\",\"début\",\"debut\",\n",
    "    \"budget\",\"montant\",\"cout\",\"coût\",\"prix\",\"ht\",\"ttc\",\"avancement\",\"progress\",\"%\",\"taux\",\n",
    "    \"site\",\"section analytique\",\"analytique\",\"commentaire\",\"observations\",\"notes\",\"remarques\",\n",
    "    # vus dans ton fichier\n",
    "    \"comments\",\"revue raf\",\"statut clipper\",\"gtm\",\"pôle\",\"pole\",\n",
    "    \"remaining forecast\",\"facturation mois\",\"hrs\",\"heures\",\"(h)\",\n",
    "    \"ca \",\"charges\",\"marge\",\"achats\",\"commandé\",\"enregistré\",\"fnp\",\"int\",\"raf\"\n",
    ")\n",
    "\n",
    "def choose_header_row(df: pd.DataFrame, scan=30) -> int:\n",
    "    limit = min(len(df), scan)\n",
    "    cand_idx, cand_hits = None, -1\n",
    "    for i in range(limit):\n",
    "        row = df.iloc[i].astype(str)\n",
    "        hits = 0\n",
    "        for v in row:\n",
    "            t = strip_accents_lower(v)\n",
    "            if t and any(k in t for k in HEADER_HINTS):\n",
    "                hits += 1\n",
    "        if hits >= 2 and hits > cand_hits:\n",
    "            cand_idx, cand_hits = i, hits\n",
    "    if cand_idx is not None:\n",
    "        return cand_idx\n",
    "\n",
    "    best, idx = -1, 0\n",
    "    for i in range(limit):\n",
    "        row = df.iloc[i].astype(str)\n",
    "        non_empty = row.map(lambda x: x.strip()!=\"\").sum()\n",
    "        texty = row.map(lambda x: bool(re.search(r\"[A-Za-zÀ-ÿ]\", x))).sum()\n",
    "        score = non_empty*2 + texty\n",
    "        if score > best: best, idx = score, i\n",
    "    return idx\n",
    "\n",
    "# ============== INFÉRENCE TYPES (→ PostgreSQL) ==============\n",
    "MAP_TRUE  = {\"true\",\"vrai\",\"oui\",\"yes\",\"1\",\"y\",\"o\"}\n",
    "MAP_FALSE = {\"false\",\"faux\",\"non\",\"no\",\"0\",\"n\"}\n",
    "\n",
    "DATE_TOKEN_RE = re.compile(\n",
    "    r\"(?:\\d{4}[-/\\.]\\d{1,2}[-/\\.]\\d{1,2})|(?:\\d{1,2}[-/\\.]\\d{1,2}[-/\\.]\\d{2,4})|\"\n",
    "    r\"(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec|janv|févr|fevr|avr|mai|juin|juil|sept|oct|nov|d[ée]c)\",\n",
    "    re.I\n",
    ")\n",
    "ISO_DATE_RE = re.compile(r\"^\\d{4}-\\d{2}-\\d{2}(?:[ T]\\d{2}:\\d{2}:\\d{2})?$\")\n",
    "\n",
    "# Catégories par en-tête (PRIMES sur le contenu)\n",
    "DATE_NAME_HINTS   = (\"date\",\"dt\",\"heure\",\"time\",\"echeance\",\"échéance\",\"debut\",\"début\",\"fin\",\"période\",\"periode\",\"semaine\",\"mois\",\"année\",\"annee\")\n",
    "MONEY_NAME_HINTS  = (\"€\",\"ht\",\"budget\",\"montant\",\"amount\",\"total\",\"prix\",\"coût\",\"cout\",\"facturation\",\"forecast\",\"achats\",\"commandé\",\"enregistré\",\"fnp\",\"ca \",\"charges\",\"marge\",\"int\",\"raf\")\n",
    "HOUR_NAME_HINTS   = (\"heures\",\"hrs\",\"(h)\",\" h \")\n",
    "PERCENT_NAME_HINTS= (\"%\", \"taux\", \"marge\", \"avancement\", \"écart\", \"ecart\", \"pourcent\")\n",
    "\n",
    "CODE_LIKE_HINTS   = (\"code\",\"nature\",\"plan\",\"compte\",\"sop\",\"section\",\"niveau\",\"trigramme\",\"immat\",\"ot\",\"ata\",\"wp\",\"n° dossier\",\"n_dossier\",\"dossier\",\"cat point\",\"cat pointage\",\"statut clipper\",\"gtm\",\"pôle\",\"pole\",\"comments\",\"cdp\",\"top custo\",\"réunion raf\",\"reunion raf\",\"statut suivi de projets\",\"statut suivi de projet\")\n",
    "\n",
    "def colname_has(hints, name):\n",
    "    n = strip_accents_lower(name or \"\")\n",
    "    return any(h in n for h in hints)\n",
    "\n",
    "def excel_serial_to_datetime(series: pd.Series) -> pd.Series:\n",
    "    vals = pd.to_numeric(series, errors=\"coerce\").astype(\"float64\")\n",
    "    vals[~np.isfinite(vals)] = np.nan\n",
    "    lower, upper = 60.0, 60000.0  # ~ 1900..2064\n",
    "    mask = (vals >= lower) & (vals <= upper)\n",
    "    n_out = int((~mask & ~pd.isna(vals)).sum())\n",
    "    if n_out:\n",
    "        log(f\"[excel_serial_to_datetime] valeurs hors fenêtre [{int(lower)}, {int(upper)}] -> NaN: {n_out}\")\n",
    "    base = pd.Timestamp(\"1899-12-30\")\n",
    "    td = pd.to_timedelta(vals.where(mask, np.nan), unit=\"D\", errors=\"coerce\")\n",
    "    dt = base + td\n",
    "    return pd.to_datetime(dt, errors=\"coerce\")\n",
    "\n",
    "def infer_col(col: pd.Series):\n",
    "    \"\"\"\n",
    "    Retourne (serie_casted, tag) avec tag ∈ {\"DATE\",\"DATETIME\",\"INT\",\"FLOAT\",\"BOOL\",\"STRING\"}.\n",
    "    PRÉCÉDENCE EN-TÊTE > CONTENU pour éviter les faux types.\n",
    "    \"\"\"\n",
    "    s = col.copy()\n",
    "    ss = s.astype(\"string\").str.strip()\n",
    "    name = s.name or \"\"\n",
    "\n",
    "    # 1) Colonnes € / CA / Charges / Marge / Facturation / Achats / RAF / Int  -> NUMÉRIQUE\n",
    "    if colname_has(MONEY_NAME_HINTS, name):\n",
    "        nums = parse_number_like(ss)\n",
    "        if nums.notna().any():\n",
    "            nz = nums.dropna()\n",
    "            # monétaire et métriques -> float par défaut\n",
    "            return nums.astype(\"Float64\"), \"FLOAT\"\n",
    "\n",
    "    # 2) Colonnes Heures -> NUMÉRIQUE (float)\n",
    "    if colname_has(HOUR_NAME_HINTS, name):\n",
    "        nums = parse_number_like(ss)\n",
    "        if nums.notna().any():\n",
    "            return nums.astype(\"Float64\"), \"FLOAT\"\n",
    "\n",
    "    # 3) Colonnes % / taux / avancement / écart -> NUMÉRIQUE (float)\n",
    "    if (\"%\" in (name or \"\")) or colname_has(PERCENT_NAME_HINTS, name):\n",
    "        nums = parse_number_like(ss)\n",
    "        if nums.notna().any():\n",
    "            return nums.astype(\"Float64\"), \"FLOAT\"\n",
    "\n",
    "    # 4) Dates ISO explicites\n",
    "    iso_mask = ss.fillna(\"\").str.match(ISO_DATE_RE)\n",
    "    if len(ss) and iso_mask.mean() >= 0.5:\n",
    "        dt_iso = pd.to_datetime(ss.where(iso_mask), errors=\"coerce\", dayfirst=False)\n",
    "        ok = dt_iso.notna().mean()\n",
    "        if ok >= 0.5:\n",
    "            has_time = (dt_iso.dt.time.astype(str) != \"00:00:00\").mean() > 0.2\n",
    "            return (\n",
    "                dt_iso.dt.strftime(\"%Y-%m-%d %H:%M:%S\") if has_time else dt_iso.dt.strftime(\"%Y-%m-%d\"),\n",
    "                \"DATETIME\" if has_time else \"DATE\"\n",
    "            )\n",
    "\n",
    "    # 5) Excel-serial -> Date : UNIQUEMENT si le nom évoque une date/heure\n",
    "    if colname_has(DATE_NAME_HINTS, name):\n",
    "        as_num = pd.to_numeric(ss, errors=\"coerce\")\n",
    "        safe_mask = (as_num >= 60) & (as_num <= 60000)\n",
    "        if (as_num.notna().mean() if len(ss) else 0.0) >= 0.9 and safe_mask.mean() >= 0.7:\n",
    "            parsed = excel_serial_to_datetime(as_num)\n",
    "            ok = parsed.notna().mean() if len(ss) else 0.0\n",
    "            if ok >= 0.7:\n",
    "                has_time = (parsed.dt.time.astype(str) != \"00:00:00\").mean() > 0.2\n",
    "                return (\n",
    "                    parsed.dt.strftime(\"%Y-%m-%d %H:%M:%S\") if has_time else parsed.dt.strftime(\"%Y-%m-%d\"),\n",
    "                    \"DATETIME\" if has_time else \"DATE\"\n",
    "                )\n",
    "\n",
    "    # 6) Tokens de date\n",
    "    date_token_ratio = ss.fillna(\"\").str.contains(DATE_TOKEN_RE, na=False).mean()\n",
    "    if colname_has(DATE_NAME_HINTS, name) or (date_token_ratio >= 0.30):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", message=\"Could not infer format.*\", category=UserWarning)\n",
    "            dt1 = pd.to_datetime(ss, errors=\"coerce\", dayfirst=True,  cache=True)\n",
    "            dt2 = pd.to_datetime(ss, errors=\"coerce\", dayfirst=False, cache=True)\n",
    "        dt = dt2 if dt2.notna().sum() > dt1.notna().sum() else dt1\n",
    "        ok = dt.notna().mean() if len(ss) else 0.0\n",
    "        ok_thresh = 0.50 if colname_has(DATE_NAME_HINTS, name) else 0.70\n",
    "        if ok >= ok_thresh:\n",
    "            has_time = (dt.dt.time.astype(str) != \"00:00:00\").mean() > 0.2\n",
    "            return (\n",
    "                pd.to_datetime(dt).dt.strftime(\"%Y-%m-%d %H:%M:%S\") if has_time else pd.to_datetime(dt).dt.strftime(\"%Y-%m-%d\"),\n",
    "                \"DATETIME\" if has_time else \"DATE\"\n",
    "            )\n",
    "\n",
    "    # 7) Bool strict (après les overrides ci-dessus)\n",
    "    mb = ss.str.lower().map(lambda x: True if x in MAP_TRUE else (False if x in MAP_FALSE else pd.NA))\n",
    "    if len(ss) and mb.notna().mean() >= 0.98:\n",
    "        return mb.astype(\"boolean\"), \"BOOL\"\n",
    "\n",
    "    # 8) Nombre générique\n",
    "    nums = parse_number_like(ss)\n",
    "    if (nums.notna().mean() if len(ss) else 0) >= 0.85:\n",
    "        nz = nums.dropna()\n",
    "        if len(nz) and (np.mod(nz, 1) == 0).all():\n",
    "            return nums.astype(\"Int64\"), \"INT\"\n",
    "        return nums.astype(\"Float64\"), \"FLOAT\"\n",
    "\n",
    "    # 9) Texte (codes/labels)\n",
    "    if colname_has(CODE_LIKE_HINTS, name):\n",
    "        return ss.astype(\"string\"), \"STRING\"\n",
    "    return ss.astype(\"string\"), \"STRING\"\n",
    "\n",
    "def pg_type(tag: str) -> str:\n",
    "    return {\n",
    "        \"DATE\":\"date\",\n",
    "        \"DATETIME\":\"timestamp without time zone\",\n",
    "        \"INT\":\"integer\",\n",
    "        \"FLOAT\":\"double precision\",\n",
    "        \"BOOL\":\"boolean\",\n",
    "        \"STRING\":\"text\"\n",
    "    }.get(tag, \"text\")\n",
    "\n",
    "# ============== MAIN ==============\n",
    "def main():\n",
    "    xlsx = Path(FILE_PATH)\n",
    "    log(f\"Fichier: {xlsx}\")\n",
    "    if not xlsx.exists():\n",
    "        log(\"[error] Fichier introuvable\"); return\n",
    "\n",
    "    try:\n",
    "        sheets = pd.read_excel(xlsx, sheet_name=None, engine=\"openpyxl\", header=None)\n",
    "    except Exception as e:\n",
    "        log(f\"[error] Lecture échouée: {e}\"); return\n",
    "\n",
    "    done = 0\n",
    "    for name, raw in sheets.items():\n",
    "        log(f\"\\n[feuille] {name}: shape initiale={raw.shape}\")\n",
    "\n",
    "        raw = raw.dropna(how=\"all\", axis=0).dropna(how=\"all\", axis=1)\n",
    "        log(f\"[feuille] {name}: après drop vides -> {raw.shape}\")\n",
    "        if raw.empty:\n",
    "            log(f\"[feuille] {name}: vide, on passe.\")\n",
    "            continue\n",
    "\n",
    "        h = choose_header_row(raw, scan=30)\n",
    "        log(f\"[feuille] {name}: header choisi à la ligne {h}\")\n",
    "\n",
    "        df_src = raw.iloc[h+1:].copy()\n",
    "        src_cols_original = raw.iloc[h].tolist()\n",
    "        df_src.columns = src_cols_original\n",
    "        df_src = df_src.dropna(how=\"all\").copy()\n",
    "        df_src = drop_empty_columns(df_src)\n",
    "        log(f\"[feuille] {name}: shape après affectation des en-têtes -> {df_src.shape}\")\n",
    "        if df_src.empty:\n",
    "            log(f\"[feuille] {name}: vide après normalisation, on passe.\")\n",
    "            continue\n",
    "\n",
    "        pg_cols = make_unique_columns([snake_id(c) for c in df_src.columns])\n",
    "\n",
    "        schema_src = {}\n",
    "        casted_df = df_src.copy()\n",
    "        for c in list(df_src.columns):\n",
    "            casted, tag = infer_col(df_src[c])\n",
    "            casted_df[c] = casted\n",
    "            schema_src[c] = tag\n",
    "\n",
    "        base = f\"{snake_id(xlsx.stem)}.{snake_id(name)}\"\n",
    "        print(f\"\\n--- Feuille: {name} -> {base} (SCHÉMA SOURCE STRICT / PostgreSQL) ---\")\n",
    "        print(f\"rows={len(casted_df)} | cols={casted_df.shape[1]}\")\n",
    "\n",
    "        print(\"\\nMapping colonnes (Excel → nom_pg) :\")\n",
    "        for src_name, pg_name in zip(df_src.columns, pg_cols):\n",
    "            print(f\"  - {src_name}  ->  {pg_name}\")\n",
    "\n",
    "        print(\"\\nSchema détecté (types PostgreSQL) :\")\n",
    "        for src_name, pg_name in zip(df_src.columns, pg_cols):\n",
    "            tag = schema_src.get(src_name, \"STRING\")\n",
    "            print(f\"  - {pg_name}: {pg_type(tag)}  (source: {src_name}, type détecté: {tag})\")\n",
    "\n",
    "        if SHOW_SAMPLE:\n",
    "            with pd.option_context(\"display.max_columns\", 220, \"display.width\", 260):\n",
    "                print(\"\\nSample (top 10) :\")\n",
    "                print(casted_df.head(10))\n",
    "\n",
    "        done += 1\n",
    "\n",
    "    print(f\"\\nDone. Feuilles analysées: {done}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532ffa8a-32de-4cfa-b21c-b99e422057ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
